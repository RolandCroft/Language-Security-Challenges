postid,tags,title,question,answers,Related
1376,issue,tls   not in built ins,tls not in built ins Why isn t tls and fs in builtins js exports fs require resolve empty js exports tls require resolve empty js I need it,What would you expect the behaviour of those to be in a browser environment Shimming the behaviour of can be somewhat accomplished with or Hi I need fs to read certificate files stored in the user s local file system Additionally and more importantly I need the tls object in order to parse pkcs certificate file contents for digital signature On Emil Bay notificationswrote What would you expect the behaviour of those to be in a browser environment Shimming the behaviour of can be somewhat accomplished with or Reply to this email directly or view it on GitHub You can t just read files from the users system like that You might be able to use FileReader however this requires the user picking the files and AFAIK there isn t a browserify compatible shim around it You might write one yourself defining the methods of in terms of and overriding in the field in See the example Ok reading files is fine I can find many ways on how to do that but what about the TLS object I need it in order to parse the certificates On Emil Bay notificationswrote You can t just read files from the users system like that You might be able to use FileReader however this requires the user picking the files and AFAIK there isn t a browserify compatible shim around it You might write one yourself defining the methods of in terms of and overriding in the field in See the example Reply to this email directly or view it on GitHub How do you parse certificates with the tls package The docs show that is only used to create TLS servers and sockets and could never work in today s browser I parse certificats using Crypto but crypto createCredentials function is deprecated This function is to be used within why browserify should contain TLS,Yes
863,pr,Feature/fix blacklist,Feature fix blacklist Fixing bugs Blacklist was not being updated due to a bad comparison Related pages was not being updated due to not sorting,Nice belated,Yes
1988,issue,rustup hash failing,rustup hash failing Hi the hash of rustup is failing It looks like the json file was updated days ago maybe something wasn t updated properly Installing rustup bit C MB Checking hash of C Hash check failed for Expected b d e a de bd b b f db bb c c e cc a Actual c ada fb d d ad f e e c b f af acd b,Fixed Thanks for being so quick I have a similar issue now with Bucket seems to be updated but hash check is failing fixed with,Yes
7150,issue,[Source Control] Issue trying to checkout a git SSH repository (Failed to start SSH session: Unable to exchange encryption keys),Source Control Issue trying to checkout a git SSH repository Failed to start SSH session Unable to exchange encryption keys Clone any repository with SSH url Create open a Solution in the cloned path in MD Press menu SourceControl Checkout In connect repository url set your SSH url Failed to start SSH session Unable to exchange encryption keys This is the full VS bug,Should be fixed by libgit bump Fixed in version master Pull Request merged by Vsevolod Kukol Author mono Commit e c e bc b fe dec f c eb f b cc mono monodevelop Fixed in version release Pull Request merged by Vsevolod Kukol Author mono Commit e c e bc b fe dec f c eb f b cc xamarin monodevelop Fixed in version master Pull Request merged by Vsevolod Kukol Author mono Commit e c e bc b fe dec f c eb f b cc xamarin monodevelop,Unsure
661,issue,Not able to get encrypted value of string using AES ECB NoPadding,Not able to get encrypted value of string using AES ECB NoPadding Describe the bug String can not be reproduced from the encrypted uint array To Reproduce Steps to reproduce the behavior encrypt a string using ECB block Try to get the string equivalent from the given uint array it gives nil Sample code Expected behavior crash as you unwrap a nil value Environment please complete the following information Swift version Platform iOS macOS Linux mac OS high sierra Installation method CocoaPods Carthage SPM CocoaPods Project name Additional context,String can not be reproduced from the encrypted uint array that s basically how encryption works A string is just a representation of bytes It s not guaranteed that we can form the valid UTF string from the ciphertext I need to send the encrypted string to server So how do I do it depends on what form of data server accepts It may be base encoded or binary Can t tell for sure without checking the protocol docs you re using server is expecting base encoded string value so how can I convert the uint array to base I m sure you checked README for that In case you didn t there is a section about conversion helpers Thanks man,Yes
2228,issue,Sticky cookies are improperly formatted.,Sticky cookies are improperly formatted Steps to reproduce the problem Go to Click Set Test Cookie Observe that one cookie is sent to the server Remove the cookie launch mitmproxy with and tell your browser to use it as a proxy Reload the page Click Set Test Cookie Observe that two cookies are sent to the server Any other comments What have you tried so far There appears to be a comma in the output of mitmproxy even though it is surrounded by quotes It s possible then that this is a parsing fail on the tool s end caused by a difference in what s sent back for the format of the date Still should it really be changing that System information Arch Linux freshly updated Mitmproxy version release version Python version Platform Linux ARCH x with glibc SSL version OpenSSL k Jan,Thanks for the report It looks like we parse it correctly But for some reason includes the attributes in the header My understanding is that this is very wrong We definitely should catch that in our tests So I ve got a hack that seems to fix it If you replace with I don t like this solution though The issue appears to be with how the cookies are stored in the sticky cookie implementation as well as to an extent the implementation Sticky cookies stores them as a list of tuple lists instead of a list of tuples as seems to be used elsewhere expects a list of tuples for each cookie It is noteworthy that this seems broken at the moment because the way it should work as currently implemented should give me cookies for every attribute The changes I would reccomend would be to have take a list tuples same as and change the cookie jar in sticky cookies to store cookies in this same format If there are big issues with this the hack I mentioned above can be applied I m going to go ahead and submit the hack in a pull request for now,Yes
964,pr,[NT-620] Skip danger for external contributors,NT Skip danger for external contributors What Does not run Danger on PRs from external contributors Why We received an external contribution recently and the CircleCI workflow that runs Danger is failing because it does not have access to How Moved the command that we previously used to execute Danger into a bash script and updated it so that it will not run if this environment variable is not available This is the solution described in Danger s docs for not exposing environment vars CircleCI also recommends explicitly passing of secrets to builds that run on forks See Acceptance criteria Danger still runs on our own branches Once this is merged into all CircleCI workflows should pass,,Unsure
7769,pr,Correct instructions for enabling the firewall.,Correct instructions for enabling the firewall Fixes,can you review the changes in my commit Hmm I m ok with more concise wording but it is fairly easy to miss and most VPS hosts don t use the default port Is there a way to make it stand out that you will LOSE access to your machine if you re not careful without using a warning Ah I missed that point Reverted Additional remark should I work in I was debating with myself on how to respond to the comments I think that adding the links would probably be a good idea Taking out the firewall section or recommending skipping it isn t wise in my opinion The last thing we need it more bots added to botnets Even if the programmer doesn t fully understand firewalls the basic instructions as we have them should enable them to reduce the hackability of their machine Links to additional resources would be a nice touch After all the reason a programmer is reading the docs is because he doesn t know the information already go ahead and add the links please review Ok I m satisfied,Yes
4662,pr,"Fix missing ""warn"" transition for spnego weblflow with ""renew"" query param",Fix missing warn transition for spnego weblflow with renew query param param When requesting sso session renew with spnego enabled eg authentication process fails on missing transition for warn User receives error screen instead of being redirected to requested service because ST was succesfully created From application logs,,Yes
6820,pr,bump webpack-dev-server due to security warning,bump webpack dev server due to security warning ,,Yes
4465,pr,Add toggle for displaying username in title,Add toggle for displaying username in title Closes Closes Signed off by Tomas Slusny,Updated to be reasonably implemented,Unsure
1527,issue,Parser performance: Excessive use of regular expressions to validate column names,Parser performance Excessive use of regular expressions to validate column names I m currently studying the H parser to compare it to the jOOQ parser to learn new tricks I ll create a few issues regarding performance problems I ve noticed in the H parser I m running this simple benchmark program that generates unique SQL strings to parse on each iteration to prevent caching effects Between ready and finished I connect to the JVM using JMC and JFR both tools are available for free to work with OpenJDK I ve noticed some heavy allocation originating almost exclusively from a single spot The JDK s regular expressions are well known for their not so efficient implementation Given the fact that the default implementation for the above method implements a trivial regular expression I strongly suggest replacing the default implementation by something that does not use regex but a simpler implementation In this case it seems that any non empty string is,N B This doesn t only affect allocation metrics but also CPU metrics See,Yes
2514,pr,Add LogLevel availability check to IMvxLog,Add LogLevel availability check to IMvxLog sparkles What kind of change does this PR introduce Bug fix feature docs update Improvement arrow heading down What is the current behavior Right now the assume that all implementations of will behave like when it comes to checking log levels an incorrect assumption new What is the new behavior if this is a feature change The underlying implementation of remains the same Relying on the current log provider to return a bool value indicating whether or not that log level is enabled The interface change however will make consumers more aware of how level checking should work boom Does this PR introduce a breaking change Nopity nope bug Recommendations for testing ping memo Links to relevant issues docs Closes thinking Checklist before submitting x All projects build x Follows style guide lines code style x Relevant documentation was updated docs style x Nuspec files were updated when applicable x Rebased onto current develop,,Unsure
731,pr,fix rest leak bug,fix rest leak bug Motivation thanks the context and why you re making that change To make others understand what is the problem you re trying to solve Modification Describe the idea and modifications you ve done Result Fixes If there is no issue then describe the changes introduced by this PR,see Report Merging into will decrease coverage by The diff coverage is Impacted file tree Impacted Coverage Complexity arrow down arrow down and Continue to review full report at Legend Click here to learn Powered by Last update Read the comment,Yes
2823,pr,Added new Azure Resource - azure_network_security_group,Added new Azure Resource azure network security group This addresses,thank you for the heads up just cleaned up the resource file spacing as per Rubocop suggestions sorry for the hold on this Azure is going through some major refactoring atm so these are in a limbo for a tad Thanks Jared Are you referring to the Azure related modules for InSpec or actual azure resources I pinged one of my friends on the Azure group and he didn t have any insight on major changes Sent from my S On May at AM Jared Quick wrote sorry for the hold on this Azure is going through some major refactoring atm so these are in a limbo for a tad You are receiving this because you were mentioned Reply to this email directly view it on GitHub or mute the thread It s the InSpec resources that represent the Azure resources are in flux Especially the underlying ways InSpec Train talks to Azure via RM SDK REST or VM SDK Thanks for the clarification Clinton makes sense Sent from my S On May at AM Clinton Wolfe wrote It s the InSpec resources that represent the Azure resources are in flux Especially the underlying ways InSpec Train talks to Azure via RM SDK REST or VM SDK You are receiving this because you were mentioned Reply to this email directly view it on GitHub or mute the thread Things have settled a bit with the Azure work there is now a resource that includes several new resources including a singular and plural NSG Looks like an implementation and integration test is there but no docs If you d care to open a PR on the resource pack with your docs that would be great Sorry about the mis coordination As there is now an NSG component in the resource pack and docs are imminent I m going to go ahead and close this,Yes
708,issue,Reference git url with hash (i.e. for multi repo PR's),Reference git url with hash i e for multi repo PR s Do you want to request a feature or report a bug I guess it s a but works in npm CLI What is the current behavior When I reference a GitHub URL with hash I get the error message If the current behavior is a bug please provide the steps to reproduce Create a PR in git repo Reference the commit s git URL in package json yarn install error needs package version What is the expected behavior We re using multiple git repositorys At times we need to reference a PR commit by hash for testing like This would help if it works which it does with the npm CLI Please mention your node js yarn and operating system version node js v yarn Windows,Referencing a branch with a hash works fine in yarn What doesn t work is the fact that you re specifying as the user which is an open issue at the workaround at specifying a source of will pull the branch and work fine Thank you that worked well,No
2634,issue,dnsjumper@2.1: hash check failed,dnsjumperhash check failed Download OK download completed Checking hash of DnsJumper zip ERROR Hash check failed App extras dnsjumper URL bytes B Expected c c ab e be a aa f f b aa e a c Actual cda b bae eba deaf fc b f baaf f f ae ea,Closed via,No
3890,pr,tls: prevent server from using dhe keys < 768,tls prevent server from using dhe keys As part of the fix for logjam node was upgraded to a level of openssl which rejects connections to servers that are using keys smaller than bits It is still possible however to create a server that uses a smaller key size and and older client may be able to connect to it This PR moves us to a secure by default stance on the server side as well preventing the creation of a server using a dhe key size less than This can be overridden with the command line option which is also added It is derived was landed in later io js node versions but makes the limit This PR uses the smaller limit in order to meet the recomendations for logjam while matching was was done on the client side in openssl to minimize the potential impacton users,can you two take a look at this PR LGTM Ran test suite locally failing but unrelated test in make test addons ran cleanly This is a patch that prevents a security misconfiguration IMO that makes it not a Technically it is semver major but it is one that should have minimal impact The introduction of the new command line switch to revert to the prior behavior is also significant That said this would land in v x which is in a weird place in semver land anyway LGTM I m not really happy about the commandline argument here and I think I d prefer to make it something you can t change than introduce another API we have to care about into the future commandline argument as an API If we must have the argument then perhaps something more specific that doesn t use the term revert Also I d vote for semver major we can argue this is a bug or misconfiguration but in the spirit of the conservative approach to semver we ve been taking we should hold off till the next major And cc The only setups this is going to break is those that have been dangerously misconfigured And they still have a way to get back the old behaviour It looks like a sane thing to do An alternative non breaking approach would be to reduce this to a big warning instead of an Error But given that this part of code is generally one of the first things that the server does anyone should notice the error immediately after the version update on the test setup note that this does not print the in the output or document it in any way The intent would be for it to be supported strictly in the LTS branches and not something that would be supported going forward The only place it would be documented is in the release notes as an indication that if this change breaks you here s the workaround we re providing which by the way is only supported in these specific LTS lines I m good with as a name tho oh I see this is for we are doing the right thing in v I take it then correct me if I m wrong but this fix would end up needing to go out in v x also unfortunately In v x it would be a semver minor bump I leave the decision of a new option name to native English speakers I have no preference I have two comments here Please add a rule of dh pem to Makefile as in There are not descriptions regarding to the new option It should be noted in src node cc doc node and doc api tls markdown It s already in v x with bits limit at Do not be worry Note this is at least because as mentioned recently downgrading while using this option will cause an error ah that s right so hard to keep track sometimes I added the requested change to the Makefile for the test fixtures In terms of documenting this the discussion I had with James was that we d prefer not to add to the regular documentation We don t want anybody to use it and it will not be in any later release Instead we planned to just document it in the migration notes so that people are aware of it if they need to use it when upgrading but otherwise are less likely to use it I think Jame s comment above echo s the same approach Does that make sense to you or do you still think we need to add it to printHelp and tls markdown updated to address wording comments and change name of the option I m okay for no doc Someone in the future would have the same question as mine so please write its description in the commit log Otherwise LGTM after CI is fine Updated based on shigeki s comment to add to the commit comment and squashed Changes LGTM Disregard my previous two comments keep forgetting this is v CI run here CI run is green on all but windows Looking at earlier failures most of them are pre existing The only one that worries me a bit is not ok test tls ticket cluster js which failed times and which I don t see in the previous run going to start another CI run to see how many times it recreates Don t think its related as I d expect any failure to be but more data can t hurt If that continues to fail may want to pass it through the new stress test job in CI to see if it s flaky From test keyFile join common fixturesDir agent key var certFile join common fixturesDir agent crt From RSA PRIVATE KEY MIIEowIBAAKCAQEAz LXZOjcQCJq ZKUFabj oo ex XsBcFqtBThjjTw CVEV So looks to be an RSA key don t see how that could be related to limiting DHE key size No recreates in second run only failures commonly seen on windows so seems unrelated I think we are good to go CI run wise can we get one more review from you on this before landing I m not entirely comfortable with squeezing this in to v cause of the breaking nature of it but I ll throw in an lgtm for the sake of secure by default and the low likelihood of anyone being impacted test tls ticket cluster js has nothing to do with DHE key exchange Probably it was a timing issue in process fork and die FYI Google is planning to deprecate DHE in Chrome because they consider that bits DHE has not enough security and moving to ECDHE is better Intent to deprecate DHE based cipher suites noted I have the same concerns but overall LGTM can you go ahead and get this landed in I m not happy with adding another seldom used command line switch but if you go ahead please at add it to and the print so it s properly documented not documenting it is intentional This switch would only exist in v and is only for people who absolutely need it There is no intent to support it in any other version The documentation would be the release notes By not putting it into any other documentation we are not committing to support it beyond the v branch On Nov PM silverwind notificationswrote I m not happy with adding another seldom used command line switch but if you go ahead please at add it to the man page and the help print so it s properly documented Reply to this email directly or view it on GitHub alright carry on I was out Friday afternoon so just see the comment from James to land will do that now landed caa b d d eeb d daa cef fa ed f,Yes
2319,issue,Call pm2.connect twice cause memory leak,Call pm connect twice cause memory leak file pm connect twice memory leak would happen that s because cb is referenced by event which never trigged so that s the design or bug if sth wrong please tell me,This function has been rewriten in pm v this version should be leak free,Yes
48774,pr,[7.x] Validate monitoring username at parse time,x Validate monitoring username at parse time Provides parse time validation for AUTH USERNAME SETTING as described in Backport of,run elasticsearch ci update branch,Yes
265,issue,[C++] Is it possible to run the C++ version in a work-stealing executor?,C Is it possible to run the C version in a work stealing executor Hi First of all very impressive work I see that in the C version starting a new session returns a client object that can be used from async tasks but the C version returns only a GUID Are C sessions inherently pinned to threads Is there any way to use the C version of FASTER from a work stealing async await like context,Yes the C version uses sessions pinned to threads We added the unpinned session feature in C due to the need of a majority of async use cases there unlike C where most use cases find thread pinning to be sufficient,Yes
3268,pr,[UWP] store alert to local variable for thread safety,UWP store alert to local variable for thread safety Description of Change The while loop on s currentAlert wasn t thread safe so it could be set to null between the check and the await which meant it would be awaiting on null and throw an exception Added text to description but the clicking to cause the issue has to happen too quickly for the UI test to detect Issues Resolved fixes Platforms Affected UWP PR Checklist Has automated tests X Rebased on top of the target branch at time of PR X Changes adhere to coding standard,build uitests,Yes
1921,issue,hibernate.hbm2ddl.auto=create bypasses the FILE_LOCK=file mechanism,hibernate hbm ddl auto create bypasses the FILE LOCK file mechanism We are using the h tested both and driver in conjunction with Hibernate in a cluster environment with nodes and a shared network storage where the h files reside The database is configured with and For our test purposes the port is blocked by the firewall preventing proper communication between them Although node A has a lock in the database and the lock file exists node B is able to initialize Hibernate with and steals the lock from node A which then steals it back in a back and forth fashion Also querying the database from each node produces different results even on the same table I am not sure if the database itself is corrupted or if each node has cached the DB file in some way however the problem is that Expected behavior node B should properly identify that the DB is locked and throw a type of error due to inability to communicate with the DB master node A in this case Actual behavior node B is able to initialize itself and start working by recreating the DB schema and destroying all data,what do the respect trace logs look like Actually it has nothing to do with hibernate ddl etc I just enabled trace logs and unfortunately the watchdog mechanism is not properly synchronized with the network file system In the problematic case we see that the challenge was not reverted on time seconds Maybe the network file protocol we use Samba fails to commit fast enough WORKS PROPERLY database opening storage AnonymousTemp h test test build fileLock load server method file id ac c b a b e deaddc f c ce e fileLock load server method file id ac c b a b e deaddc f c ce e fileLock save id ac d bcfae dc a c d ab ca method file fileLock load server method file id ac c b a b e deaddc f c ce e fileLock load server method file id ac c b a b e deaddc f c ce e error while configuring hibernate Unable to create requested service org hibernate engine jdbc env spi JdbcEnvironment PROBLEMATIC database opening storage AnonymousTemp h test test build fileLock load server method file id ac c b a b e deaddc f c ce e fileLock load server method file id ac c b a b e deaddc f c ce e fileLock save id ac fd df aec fdafeaa f f f dc e method file fileLock load method file id ac fd df aec fdafeaa f f f dc e fileLock save id ac fd df aec fdafeaa f f f dc e method file fileLock load method file id ac fd df aec fdafeaa f f f dc e fileLock save server hostName E PC id ac fd df aec fdafeaa f f f dc e method file These logs were produced running the same code twice one after the other while another process in a VM has the DB locked H has multiple locking methods for specific use cases For example I use in database URLs when databases are used inside OpenVZ containers because the default locking method does not work with their simfs file system You might have the same problem with Is there a way to change the watchdog timer from second to something else It is under the Constants LOCK SLEEP static final field EDIT Reflection doesn t work because the compiler inlines the value wherever it is used Network filesystems are always tricky they tend to do weird stuff like this You can build from source if you want to experiment,Yes
494,issue,Feature request: Add Streebog (aka. GOST R 34.11-2012) hash algorithm,Feature request Add Streebog aka GOST R hash algorithm Summary Would be helpful to add GOST R,Implemented in,Unsure
7260,issue,Slice support for FileRegion in JNI transports,Slice support for FileRegion in JNI transports Recently support was added to file region for and We should do the same for and There are some challenges related to how and are handled in these JNI transports There are assumptions made about the type of made in order to get the integer file descriptor There are also assumptions made about and its internals in JNI code There is some support for types other than via but this doesn t take advantage of We should investigate alternative approaches which may help unify the two approaches in most cases and remove assumptions of types in JNI For example we should investigate moving extracting the file s FD and the reflection involved up to the java layer creating a new interface for extensibility to give access to the file s FD and pass the file s FD and other necessary arguments directly to JNI,FYI Thanks nice writing up I think for FileChannelBasedFileRegion we an try to get the FileChannel and then the FD and then pass it to JNI,Unsure
318,issue,Add ability to cycle through cassettes,Add ability to cycle through cassettes It would be excellent if VCR had a method that when passed an array would cycle through them for each request Admittedly this is an edge case but I m trying to test long running CoffeeScript polling routines that change page content when an object s state changes This state change occurs outside of the Rails application and I ve got corresponding cassettes for each state I could test the Javascript in isolation and stub the Rails API but having VCR cycle through cassettes would allow me to do a full stack test ensuring that the external state change propagates through the Rails app and into the view,Anything preventing you from using VCR use cassette in a loop I ve actually gotten this scenario to work At some point the ajax poller would return a error but rescheduling the polling regardless of the return code lead to it eventually succeeding So in the end having the ajax be more resilient to server errors fixed this,Unsure
74,issue,获取vuex中的username失败,vuex username username mapGetters UserMenu mapGetters methods computed,,Unsure
1161,pr,Add Elliptic Curve verification support for spring-security-jwt,Add Elliptic Curve verification support for spring security jwt The implementation is inspired by the RSAVerifier and uses code from org apache xml security algorithms implementations SignatureECDSA to transcode from JWK to JCE compatible signatures It is meant to be used by the patch to which introduces support for Elliptic Curve based JWK keys This PR is one of the two PRs to deliver,I addressed the comments you had Regarding the default algorithm I don t have any preference Thanks I ll take a look at this shortly Thanks for the PR I added some polish in a separate commit This is now in master,Yes
1756,pr,security: upgrade jackson to avoid security vulnerabilities,security upgrade jackson to avoid security vulnerabilities Describe what this PR did This PR upgraded jackson version to to avoid CVE ReleaseNote Patch databind issue Do we need to upgrade to latest version Does this pull request fix one issue Why don t you add test cases unit test integration test Describe how to verify it Special notes for reviews,Report Merging into will decrease coverage by The diff coverage is Impacted file tree Impacted Coverage Complexity Continue to review full report at Legend Click here to learn Powered by Last update Read the comment,Yes
2779,issue,Highlight players who can attack you in the wilderness,Highlight players who can attack you in the wilderness This would help a ton when runecrafting,And when pking I second this Duplicate of,No
7158,issue,JsonPatchDocument.ApplyTo<T> should validate target model,JsonPatchDocument ApplyTo T should validate target model When is called on model which is provided as a input parameter and the model isn t valid is generated and provided as a body output by all operations with status code In case above when validation fails because is null returns following response Now implementation of Method with The output is different The reason for this is that doesn t invoke validation on the target model which should be expected behavior Because of this need to be called explicitly and object must be provided as an input for object which leads to inconsistent output Need to notice when you don t provide you don t get any validation details errors,Seems to be relevant Same problem here I m also using overload and leads to unexpected behavior Thanks for contacting us free to send a PR for this and we ll happily consider it As this will potentially be a breaking change this should be backed by some compatibility option,Yes
14593,issue,Style changes for System.Security.Cryptography.Encryption,Style changes for System Security Cryptography Encryption Some style only comments were given in pull request best facilitate the code round tripping through the mirror this issue was created to do the cleanup after merging to master x Reduce the configuration matrix down to just Debug and Release since it has no OS specific code x CryptoStream has some redundant initializers which should be removed x CryptoStream has some private fields which are PascalCased instead of camelCased x CryptoStream has a trivial overload why is it there maybe just that adding an overload later is a recompile required change,,Yes
2538,issue,Unhandled exception: UnicodeEncodeError: 'latin-1' codec can't encode characters,Unhandled exception UnicodeEncodeError latin codec can t encode characters Step Please describe your environment ZeroNet version r Operating system Raspbian Web browser FF Step Describe the problem debug log shows multiple errors during startup INFO ConnServer Server port opened ipv False ipv False ERROR Unhandled exception UnicodeEncodeError latin codec can t encode characters in position ordinal not in range in greenlet py line Bigfile BigfilePlugin py line Site py line FilePack FilePackPlugin py line SiteStorage py line genericpath py line it was added not many seconds before i loaded plugins page which does not list any plugins then after maybe one minute the plugin list appeared,For what you using latin Use utf Change it back how it was and it will work It s an error from an internal Python module I m afraid we can t easily do this,Yes
306,issue,rack-ssl 1.3.4 solves CVE-2014-2538,rack ssl solves CVE This has been fixed avoid according to we get the advisory yml for that updated,Oh somehow I was linked to an old commit of that file I see it is correct now,Yes
8612,pr,FIX: category routes model params should decode their URL parts,FIX category routes model params should decode their URL parts Ember s route star globbing does not uri decode by default This is problematic for subcategory globs with encoded URL site settings enabled Subcategories with encoded URLs will without this decode I found this explicitly explains that globbing does not decode automatically,You ve signed the CLA featheredtoast Thank you This pull request is ready for review per Daniel I m instead implementing this in findBySlugPathWithID slash and splitting is already handled in there,Yes
1743,issue,Feature request: x-www-form-urlencoded POSTs should be easier to do,Feature request x www form urlencoded POSTs should be easier to do It shouldn t require a to get the behavior that nearly every web service on the internet expects Angular already depends on a subset of jQuery and jQuery does this behavior by default which means using the service is a bit of a downgrade I expect most users will get frustrated and ditch it before they stumble across this post on the mailing list At the very least the content of this post should be included in the documentation There was an issue for this before but it got closed when xhr was renamed to That didn t resolve the issue,From I have to work with a backend PHP which does not automatically parse JSON and which I cannot change I would like angular to automatically urlencode my POST data when the is See this thread where the recommended solution is to use jQuery s Volunteer I am wondering though as to whether I should just copy param into or perhaps jqLite js if jqLite js should be used for any subset of jQuery code or if there is some wiser way to url encode an object like the solution proposed here Retracting this is not a problem with AngularJS I don t know what backend you are using but in PHP you can simply data json decode file get contents php input data becomes an object and you can access values with def a pain in the back end When you POST a form your browser makes a form encoded POST payload This is the default behavior and accordingly every web framework I ve ever encountered expects this You can also construct form encoded payloads with jQuery or even with the FormData in javascript Because this method of POST requests is so ubiquitous most application servers I ve seem implement it for all requests It doesn t make a lot of sense to implement views differently just because they are going to be accessed by JavaScript and besides that precludes the ability to interact with them via forms Allowing these two methods of access at once is convenient Also what if you re trying to access a third party server Then you don t have the choice to change the POST encoding method You asked what framework I m using I m using Pyramid In Pyramid the url router can actually decide which view to select based on form encoded fields in the POST data see request params for Unless I form encode my POST I can t use this helpful feature I don t know why Angular would break from the standard here I don t think it is a standard as much as a convention Conventionally by default when preforming an AJAX request the data is sent form encoded AngularJS is different in more ways then this in it s design and patterns On M you need to jump through a few hoops to get it to decode properly using Mvc Nancy Webapi I feel this is more of a problem with the server than the client Because the body is represented as a stream I end up just reading that string to a dynamic of some sorts or a strong type would even work That being said providing a simple switch on the client would avoid having people spend time learning about deserialization headers etc Disregarding what is standard and what is not if it s a simple implementation and the user just have to toggle a bool to opt in or opt out that would be ideal i think Going to close this one as a duplicate of to centralise the whole discussion in one place Why close the thread that was opened first and has more discussion oh sorry actually both issues have some discussion and I wanted to centralise it one place so we can act on this I ve closed this one since started to have discussion on the actual discussion But I don t mind it either way we can re open this once and close the other For me the most important part is to draft a solution and act on it,Unsure
4518,issue,How to inject Amazon.S3.IAmazonS3 to Unit test,How to inject Amazon S IAmazonS to Unit test In Testmodules i have some code How to inject Amazon S IAmazonS this file,You should refer to the documentation for Amazon S IAmazonS Then use the Abp dependency injection Let me describe situation i injected AmazonS in UserAppService and use this normally In test file UserAppService Tests i inject UserAppService and call some function of UserAppService I run test then get error Here is my UserAppService Tests file Why the UserAppService Tests can t get AmazonS although UserAppService injected it Do i need add some code in TestModule file hi I guess you added IAmazonS to the dependency injection container in the web tier If you need to use it in unit tests you also need to add IAmazonS to the dependency injection container Or create an IAmazonS implementation in unit tests using a tool like nsubstitute Hi I want to use real library so i don t want to use nsubstitute If you need to use it in unit tests you also need to add IAmazonS to the dependency injection container Did you mean add package AmazonS from NuGet I add package and retest but get error I guess you added IAmazonS to the dependency injection container in the web tier I m using Net Core x Here is my UserAppService file Have you written the relevant code in Such as What is the document link for the Amazon S IAmazonS component Hi The document link i add some code in startup cs So for unit test what need to do adding it here Hi I can add to ServiceCollectionRegistrar But i can t add How to add config for unit test in ServiceCollectionRegistrar Here is my startup cs file You can refer to the source code manually new see,Unsure
183,issue,When will the encoder support structured append?,When will the encoder support structured append I see that there is some support for structured append in the decoder and reader but not encoder Is this planned,Questions go on the mailing list There is no roadmap and would not assume anything is being worked on You can propose a patch though I find structured append hardly ever used but it is a real optional part of the QR spec A clean patch that doesn t complicate the existing code much could be handy Alex Dupre s patch at included structured append encoding support See also,Unsure
5612,pr,docs(custom-audit): update custom-audit to 3.0.0 api,docs custom audit update custom audit to api Summary Update custom audit example as latest version changed the api so custom audit is currently broken,my man thanks for hooking this up D,Unsure
5622,issue,Can not find compilation library location for package 'Microsoft.AspNetCore.Antiforgery',Can not find compilation library location for package Microsoft AspNetCore Antiforgery Hi I am developing web app with ASP NET Core My application worked with IIS Express But when I was deployed app to IIS I got this error How can I resolve this problem project json Startup cs,Which error Hi Frank I am getting the error Can not find compilation library location for package Microsoft AspNetCore Antiforgery Also I was removed preserveCompilationContext from project json but I got One or more compilation references are missing Possible causes include a missing preserveCompilationContext property under buildOptions in the application s project json error message May be something is missing on the server Try to deploy to another server for instance on a free Azure account can you show a full screenshot of exactly the error you re getting Resolved issue by distributing to another server Ok,Yes
6281,issue,Reader: Some gravatar image urls contain encoded xml entities causing a crash,Reader Some gravatar image urls contain encoded xml entities causing a crash Props for the find in this post Gravatar URL currently contain encoded xml entities which results in an unexpected being returned when the url is used to make an NSURL We need to sanitize these and properly handle the scenario when creating a,,Yes
22982,pr,Implement JWT signature validation with JWKs [master],Implement JWT signature validation with JWKs master Purpose This PR provide the support to validate the inbound provided JWT against the property configured in JWT header and the public key generated with the JWKs attributes related to the provided property The related discussions and the requirements can be found at GitHub issues Fixes Fixes Fixes Approach As of now we can validate the signature of JWT with the use of With JWKs support the signature of a JWT can be validated using either or The is used to call the JWKs endpoint exposed by the JWT issuer This endpoint contains the public keys in the JWK format As a sample JWKs endpoint exposed by GoogleAPIs is as follows With the introduction of the updated record for the is as follows When validating the inbound provided JWT if the was configured with the kid property should be there in the header of the JWT Otherwise validation will be failed by returning an error To verify the signature the RSA public key which is built using the JWK parameters modulus and exponent is used In order to do that the PR introduced a new API Samples Sample program for validating a provided JWT with the use of JWKs endpoint Check List x Read the Contributing Updated Change Log Checked Tooling Support Added necessary tests Unit Tests Spec Conformance Tests x Integration Tests Ballerina By Example Tests Increased Test Coverage Added necessary documentation API documentation Module documentation in Module md files Ballerina By Examples,,Yes
30,issue,java.io.IOException: Image failed to decode using JPEG decoder - Samsung Galaxy S3/S4,java io IOException Image failed to decode using JPEG decoder Samsung Galaxy S S Hi Thanks for the lib has been working great for me until I tried using it on a Samsung Galaxy S and since then have been receiving the following error I m fairly sure it s something to do with the JPEG I m trying to use It s been converted from PDF to JPG using Imagick on a server Maybe you can enlighten me Thanks,Please could you attach the converted JPG This is it This image is CMYK if you convert it to RGB it should work fine I would obviously run into the same Sorry to bring this back from the dead but as this seems like a common issue wouldn t it make sense to add some sort of converter in the library Upon further inspection it looks like adding a converter involves icc profiles which could be quite big with respect to applications For those who stumble upon this issue here are some references Stack Overflow old lib Stack Overflow currently,Yes
33571,pr,Upgrade cryptography to 2.9,Upgrade cryptography to Proposed change Changelog Type of change What type of change does your PR introduce to Home Assistant NOTE Please check only box If your PR requires multiple boxes to be checked you ll most likely need to split it into multiple PRs This makes things easier and faster to code review x Dependency upgrade Bugfix non breaking change which fixes an issue New integration thank you New feature which adds functionality to an existing integration Breaking change fix feature causing existing functionality to break Code quality improvements to existing code or addition of tests Example entry for Supplying a configuration snippet makes it easier for a maintainer to test your PR Furthermore for new integrations it gives an impression of how the configuration would look like Note Remove this section if this PR does not have an example entry Additional information Details are important and help maintainers processing your PR Please be sure to fill out additional details if applicable This PR fixes or closes issue fixes This PR is related to issue Link to documentation pull request Checklist Put an in the boxes that apply You can also fill these out after creating the PR If you re unsure about any of them don t hesitate to ask We re here to help This is simply a reminder of what we are going to look for before merging your code x The code change is tested and works locally x Local tests pass Your PR cannot be merged unless tests pass x There is no commented out code in this PR x I have followed the development checklist dev checklist x The code has been formatted using Black Tests have been added to verify that the new code works If user exposed functionality or configuration variables are added changed Documentation added updated for www home assistant io docs repository If the code communicates with devices web services or third party tools x The manifest file manifest docs has all fields filled out correctly Updated and included derived files by running x New or updated dependencies have been added to Updated by running Untested files have been added to The integration reached or maintains the following Integration Quality Scale quality scale The Integration Quality Scale scores an integration on the code quality and user experience Each level of the quality scale consists of a list of requirements We highly recommend getting your integration scored No score or internal Silver Gold Platinum Thank you for contributing Below some useful links you could explore dev checklist,,Yes
240,issue,"net.minecraftforge.common.Configuration should use one array, not two.",net minecraftforge common Configuration should use one array not two Here is an issue I filed against buildcraft problem occurs when mod A creates an item with id X Game is started and config is created for mod A Another mod B creates a block with id Y There is an id conflict in minecraft when X ITEM SHIFT Y This causes very strange behavior in the world I was able to create a forestry fermenter with the BC blue print recipe of paper and lapis Can Configuration be changed to have one array instead of two for checking if a slot is reserved,I still don t know why the item shift has not been updated to Can a Forge Dev enlighten me Cause that would break all the existing worlds It should have been done when the save changed to anvil Until then Itemid on Blockid conflicts have to be treated the same way as Blockid on Blockid conflicts Right now Itemid on Blockid is ignored and causes interesting interactions A more extensive solution would include two mod loading passes The first pass would only load mods that have been loaded previously have an existing config file and the second pass would add new mods is it now last time I checked the items are automatically shifted as necessary and are not allowed to have IDs that conflict with Items The problem is that items conflict with blocks To fix this always use item ids above and block ids below this ALWAYS What you could do is write a small bit of code that would take two constants one being and the other being and shift your items in your own mod by MAX BLOCK ID minus ITEM SHIFT Then when if ever Forge changes it s item shift to You change it in your mod and bang you re already compatible and your ids never changed The dummy blocks in the block array matching any item which is not an item block prevent this being an issue Forge will NOT shift items by not really wanting to repeat this all but making old worlds explode is bad mmkay This isn t a forge issuse though I could optimize it to use a single array as you said but this has nothing to do with items blocks in the mods Buildcraft needs to get there items out of the range,Unsure
8745,issue,[Feature] Display user name without @-annotation in upper-left corner,Feature Display user name without in upper left corner In the upper left corner the current user s picture as well as the user name is displayed The is not familar for non tech people Hence it looks unprofessional for business people We should add an option that displays the real name in the upper left corner like it is already implemented for channels property criteria Make use of the property UI Use Real Name in the upper left corner as well,Oh I just found another issue which already indicates this topic close,Unsure
692,pr,Secret/key encryption,Secret key encryption Resolves Getting an early PR out for feedback,ship,Yes
801,pr,Fix no users being allowed to login when `accept_roles` set.,Fix no users being allowed to login when accept roles set Thanks for submitting a pull request Please make sure you ve read and understood our contributing this is a bug fix make sure your description includes fixes xxxx or closes xxxx where xxxx is the issue number Please provide enough information so that others can review your pull request The first three fields are mandatory Summary The actual code was invalid here I haven t done much work with yet so I don t completely understand the code but this looks like the right place to put it Fixes Test plan Logging into both with and without seems to work normally Description for the changelog Fix no users being allowed to login when set A picture of a cute animal not mandatory but encouraged,already reviewed so this should be good to merge,Yes
2836,issue,I just convert MVC authentication to vb & login page not loading properly ,I just convert MVC authentication to vb login page not loading properly x I read and understood how to enable Question Issue Relevant parts of the log file,,Yes
276,pr,Add ssl query string to the connection string parser #275,Add ssl query string to the connection string parser This commit only addresses the issue in which looks like it will boil up to the JavaScript client A quick look at the native client shows that it s using but I don t know enough about that part of the project to determine if that will make a difference there,I wasn t sure if I should use or something more standard like It looked like the code wasn t using sslmode though so I didn t want to specify something in the connection string that couldn t be backed up by the code,Yes
1893,issue,"Repetetive ""Sorry, something went wrong with adding the app"" when trying to deploy assets via SPFx-solution(s)",Repetetive Sorry something went wrong with adding the app when trying to deploy assets via SPFx solution s I m facing repetitive issues when trying to deploy SharePoint assets via PSPFx solution s It seems that provisioning Fields and Content Types works fairly stable but as soon as a List Instance is added and especially when specifying a CustomSchema the App Installation ends up with an indescribable error message Sorry something went wrong with adding the app I have tried both in SPFx Application Customizer s and Client Side Web Parts but to no avail Have someone else been experiencing the same issues and could perhaps share some experiences regarding this matter Document Details Do not edit this section It is required for docs microsoft com GitHub issue linking ID c b c c bc d bb efb e Version Independent ID ad d e f d d d b d Content Provision SharePoint assets from your SharePoint client side web Content Source Service unspecified Product sharepoint GitHub Login Microsoft Alias spdevdocs,I hace the exact same issue This doesnt work double checked all code Also tried ship Nothing Get the same error Update Got mine working no problem now I tried customising first so clearly something wrong in what I did in the Schema perhaps So I deleted everything and copied the code EXACTLY as above Used ship as well and working I m going to reproduce my st attempt have an idea of what could be happening Ok so here s what I ve found I got it all working nicely with my own fields etc with and without ship Once working though was a very painful excercise to try and reproduce the error again I made minor adjustments until I found the culprit Elements xml This works Field ID E AC E C D C B F DE BCAC F This breaks it Field ID ec e d f b b f b df i e For me specifically lowercase field ID s in the Elements xml file cause the error For reference I uploaded my files here a publishing hyperlink field choice field and number field Thanx for the feedback This was not the cause of the error in my case I m afraid For some reason an unintentionally character had sneaked its way in the schema xml definition It took a lot of effort to find the culprit and I m kind of surprised that VS Code did not identify this character as an invalid attribute in the XML and give me a warning at least I m closing this issue as it regrettable was my own fault Still facing the issues related to regarding getting the correct Content Type to appear in the New Menu for the list library The fields and Content Type are provisioned correctly to the site but seem to be improperly connected to the list Thank you it has fixed the issue for me Issues that have been closed had no follow up activity for at least days are automatically locked Please refer to our wiki for more details including how to remediate this action if you feel this was done prematurely or in error Issue List Our approach to locked,Unsure
1551,issue,Alamofire 4.0.0 memory leaks with uploadProgress and downloadProgress,Alamofire memory leaks with uploadProgress and downloadProgress Hi I think that I have identified a memory leak when I am using uploadProgress or downloadProgress in my code Here is the code example that is generating memory leak If I don t use uploadProgress I don t have memory leaks and all my objects are correctly deinit But I want to know the progression of an upload I find a way to avoid this problem in Alamofire In UploadRequest I have replaced uploadProgress with this one After that memory leaks disappeared I think the same thing could be done with downloadProgress I want to open issue on this because I am sure that my solution is not the the good one,I ve encountered a memory leak in AlamofireImage and found the leak is linked to the Request validate method If I remove the validate the memory leak disappears The validate leaks appear related to Validate swift building closures while capturing strong self e g lines These need changing to unowned self or refactored for weak self For example Around Validation swift Line Suggested change There are several of these throughout the code that need to be handled Thank you everyone for all the detailed information is certainly correct The core issue stemmed from the validation closures not marking each internally stored closure as I ve pushed b ae c into which will be released shortly that addresses the issue Validation no longer causes the request to leak Also the and progress APIs do not cause any leaks Background To give a bit of backstory any closure that executes on the TaskDelegate s operation queue MUST capture a reference to Without this the will actually be deallocated before the closure can be run which will result in no ops for things like response handlers The reason for this is that once the completes Alamofire no longer holds a strong reference to the It is released by the as soon as the task completes This behavior is slightly different when using a but let s assume for now you re not using one Once the task completes the s internal operation queue is resumed and the is released by Alamofire The only thing still holding a reference to the at this point is any closure that was dispatched onto the operation queue GCD holds onto the operation queue dispatch queue underneath until all the closures on the queue have completed Then GCD will cleanup the queue which is roughly the same time the will be deallocated Alamofire In Alamofire we moved all validation to be stored directly by the so we can run validations off the operation queue This allows us to support the before actually starting the internal operation queue in case we need to retry the request before running the response handlers The mistake we made when we did this was that we forgot to mark the validation closures as so that we wouldn t create a retain cycle The changes in b ae c remove the retain cycle We ll look to get this fix deployed as soon as possible Thanks again everyone for all your help here Cheers The problem still exists I am getting leaks If I validate the requests The leak is gone If I remove the validation part,Yes
1767,issue,icon-hash,icon hash it would be nice have icon hahs,dup of please that request closing here,No
3125,issue,[SUGGESTION] Add option to enable browser fingerprinting defenses ,SUGGESTION Add option to enable browser fingerprinting defenses Describe the issue Tom added an option to enable browser fingerprinting defenses by setting with the goal that privacy tools can toggle it on and take advantage of the work we ve been doing This has been added for Firefox so it s not until that time that one can take advantage of this Also see his patch,Personally I believe this is best left until it is more mature at the very least It will get an option in the preferences UI anyway hopefully with a Learn more link The target AFAIK is for since the next TBB will be based on ESR If you add it then due diligence means keeping up to date with the changes it causes and providing some info and there is a LOT including conflicts with existing prefs and a LOT more to come I would leave this in Mozilla s hands For an idea of the scope of explaining this to people see for an idea of how this can conflict with existing prefs and alter your intended fingerprint see looks like it will change from boolean to integer as will privacy resistFingerprinting privacy firstparty isolate where off on global and pb mode windows only see and so be aware of that Edit I meant as will privacy firstparty isolate Duplicate of,Yes
1986,pr,Abstract azure storage / inject abstraction into ImageService and TaskAttachmentService to make them testable,Abstract azure storage inject abstraction into ImageService and TaskAttachmentService to make them testable ImageService and TaskAttachmentService have a lot of repeated code but the most important elements of those classes is there is no way to test we re building the correct paths to the azure blob storage or in the case of ImageService there is no way to test the exception that will be thrown when trying to upload an image extension we don t support although I think this should be done in the Model validation in the controller not in the ImageService itself I ve added an IBlobStorage BlobStorage implementation which encapsulates the calls to the azure api which should not require testing and now both ImageSerive and TaskAttachmentService have IBlobStorage injected We ll see if the IBlobStorage API abstraction holds up against future needs for azure storage types and how AllReady will need to work with those types For now I consider this a step in the right direction,since I don t see WIP in the title I will assume this is good to go and merge later today let me know if otherwise I smoke tested all the changes against real azure blobs and everything works so you can merge this PR whenever you want I didn t tag anyone for a code review b c I figured it s not a very interesting change,Yes
3078,pr,Fix race conditions when an RLMRealm is deallocated from the wrong thread,Fix race conditions when an RLMRealm is deallocated from the wrong thread The runloop notification source needs to hold a strong reference while the block is running and a zeroing weak reference the rest of the time to handle being called from a different thread Similarly RLMNotificationHelper needs a zeroing weak reference to the RLMRealm because the SharedRealm can outlive the RLMRealm and then crash when it tries to deliver a notification to the RLMRealm The reads of the weak pointer are in autoreleasepools because ARC autoreleases pointers when acquiring a strong reference to a weak pointer Fixes,Any chance of a test case that reproduces or does hitting the issue involve too much luck with timing I don t have any idea how to meaningfully test it deterministically and the time to hit a crash the brute force way varied from a few seconds to a few minutes,Yes
509,pr,Make PFDeviceSysctlByName more safe and easy to maintain,Make PFDeviceSysctlByName more safe and easy to maintain Changes made according to the comments in,Looks better love that we are using proper encoding not a big fan of goto Deferring to Getting much closer Let s see if we can avoid using here as it has one major con with our usage Undefined behavior with ARC enabled If ARC is enabled and you use a statement with an ARC managed variable in scope it s undefined whether or not ARC will properly clean up that variable In this particular case we never have a variable who s scope gets improperly exited but I m still not a fan of using with ARC because of the maintenance issues involved Can we change this into a loop and just in error cases Remember that its well defined behavior to call so I think it will create much cleaner code in the end It is definitely better to use instead of in the mixed objective c code I have updated the code Please double check the code before we can merge this Love it when you have a chance to look it over merge me up scotty Aye captain energizing,Yes
8092,issue,Password manager prompt for ProtonMail encrypted mail,Password manager prompt for ProtonMail encrypted mail Have you searched for similar issues Before submitting this issue please check the open issues and add a note before logging a new issue PLEASE USE THE TEMPLATE BELOW TO PROVIDE INFORMATION ABOUT THE ISSUE INSUFFICIENT INFO WILL GET THE ISSUE CLOSED IT WILL ONLY BE REOPENED AFTER SUFFICIENT INFO IS PROVIDED Description When a password is entered for a ProtonMail encrypted message Brave s password manager prompts to update the ProtonMail account password Steps to Reproduce Compose new message Select Encryption Encrypt for non ProtonMail users Enter password confirm and Set Brave password manager prompt may take several seconds to appear requesting if the user would like to update their stored ProtonMail account password with the password that was set on the message Actual result Brave password manager prompt appearing to update the account password Expected result No prompt to update the account password Reproduces how often Easily reproduced Brave version brave version info Version Chromium Official Build bit Version Channel Information Can you reproduce this issue with the current release Yes Can you reproduce this issue with the beta channel Untested Can you reproduce this issue with the dev channel Untested Can you reproduce this issue with the nightly channel Untested Other Additional Information Does the issue resolve itself when disabling Brave Shields No Does the issue resolve itself when disabling Brave Rewards No Is the issue reproducible on the latest version of Chrome Yes tested in VirtualBox and Linux Mint Cinnamon Miscellaneous Information Linux Mint Cinnamon Brave keyring in use,,Yes
2077,pr,fixes #8925 - support plugin asset manifests beneath app root,fixes support plugin asset manifests beneath app root This supports Debian packaging where storing the assets manifest yml beneath the gem installation directory isn t possible as bundler manages gem installations Instead support loading so plugin manifests can be packaged under the main Foreman root,Merged as d f c d a e f cd e be e thanks Tested by precompiling assets myself without the PR to generate the general manifest yml then creating public assets foreman docker manifest yml and move the relevant part from the general manifest yml there and checking that it s read by the after initialize script,No
1970,pr,Don't percent-encode non-ASCII characters in fragments,Don t percent encode non ASCII characters in fragments Fixes,lgtm,Yes
4932,issue,switching between secure and insecure persists between contacts,switching between secure and insecure persists between contacts I have a few contacts that still have Signal installed in hopes of bugs like being resolved but do not prefer Signal for their daily driver until the application is usuable for them Which for users that are experiencing this iOS bug the application is insanely frustrating to use Signal rightfully defaults to messaging being secure However when I switch to insecure for this contact move to another contact the method of delivery is still insecure This is also true the other way around If I switch that contact back to secure and then go to the contact that prefers insecure iMessage conveniences etc then the delivery is set to secure Steps to reproduce Open Signal contact A send insecure message Open Signal contact B message defaults to insecure Change delivery of message for Signal contact B back to secure Switch to Signal contact A message delivery now set to secure due to action in step I would like to see a per conversation or per contact preference for delivery of secure vs insecure An additional remind confirm insecure messages in x days hours would also be awesome,I m unable to reproduce with those steps Nexus stock For Signal contacts the app always uses Signal messages unless you change by long pressing the attachment send button And then when you exit the conversation and come back it will automatically change to Signal messages again Can you post a debug log after the steps After the latest update I m unable to reproduce it using the steps I indicated before However the feature to change the default delivery per contact would be immensely helpful If this happens again I ll comment on this issue with a debug log Thanks Thanks closing for not reproducible any more Default delivery option is a dupe of This behavior was observed again Debug log please reopen Can you reproduce this consistently with the steps in your first post At a high level the steps are still the same It s happened a few more times In addition to the original steps to reproduce could you try these Open Signal contact A send insecure message Receive message from Signal contact B Tap on notification to go to received message from Contact B Change delivery of message for Signal contact B back to secure Receive message from Signal contact A Tap on notification to go to received message from Contact A Message delivery now set to secure due to action in step All right I can definitely reproduce a bug with the transport mode now Open conversation with Signal contact A Long press send button and change to SMS transport you don t have to send anything While you are in the conversation with A receive a Signal message from Signal contact B Tap the notification to open the conversation with B Observe that the transport mode is SMS should be Signal Alternative to step is to press the Android home button or the app switch button to leave the conversation with A and then receive a Signal message from Signal contact B Nexus Huawei U Could this be One of my contacts is on Signal but he has decided to not purchase data plan for now Signal insist I send him secure message which will of course not reach him It s a design flaw that Signal thinks that once you become a Signal user you will always have access to it and it gives Signal authority to override user choice If I have switched to unencrypted channel then Signal should honor my choice until I choose to I second had a friend try out Signal on her iPhone but when I found out that she isn t able to use Signal for regular SMS conversations as I am able to on Android I had her remove Signal So this means that Signal was installed on her iPhone we sent a message or two then she uninstalled it I say this fully understanding that it s IOS that doesn t allow rd party apps to manage SMS messages and not the fault of Signal I can send her regular SMS messages through my Signal app but it keeps defaulting back to Signal messages when I exit the conversation So every time I want to have a conversation with her I have to long press the send button and set it back to Insecure SMS This isn t very user friendly and as stated I believe that it is a design flaw to assume that just because Signal may have been associated with someones number once it doesn t mean they will always have it A per conversation setting that allows the user to set the default message mode with explicitly clear wording around what changing the default message mode means for security would be a very useful feature to have Steps to reproduce the usability issue I mentioned above Open a conversation with a contact Long press send attachments button Select Insecure SMS option Tap back or hit the back button at the top of the conversation window Open the conversation from step Note how the app has defaulted back to the Signal option Every time I have a conversation with my friend that uninstalled Signal I need to select Insecure SMS again EDIT Just read the referenced closed case and can understand the reasoning for not having an explicit option to change the delivery method I do not anticipate my friend installing Signal again so I must long press the send attach button to change the channel every time I talk to her This seems like an unnecessary hurdle I still insist that having Signal remember the last delivery method you selected on a per conversation basis would make this app significantly easier to use There are enough cues in the UI indicating that messages are insecure that I do not believe this will have any significant impact on the secure by default approach Thoughts That s currently expected behavior This is a different issue The issue you are describing is tracked at Thanks This is still an issue on Android and it s very frustrating and is almost forcing me to stop using Signal This seems like a very simple fix to make the setting persist is there no work being done on this I m unable to reproduce this I tried these steps from Open conversation with Signal contact A Long press send button and change to SMS transport you don t have to send anything While you are in the conversation with A receive a Signal message from Signal contact B Tap the notification to open the conversation with B For me all I have to do is open a conversation with a Signal user change to insecure SMS and then back out of the conversation view then it will have reset as I go back in again This makes it really inconvenient to message people who aren t using the app any longer since they can t see my text messages That s not what this issue is about This is referring to the opposite situation where changing to insecure SMS persists that setting when communicating with other contacts I m going to close this as fixed but please reopen if it s still an issue sorry about that I must have misunderstood the issue from the description Is there an equivalent bug where the issue I described is being tracked Edit saw it mentioned previously in the conversation please ignore my question,Yes
1731,issue,页面刷新或重定向后路由中的hash会丢失,hash location href location hash token jhkjczx App vue App Launch App Show location href location href location hash token jhkjczx App vue location href location hash token jhkjczx h history uni simple router hash,,Unsure
16,issue,Maybe make YAML parsing safer,Maybe make YAML parsing safer Need to make sure this doesn t interfere with preloaded code though,,Yes
26795,issue,salt-cloud gives AttributeError: 'module' object has no attribute '_create_loader',salt cloud gives AttributeError module object has no attribute create loader Hi there I m having an issue with salt cloud in and Just running salt cloud or salt cloud m path to map file conf throws Here are my versions Any Idea,I forgot to mention that the salt cloud version I have is salt cloud I fixed it uninstalling it was an odd version I had setup with easy install and re installing it using apt get I have the proper version now salt cloud Lithium,No
755,issue,Is it possible to access the contenthash within a JS file?,Is it possible to access the contenthash within a JS file I have to implement a react component inside a web component don t ask in which I want to reference a bundled CSS file Like this index js Unfortunately or luckily actually the CSS file is hashed but is there a way to know the hash from inside a js file,How is this related to the html webpack plugin Sorry because I am using the html webpack plugin and does it not hash my files sorry noob alert No that is done by webpack Ok thank you This issue has been automatically locked since there has not been any recent activity after it was closed Please open a new for related bugs,Yes
25013,issue,Multiple instances of salt-minion -d,Multiple instances of salt minion d if salt minion d is run multiple times on the same machine then a duplicate process will be created When the salt master runs a command on the minions it will run once for each instance of salt minion d Ideally the salt minion d command would kill the previous daemon and then start up again else see that there is already a daemon running and not create a new instance,Thanks for the bug report Hi There are legitimate cases of a person wanting to have salt minion procs in a process list when having another salt minion start Some multi tenent virtualization platforms or people using oddball deployments where they really do intend to have multiple minions running inside a single OS I can t however think of a reason offhand that we couldn t check a pidfile Unless we come up with a good reason that isn t viable I think this ought to be the way we go here OK we re good to go with Marking as Fixed Pending Verification,No
447,issue,Better errors from .validate method.,Better errors from validate method Currently if validation fails the error object seems to always be It would be nice if the would return something besides a maybe so that if the validation failed because of a the error object given to the response handler might have a description of Invalid Status Code File Not Found,Is there also a way to capture the body content of a failing request With the code above when an error happens is meaningless and json is nil At least we have access to the statusCode Is this by design EDIT My bad this is caused by Alamofire SwiftyJSON After thinking about this I think by design to the keep the type easy to understand and create The client should write their own error messages On the other hand it would be nice to know which Validator failed just to narrow down what the issue could be So I have been working with an API that sends HTML error pages when it fails This is useful debugging information for me so I ve been using both and completionHandler See example below I just realized I haven t actually commented on this issue Sorry for that gents to your original question yes it would be nice to have a more verbose error system We should have some better error handling logic around validation and anywhere else we can possibly throw an error Since this will be a fairly large breaking change we ve slated this for the release We would also like to incorporate the new error handling logic from Swift to make this process as simple as possible to use I ve only read about but haven t used Swift s new way of handling errors but it reminds me of Java exceptions In Java exception handling is rather expensive and can really interrupt the code flow so it should only be used for very uncommon some would say exceptional circumstances Since APIs can use status codes to represent common errors like invalid login credentials I don t know if the using the new syntax for error handling would be appropriate It maybe considered premature for me to voice this concern since I haven t played around with the new error handling But I wanted to voice my concerns earlier than later after playing with the new error handling maybe my concern will be invalidated I think I ll have to update my most popular Stack Overflow soon From the WWDC talk on What s New in Swift But it means that you don t have to worry about our error handling feature being so expensive that you can t use it in order for the actual reasons that you need to if you do need to care about the efficiency of the error path Sounds like they were careful to avoid the huge performance hits like you see with Java Thanks I ll take a look Hey everyone I just pushed up PR which adds much better support for validation error handling If you could check it out and leave some feedback I d really appreciate it Please redirect all further comments to that issue since I m going to close this one out Cheers,Yes
1689,issue,App crashing with encryption turned on,App crashing with encryption turned on I m getting error A art art runtime fault handler cc Check failed initialized When using realm encryption on Android,Which device Can you please post a full log here Nexus OTA Android Unfortunately that s was the only line of the log It crashes when the Realm opened Could it be easily reproduced How It crash about seconds after Realm opened There are no stack trace or SIGSEGV type of error message at all I tested with HTC M Android No errors We are working on new implementation of encryption right now which should solve this problem as well I will update this issue when that is done I have the same problem when using realm encryption on Android M And device not print error log on account password qqqqqq Hello We are working on new implementaion yet I think it already fixes this problem But we need more testing and optimization to release this We will update this soon have this been fixed We are optimizing and testing the new encryption implementation now And it will be released recently We are having the same issue Also on a Nexus with Android installed What is the status of this issue Realm java released which has a new implementation of encryption believe this problem should be fixed in the new release If you still can reproduce the issue feel free to reopen this issue Thanks everybody,Yes
14901,pr,Update enforcing-ssl.md,Update enforcing ssl md Fixes,,Yes
154,issue,Deserialize from stream introduces a serious vulnerability due to shared buffers,Deserialize from stream introduces a serious vulnerability due to shared buffers I have encountered an issue when implementing error handling for malformed json in my web application instead of unexpected end of string I was getting error messages with unexpected char that was not even in the json After some digging I discovered an exploit that enables an attacker to read data from previously serialized objects This exploit can be used to target any web application that uses the MVC formatters in this repository or parses json from stream using this library The example below illustrates the issue This issue is caused by sharing buffers that are never cleared and could be solved by clearing the buffers or by passing the length to the reader in adittion to the buffer There is already an issue regarding this months old but it does not mention the security impact especially for web applications using the formatters,it seems serious too me,Yes
341,issue,Oracle - Cannot generate explain plan as non admin user due to insufficient privileges (but TOAD can),Oracle Cannot generate explain plan as non admin user due to insufficient privileges but TOAD can If you try to get an explain plain using a non admin user DBeaver raises an Insufficient privileges error and does not output if I try to get the eplain plan for the same query using the same user in TOAD the explain plan is calculated are listed all the user permissions from USER ROLE PRIVS USER SYS PRIVS and USER TAB PRIVS are empty for the given user GRANTED ROLE ADMIN OPTION DEFAULT ROLE OS GRANTED UTE READ NO YES NO,Can t reproduce that Please post error with stacktrace Hi Serge here you can find the output of the log SESSION eclipse buildId unknown java version java vendor Oracle Corporation BootLoader constants OS win ARCH x WS win NL it Command line arguments os win ws win arch x ENTRY org jkiss dbeaver model MESSAGE org jkiss dbeaver model exec DBCException Errore SQL ORA privilegi insufficienti SUBENTRY org jkiss dbeaver model MESSAGE DBCException Errore SQL ORA privilegi insufficienti STACK org jkiss dbeaver model exec DBCException Errore SQL ORA privilegi insufficienti Caused by java sql SQLSyntaxErrorException ORA privilegi insufficienti SUBENTRY org jkiss dbeaver model MESSAGE SQLSyntaxErrorException ORA privilegi insufficienti STACK java sql SQLSyntaxErrorException ORA privilegi insufficienti The insufficient privileges is due to the query in this screenshot the user has no delete permission in this Try to change plan table Preferences Database Drivers Oracle change Plan table to some existing and accessible plan table E g TOAD PLAN TABLE TOAD creates it on demand Hi Serge I changed the table in order to use the one created by TOAD TOAD TOAD PLAN TABLE and it works Thanks a lot sunglasses,Yes
36626,issue,Editor: Posts page not being password protected ,Editor Posts page not being password protected Steps to reproduce WordPress com Site Pages Add new Add title Publish Mark as password Protected Update WordPress com Design Customize Homepage settings Select static page Select Home from dropdown Select password protected page as posts page Publish What I expected When I visit the posts page from the front the page should be password protected and I should see a field to enter in the password What happened instead Content was visible Browser OS version All browsers Screenshot Video n a Context Source Please see hc The expectation here and rightly so was to password protect the posts page as this is the flow that they followed to do this Instead this isn t the case This particular user wanted to password protect the post page and keep other pages visible so marking the whole site as private isn t an option and individually marking posts as private is time consuming for the user They also expressed concerns about using the same password for each post or different passwords and keeping track of them all Feature suggestions Make posts page password protectable Remove the ability to make posts page password protectable under the Publish tab,,Yes
4713,issue,Update security/authorization/resourcebased to 2.0,Update security authorization resourcebased to Update content to ASP NET Core UE edit Follow MVC writing style Address Livefyre questions Address customer verbatim The document is incomplete missing code and steps thus making it difficult to understand,Some of the updating was handled in,Yes
143,pr,Master based base64url decode padding fix,Master based base url decode padding fix small fix for error in Base Url Decode with padding missing for the result of modulo Compiled JWT project in VS Mac and on Windows in VS and with Cake Green Could not run Cake on Mac and XUnit tests in VS Mac Red,My mistake did not read specs properly Closing,Yes
1377,issue,Connection count leak,Connection count leak Somewhere in our program we have a connection counter leak There are no open connections but throws too many connections exception I cannot exactly reproduce the problem but looking at the code I see at least one issue in function If throws an exception after for example in then counter is leaked,for example in asyncHandlerExtensions onHostnameResolutionAttempt name I m very tempted to document that one is NOT supposed to throw Exceptions in AsyncHandlers and just swallow and log them instead of trying to deal with such mess and report them in the Future onThrowable Anyway thanks for reporting but except for the potential problem with and friend I really can t do anything without a reproducer Please ping if you manage to create one I m very tempted to document that one is NOT supposed to throw Exceptions in AsyncHandlers Nobody is safe against stupid errors like But blaming users for throwing unexpected exceptions you make library very dangerous to should properly handle those exceptions not document it,Yes
487,issue,Completion for ssh-copy-id,Completion for ssh copy id Completion for ssh copy id is not shown on ssh user input completes to ssh copy id successfully,Thanks Fixes Will be ok in next version,Yes
19645,issue,ActiveModel - insecure defaults?,ActiveModel insecure defaults I came across an interesting problem which could be categorized as insecure defaults When using for example string fields on user model such as name no one expects that it would contain newlines but they are allowed in most cases without using full regex validations for correct me if I am wrong but that allows to use newlines in user s name That could cause broken page layout in best case evil user or if you are trying to export something containg user data i e recent transactions a broken file that s the one that made me think about this problem There is no validation to ensure that no newlines are used I propose to add a allow newlines validation or disable newlines if db field is of string type and not text,You re right that unless you make a validation strings can contain characters you might not be expecting like newlines The validation you re proposing already exists in a more general form It s the The example provided in the guide prevents newlines as well as any character other than A z I think that this not being the default ends up being less of an issue than you might think because of two things First if the form field is a normal text input not text area then the newlines will automatically get removed by the browser That doesn t prevent users from posting data that has newlines though so if you need to be certain it won t contain newlines you should create a validation and maybe also a database level constraint if you need to be absolutely certain Second even if the field has newlines in it since whitespace in HTML is generally ignored it will show up as a space instead of a newline when displaying later unless you use something like that replaces newlines with tags It might be nice to have an option but I think if you want to exclude newlines it is likely you also want to exclude other whitespace too so you should probably just use a validation to specify exactly what characters you do want but I think if you want to exclude newlines it is likely you also want to exclude other whitespace too so you should probably just use a format validation to specify exactly what characters you do want Agree While I don t think it would ve mattered here in future if you re creating an issue and feel the title should contain the word insecure please strongly consider applicability of,Yes
4185,pr,Move UserPasswords to scrypt,Move UserPasswords to scrypt This PR Makes scrypt the default password storing function The scrypt gem has sane defaults with MB memory requirements per default so we don t have to re configure it Make available only for existing passswords They will still be valid however as soon as a user logs in the password is re hashed as scrypt This allows us to keep the expiration time the same no longer has the functionality to create save new passwords Warning exclamation The introduced migration has to delete passwords when migrating down since otherwise using the application will croak for scrypt passwords I don t think we should easily remove the passwords in the down migration so If you have a better solution let me,I ve prepared a stage to preview changes Open stage or view logs I will continue this after,Yes
12808,issue,Destroy reliable topic memory leak OOME hprof,Destroy reliable topic memory leak OOME hprof I was just trying to reproduce the topic issue described in the community channel as I got OOME from the members the hprof is i was creating topics using and destroying and it results in OOME the main difference to the usual create use destroy test i run is before I would operate on the same topic over and over where as in this latest fails test I create use and destroy a topic with a random name each time when we destroy a structure do we intentionally keep some small amount of data state about it in the cluster Matko Medenjak we aren t supposed to I ll take a quick look at the heap dump looks like we keep the ringbuffers so this might be a bug,Datastructures are difficult to destroy in HZ because they are automatically recreated So if you have some kind of operation interaction with a data structure previously destroyed it will be recreated And since you are using random names you can get a build up of recreated data structures This is nothing new I m failing to see the added value for this family of tests since the underlying issue is known do you have the test code somewhere The directory in the link does not contain it We even have a unit which asserts that the ringbuffer is cleaned up when the reliable topic is destroyed which makes this failure a bit strange I m not sure how ringbuffers were retained in your test I also ran code similar to a create use destroy pattern And I can t see a leak so i have the same simple code mabey the difference is running on a members and clients on members and clients using a member client setup if i run just from Member i do not see the OOMe if i run just from client I see the OOME if i run from member and client i also see the OOME Yes looks like there s a leak in client code and it s pretty simple to fix the fix for reliable topic was merged please retest after fix was merged I can not reproduce the Member OOME,Yes
895,pr,ByteBuffer docs: gets are safe,ByteBuffer docs gets are safe Motivation ByteBuffer s get methods are now safe docs claimed they were unsafe though Modifications Document the gets as safe Result More correct docs,,Yes
384,issue,Unable to parse multiple times when urlencoded-body-parser is used,Unable to parse multiple times when urlencoded body parser is used Unable to call both urlencoded body parser and in the same request The error varies depending on the order,,Yes
10225,issue,An OPTION to change app display name while resigning.,An OPTION to change app display name while resigning New Issue Checklist x Updated fastlane to the latest version x I read the Contribution x I read x I searched for existing GitHub Issue Description Complete output when running fastlane including the stack trace and command used You can use as the last commandline argument to get that collected for you INSERT OUTPUT HERE Is there a way to change app display name post re signing If yes how If no can you please add that feature as an OPTION ONLY in your next release ONLY if we want to change we can Add this feature to off course Thanks Environment Please run and copy the output below This will help us help you If you used option please remove this block as it is already included there INSERT OUTPUT HERE,It seems like this issue might be related to code signing no entry sign Have you seen our new Code Signing Troubleshooting It will help you resolve the most common code signing issues It seems like you have not included the output of To make it easier for us help you resolve this issue please update the issue to include the output of Sorry that seems very specific and probably not something we want in the fastlane code base for now however feel free to build a plugin or location for this Try adding the feature of signing the app bundle app file at least That d be extremely useful Do oblige Thanks There hasn t been any activity on this issue recently Due to the high number of incoming GitHub notifications we have to clean some of the old issues as many of them have already been resolved with the latest updates Please make sure to update to the latest version and check if that solves the issue Let us know if that works for you by adding a comment This issue will be auto closed because there hasn t been any activity for a few months Feel free to open a new if you still experience this problem,Yes
10657,issue,[QUERY] DefaultAzureCredential authentication failed ,QUERY DefaultAzureCredential authentication failed Query Question I am not sure if this is a bug or not or even belongs here The reason I am posting here is the stack trace from the kudu console We are using key vault secrets with config builders to update our web config during pre application start initialisation Environment Name Version used in current Azure AppService KeyVault Azure AppService targeting net We have followed a couple of how tos We have set up the system assigned managed identity and have given the managed identity RBAC role read to the keyvault and applied the access policy to secrets Get List When looking at Azure Diagnostics on the key vault we see the Authentication event is successfult but then receive the and the following stack trace Unfortunately the we cannot get any more information that this If this is the wrong place I hope someone can point us in the correct direction We do have a support ticket open with Azure support but because we cannot move forward with our test cycles I am hoping to find some insight Here is the following stack trace methods Func methods at System Web Compilation BuildManager CallPreStartInitMethods String preStartInitListPath Boolean isRefAssemblyLoaded at System Web Compilation BuildManager ExecutePreAppStart at System Web Hosting HostingEnvironment Initialize ApplicationManager appManager IApplicationHost appHost IConfigMapPathFactory configMapPathFactory HostingEnvironmentParameters hostingParameters PolicyLevel policyLevel Exception appDomainCreationException An error occurred creating the configuration section handler for connectionStrings Error in Configuration Builder KeyVault GetAllValues D home site wwwroot web config line at System Configuration BaseConfigurationRecord EvaluateOne String keys SectionInput input Boolean isTrusted FactoryRecord factoryRecord SectionRecord sectionRecord Object parentResult at System Configuration BaseConfigurationRecord Evaluate FactoryRecord factoryRecord SectionRecord sectionRecord Object parentResult Boolean getLkg Boolean getRuntimeObject Object result Object resultRuntimeObject at System Configuration BaseConfigurationRecord GetSectionRecursive String configKey Boolean getLkg Boolean checkPermission Boolean getRuntimeObject Boolean requestIsHere Object result Object resultRuntimeObject at System Configuration BaseConfigurationRecord GetSection String configKey at System Configuration ConfigurationManager GetSection String sectionName at System Configuration ConfigurationManager get ConnectionStrings at EnvSettings SettingsUtils SetConnectionString String name String connString String providerName at EnvSettings SettingsUtils ApplyEnvironments at EnvSettings SettingsProcessor Start Error in Configuration Builder KeyVault GetAllValues at Microsoft Configuration ConfigurationBuilders KeyValueConfigBuilder EnsureGreedyInitialized at Microsoft Configuration ConfigurationBuilders KeyValueConfigBuilder ProcessConfigurationSection ConfigurationSection configSection at System Configuration ConfigurationBuilderChain ProcessConfigurationSection ConfigurationSection configSection at System Configuration RuntimeConfigurationRecord RuntimeConfigurationFactory CreateSectionImpl RuntimeConfigurationRecord configRecord FactoryRecord factoryRecord SectionRecord sectionRecord SectionInput sectionInput Object parentConfig ConfigXmlReader reader at System Configuration RuntimeConfigurationRecord RuntimeConfigurationFactory CreateSectionWithRestrictedPermissions RuntimeConfigurationRecord configRecord FactoryRecord factoryRecord SectionRecord sectionRecord SectionInput sectionInput Object parentConfig ConfigXmlReader reader at System Configuration RuntimeConfigurationRecord CreateSection Boolean inputIsTrusted FactoryRecord factoryRecord SectionRecord sectionRecord SectionInput sectionInput Object parentConfig ConfigXmlReader reader at System Configuration BaseConfigurationRecord CallCreateSection Boolean inputIsTrusted FactoryRecord factoryRecord SectionRecord sectionRecord SectionInput sectionInput Object parentConfig ConfigXmlReader reader DefaultAzureCredential authentication failed at Azure Identity DefaultAzureCredential d MoveNext End of stack trace from previous location where exception was thrown at System Runtime ExceptionServices ExceptionDispatchInfo Throw at System Runtime CompilerServices TaskAwaiter HandleNonSuccessAndDebuggerNotification Task task at Azure Identity DefaultAzureCredential GetToken TokenRequestContext requestContext CancellationToken cancellationToken at Azure Security KeyVault ChallengeBasedAuthenticationPolicy d MoveNext End of stack trace from previous location where exception was thrown at System Runtime ExceptionServices ExceptionDispatchInfo Throw at System Runtime CompilerServices TaskAwaiter HandleNonSuccessAndDebuggerNotification Task task at Azure Security KeyVault ChallengeBasedAuthenticationPolicy d MoveNext End of stack trace from previous location where exception was thrown at System Runtime ExceptionServices ExceptionDispatchInfo Throw at System Runtime CompilerServices TaskAwaiter HandleNonSuccessAndDebuggerNotification Task task at Azure Security KeyVault ChallengeBasedAuthenticationPolicy Process HttpMessage message ReadOnlyMemory pipeline at Azure Core Pipeline RetryPolicy d MoveNext End of stack trace from previous location where exception was thrown at System Runtime ExceptionServices ExceptionDispatchInfo Throw at Azure Core Pipeline RetryPolicy d MoveNext End of stack trace from previous location where exception was thrown at System Runtime ExceptionServices ExceptionDispatchInfo Throw at System Runtime CompilerServices TaskAwaiter HandleNonSuccessAndDebuggerNotification Task task at Azure Core Pipeline RetryPolicy Process HttpMessage message ReadOnlyMemory pipeline at Azure Core Pipeline HttpPipelineSynchronousPolicy Process HttpMessage message ReadOnlyMemory pipeline at Azure Core Pipeline HttpPipelineSynchronousPolicy Process HttpMessage message ReadOnlyMemory itemFactory String operationName CancellationToken cancellationToken at Azure Security KeyVault Secrets SecretClient c DisplayClass b String nextLink at Azure Core PageResponseEnumerator FuncPageable d MoveNext at Microsoft Configuration ConfigurationBuilders AzureKeyVaultConfigBuilder GetAllKeys at Microsoft Configuration ConfigurationBuilders AzureKeyVaultConfigBuilder LazyInitialize String name NameValueCollection config at Microsoft Configuration ConfigurationBuilders KeyValueConfigBuilder EnsureInitialized at Microsoft Configuration ConfigurationBuilders KeyValueConfigBuilder EnsureGreedyInitialized Invalid response the authentication response was not in the expected format at Azure Identity ManagedIdentityClient Deserialize JsonElement json at Azure Identity ManagedIdentityClient Deserialize Stream content at Azure Identity ManagedIdentityClient Authenticate String scopes CancellationToken cancellationToken at Azure Identity ManagedIdentityCredential GetTokenImpl TokenRequestContext requestContext CancellationToken cancellationToken Thanks,cc and from what I can make out in your stack can you re paste that into dotnet nuget add source n AzureSDK dotnet add package Azure Security KeyVault Secrets version dev Rebuild your project Make sure the right DLL was copied to your output It should have the file version and product version dev a ee bffe c e a ea ea Please let me know if this solves your problem and we ll get a release out on nuget org Thank you We had one customer from the other verify the fix works so you can use that for now We want to do some additional to make sure we didn t regress anything and fixed all the related issues here and will get a servicing release out on nuget org shortly Hello apologies for the delay I had been distracted by another problem Deployed the new package and we are unfortunately observing the same error I verified the binary is being deployed and can see it being referenced in the latest Azure Diagnostics Can you verify you are seeing our pipeline trace messages in your diagnostics if not see my link to troubleshooting steps above and send my any events named Azure via email so we can diagnose further My email is my GitHub username,Yes
11488,issue,"MulticastDelegate.CombineImpl throws ""double free or corruption"" or ""pointer being freed was not allocated"" errors",MulticastDelegate CombineImpl throws double free or corruption or pointer being freed was not allocated errors Steps to Reproduce Run System ServiceModel or System ServiceModel Web tests seen it happen both on Linux ARMv and OSX x see stack traces below It occasionally crashes with the mentioned malloc errors Current Behavior From double free or corruption fasttop xf d f Stacktrace at at System MulticastDelegate CombineImpl System Delegate x c in home builder jenkins workspace test mono pull request armel mcs class corlib System MulticastDelegate cs at System Delegate Combine System Delegate System Delegate x f in home builder jenkins workspace test mono pull request armel mcs class corlib System Delegate cs at System ServiceModel Channels CommunicationObject add Closed System EventHandler x b in at System ServiceModel Dispatcher ListenerLoopManager c DisplayClass b object System EventArgs x in home builder jenkins workspace test mono pull request armel mcs class System ServiceModel System ServiceModel Dispatcher ChannelDispatcher cs at System ServiceModel Channels CommunicationObject OnOpened x f in home builder jenkins workspace test mono pull request armel mcs class System ServiceModel System ServiceModel Channels CommunicationObject cs at System ServiceModel Channels CommunicationObject ProcessOpened x in home builder jenkins workspace test mono pull request armel mcs class System ServiceModel System ServiceModel Channels CommunicationObject cs at System ServiceModel Channels CommunicationObject Open System TimeSpan x d in home builder jenkins workspace test mono pull request armel mcs class System ServiceModel System ServiceModel Channels CommunicationObject cs at System ServiceModel Channels CommunicationObject Open x in home builder jenkins workspace test mono pull request armel mcs class System ServiceModel System ServiceModel Channels CommunicationObject cs at System ServiceModel Dispatcher ListenerLoopManager ChannelAccepted System ServiceModel Channels IChannel x in home builder jenkins workspace test mono pull request armel mcs class System ServiceModel System ServiceModel Dispatcher ChannelDispatcher cs at System ServiceModel Dispatcher ListenerLoopManager c DisplayClass b System IAsyncResult x in Users builder jenkins workspace test mono pull request amd osx mcs class System ServiceModel System ServiceModel Dispatcher ChannelDispatcher cs at wrapper runtime invoke runtime invoke void this object object intptr intptr intptr x e in at at wrapper managed to native System Runtime Remoting Messaging AsyncResult Invoke System Runtime Remoting Messaging AsyncResult x in at System Runtime Remoting Messaging AsyncResult System Threading IThreadPoolWorkItem ExecuteWorkItem x in Users builder jenkins workspace test mono pull request amd osx mcs class corlib System Runtime Remoting Messaging AsyncResult cs at System Threading ThreadPoolWorkQueue Dispatch x in Users builder jenkins workspace test mono pull request amd osx mcs class referencesource mscorlib system threading threadpool cs at System Threading ThreadPoolWaitCallback PerformWaitCallback x in Users builder jenkins workspace test mono pull request amd osx mcs class referencesource mscorlib system threading threadpool cs at wrapper runtime invoke runtime invoke bool object intptr intptr intptr x b in Memory around native instruction pointer x fff dad x fff dad ff ff c b ca f H I x fff dad c e f ff ff c b c s H c L x fff dad ca f c e b f I s H K x fff dad ff ff c b ca f I I Native stacktrace mono x d e mono dump native crash info mono x cde f mono handle native crash libsystem platform dylib x fff bbb a sigtramp mono x f monoeg malloc libsystem c dylib x fff abort libsystem malloc dylib x fff ffe szone size mono x c ffe mini method compile mono x c c mono jit compile method inner mono x c b mono jit compile method with opt mono x c a mono jit compile method with opt mono x ce common call trampoline mono x ce mono magic trampoline mono x ce e mono aot trampoline x fb x mscorlib dll dylib x ada f System MulticastDelegate CombineImpl System Delegate x e f b x x e c x x e c x mono x c b d mono jit runtime invoke mono x e b do runtime invoke mono x e a ves icall System Runtime Remoting Messaging AsyncResult Invoke x e bc c x mscorlib dll dylib x ade d System Threading ThreadPoolWaitCallback PerformWaitCallback mono x c b d mono jit runtime invoke mono x e b do runtime invoke mono x e d worker callback mono x daae c worker thread mono x e e b start wrapper libsystem pthread dylib x fff c b pthread body libsystem pthread dylib x fff c pthread body libsystem pthread dylib x fff c d thread start Pkilling x d from x dcc Pkilling x fcf from x dcc Pkilling x bc from x dcc Pkilling x c from x dcc Pkilling x fffa e c from x dcc Pkilling x c from x dcc Pkilling x de from x dcc Pkilling x c from x dcc Pkilling x db from x dcc Pkilling x bd from x dcc Pkilling x d from x dcc Pkilling x e e from x dcc Pkilling x ba from x dcc Pkilling x d from x dcc Entering thread summarizer pause from x dcc Finished thread summarizer pause from x dcc Users builder jenkins workspace test mono pull request amd osx scripts ci babysitter Command timed out Users builder jenkins workspace test mono pull request amd osx scripts ci babysitter Saw timeout in test case MonoTests Features Serialization AsyncPatternTest TestAsync never allowed Will halt testing end System ServiceModel e mUnstable e m Expected Behavior No crash On which platforms did you notice this X macOS X Linux Windows Version Used master,Hmm looks like I see this in the Helix environment where I m working too though not in MulticastDelegate Maybe it s more remoting related X home helixbot dotnetbuild work f b c d a fc d bc Payload net x mono sgen double free or corruption fasttop x c b Backtrace lib i linux gnu libc so x a xf ad a lib i linux gnu libc so x dfc xf b fc lib i linux gnu libc so x e xf b home helixbot dotnetbuild work f b c d a fc d bc Payload net x mono sgen monoeg g free x x b f home helixbot dotnetbuild work f b c d a fc d bc Payload net x mono sgen mono bitset free x x f home helixbot dotnetbuild work f b c d a fc d bc Payload net x mono sgen x d x be home helixbot dotnetbuild work f b c d a fc d bc Payload net x mono sgen x f e x c e home helixbot dotnetbuild work f b c d a fc d bc Payload net x mono sgen x ea x cfa home helixbot dotnetbuild work f b c d a fc d bc Payload net x mono sgen x ee x cfe home helixbot dotnetbuild work f b c d a fc d bc Payload net x mono sgen xbfde x de home helixbot dotnetbuild work f b c d a fc d bc Payload net x mono sgen xc x xf ab xf dee xf e xf c c xf afc xf c xf xf dd xf e xf xf c d xf bb f xf b f c xf b d xf b d xf b cdc xf b bac xf b c xf b b c xf b xf b bb home helixbot dotnetbuild work f b c d a fc d bc Payload net x mono sgen x x d Memory map a a d r xp home helixbot dotnetbuild work f b c d a fc d bc Payload net x mono sgen a e aa r p fc home helixbot dotnetbuild work f b c d a fc d bc Payload net x mono sgen aa aa rw p home helixbot dotnetbuild work f b c d a fc d bc Payload net x mono sgen aa b c rw p rw p heap f ff f p f f rw p f f cb rw p f cb f p f ff f p f f rw p f f rw p f f p f d f p f f a e rw p f a e f d r p home helixbot dotnetbuild work f b c d a fc d bc Payload net x System dll f d f d rw p f d f e p f ef f f r xp home helixbot dotnetbuild work f b c d a fc d bc Payload net x mscorlib dll so f f f a r p a home helixbot dotnetbuild work f b c d a fc d bc Payload net x mscorlib dll so f a f a rw p a home helixbot dotnetbuild work f b c d a fc d bc Payload net x mscorlib dll so f a f b rw p f b f bff r p home helixbot dotnetbuild work f b c d a fc d bc Payload net x mscorlib dll f bff f ff rw p f ff f p f f rw p f b f r xp lib i linux gnu libgcc s so f f r p b lib i linux gnu libgcc s so f f rw p c lib i linux gnu libgcc s so f f c rwxp f c f ce rw p f ce f d r p home helixbot dotnetbuild work f b c d a fc d bc Payload net x System Core dll f d f d rw p f d f e p f e f d rw p f d f rw p f f rwxp f f r p home helixbot dotnetbuild work f b c d a fc d bc Payload net x tests runtime appdomain threadpool unload exe f f b rw p f b f aa p f aa f ab rw s dev shm mono f ab f bb rwxp f bb f c r p usr lib locale aa DJ utf LC CTYPE f c f d r p usr lib locale aa ET LC NUMERIC f d f e r p usr lib locale en US utf LC TIME f e f e r p usr lib locale aa DJ utf LC COLLATE f e f f r p usr lib locale chr US LC MONETARY f f f r p usr lib locale en AG LC MESSAGES SYS LC MESSAGES f f r p usr lib locale chr US LC PAPER f f r p usr lib locale chr US LC NAME f f r p usr lib locale en US utf LC ADDRESS f f r p usr lib locale chr US LC TELEPHONE f f rw p f f f r xp lib i linux gnu libc so f f f f r p b lib i linux gnu libc so f f f fa rw p b lib i linux gnu libc so f fa f fd rw p f fd f r xp lib i linux gnu libpthread so f f r p lib i linux gnu libpthread so f f rw p lib i linux gnu libpthread so f f a rw p f a f d r xp lib i linux gnu libdl so f d f e r p lib i linux gnu libdl so f e f f rw p lib i linux gnu libdl so f f f r xp lib i linux gnu librt so f f r p lib i linux gnu librt so f f rw p lib i linux gnu librt so f f b r xp lib i linux gnu libm so f b f c r p lib i linux gnu libm so f c f d rw p lib i linux gnu libm so f d f e r p usr lib locale chr US LC MEASUREMENT f e f r s usr lib i linux gnu gconv gconv modules cache f f r p usr lib locale en US utf LC IDENTIFICATION f f rw p f f b r p vvar f b f d r xp vdso f d f b r xp lib i linux gnu ld so f b f b r p lib i linux gnu ld so f b f b rw p lib i linux gnu ld so ff ff p ffb e ffb f rw p stack Stacktrace at at System IO MonoIO Read System Runtime InteropServices SafeHandle byte int int System IO MonoIOError x in at System IO FileStream ReadData System Runtime InteropServices SafeHandle byte int int x in at System IO FileStream RefillBuffer x in at System IO FileStream ReadInternal byte int int x in at System IO FileStream Read byte int int x a in at System IO StreamReader ReadBuffer x in at System IO StreamReader Peek x in at Mono Xml SmallXmlParser Peek x in at Mono Xml SmallXmlParser Parse System IO TextReader Mono Xml SmallXmlParser IContentHandler x d in at System Security Cryptography CryptoConfig LoadConfig string System Collections Generic IDictionary x e in at System Security Cryptography CryptoConfig Initialize x in at System Security Cryptography CryptoConfig CreateFromName string object x in at System Security Cryptography CryptoConfig CreateFromName string x in at System Security Cryptography RandomNumberGenerator Create string x in at System Security Cryptography RandomNumberGenerator Create x in at System Guid NewGuid x f in at System Runtime Remoting RemotingServices NewUri x e in at System Runtime Remoting RemotingServices Marshal System MarshalByRefObject string System Type x a in at System AppDomain GetMarshalledDomainObjRef x in at wrapper runtime invoke runtime invoke object this object intptr intptr intptr x in at at wrapper managed to native System Reflection MonoMethod InternalInvoke System Reflection MonoMethod object object System Exception at System AppDomain InvokeInDomain System AppDomain System Reflection MethodInfo object object at System Runtime Remoting RemotingServices GetDomainProxy System AppDomain at System AppDomain CreateDomain string System Security Policy Evidence System AppDomainSetup at System AppDomain CreateDomain string at Driver c b int at System Linq Parallel SelectQueryOperator MoveNext int int at System Linq Parallel SelectQueryOperator MoveNext int int at System Linq Parallel PipelineSpoolingTask home helixbot dotnetbuild work cc ecc c dd e e a Payload net x mono sgen double free or corruption fasttop x ff bc b Backtrace lib x linux gnu libc so x bfb x ff cfac bfb lib x linux gnu libc so x fc x ff cfacafc lib x linux gnu libc so x e x ff cfacb e home helixbot dotnetbuild work cc ecc c dd e e a Payload net x mono sgen x fc a x ad a c a home helixbot dotnetbuild work cc ecc c dd e e a Payload net x mono sgen x df x ad a df home helixbot dotnetbuild work cc ecc c dd e e a Payload net x mono sgen x fc x ad c home helixbot dotnetbuild work cc ecc c dd e e a Payload net x mono sgen x ff x ad f home helixbot dotnetbuild work cc ecc c dd e e a Payload net x mono sgen xc x ad cc home helixbot dotnetbuild work cc ecc c dd e e a Payload net x mono sgen xc f x ad cd f x Memory map rwxp f cf rwxp rwxp f fa rwxp ad ad d r xp home helixbot dotnetbuild work cc ecc c dd e e a Payload net x mono sgen ad f ad f c r p d home helixbot dotnetbuild work cc ecc c dd e e a Payload net x mono sgen ad f c ad f rw p home helixbot dotnetbuild work cc ecc c dd e e a Payload net x mono sgen ad f ad rw p ad be ad e rw p heap ff b ff b rw p ff b ff b p ff b ff b c rw p ff b c ff bc p ff bc ff bc rw p ff bc ff c p ff c ff c rw p ff c ff c p ff c ff c rw p ff c ff c p ff c ff c rw p ff c ff cc p ff cc ff cc a r p home helixbot dotnetbuild work cc ecc c dd e e a Payload net x Mono Security dll ff cc a ff cc ab p ff cc ab ff cc a rw p ff cc a ff cc ac p ff cc ac ff cc a rw p ff cc a ff cc ad p ff cc ad ff cc a rw p ff cc a ff cc ae p ff cc ae ff cc a rw p ff cc a ff ccb r p home helixbot dotnetbuild work cc ecc c dd e e a Payload net x System dll ff ccb ff ccb p ff ccb ff ccd rw p ff ccd ff cd c r xp home helixbot dotnetbuild work cc ecc c dd e e a Payload net x mscorlib dll so ff cd c ff cd b p home helixbot dotnetbuild work cc ecc c dd e e a Payload net x mscorlib dll so ff cd b ff cd c r p home helixbot dotnetbuild work cc ecc c dd e e a Payload net x mscorlib dll so ff cd c ff cd d rw p home helixbot dotnetbuild work cc ecc c dd e e a Payload net x mscorlib dll so ff cd d ff cd b rw p ff cd b ff cdbff r p home helixbot dotnetbuild work cc ecc c dd e e a Payload net x mscorlib dll ff cdbff ff cebff rw p ff cebff ff cec p ff cec ff cf rw p ff cf ff cf rw p ff cf ff cf r p home helixbot dotnetbuild work cc ecc c dd e e a Payload net x System Core dll ff cf ff cfa rw p ff cfa ff cfa r p home helixbot dotnetbuild work cc ecc c dd e e a Payload net x tests runtime appdomain threadpool unload exe ff cfa ff cfa rw p ff cfa ff cfbe r xp lib x linux gnu libc so ff cfbe ff cfde p lib x linux gnu libc so ff cfde ff cfded r p lib x linux gnu libc so ff cfded ff cfdef rw p lib x linux gnu libc so ff cfdef ff cfdf rw p ff cfdf ff cfe r xp lib x linux gnu libgcc s so ff cfe ff d p lib x linux gnu libgcc s so ff d ff d r p lib x linux gnu libgcc s so ff d ff d a rw p lib x linux gnu libgcc s so ff d a ff d r xp lib x linux gnu libpthread so ff d ff d p lib x linux gnu libpthread so ff d ff d r p lib x linux gnu libpthread so ff d ff d rw p lib x linux gnu libpthread so ff d ff d rw p ff d ff d a r xp lib x linux gnu libdl so ff d a ff d p lib x linux gnu libdl so ff d ff d a r p lib x linux gnu libdl so ff d a ff d b rw p lib x linux gnu libdl so ff d b ff d r xp lib x linux gnu librt so ff d ff d p lib x linux gnu librt so ff d ff d r p lib x linux gnu librt so ff d ff d rw p lib x linux gnu librt so ff d ff d r xp lib x linux gnu libm so ff d ff d p lib x linux gnu libm so ff d ff d r p lib x linux gnu libm so ff d ff d rw p lib x linux gnu libm so ff d ff d a r xp lib x linux gnu ld so ff d a ff d rw p ff d ff d bf p ff d bf ff d c rw s dev shm mono ff d c ff d a r p usr lib locale aa DJ utf LC CTYPE ff d a ff d a r p usr lib locale aa ET LC NUMERIC ff d a ff d a r p usr lib locale en US utf LC TIME ff d a ff d b r p usr lib locale aa DJ utf LC COLLATE ff d b ff d b r p usr lib locale chr US LC MONETARY ff d b ff d b b r s usr lib x linux gnu gconv gconv modules cache ff d b b ff d b rw p ff d b ff d b r p usr lib locale en AG LC MESSAGES SYS LC MESSAGES ff d b ff d b r p usr lib locale chr US LC PAPER ff d b ff d b r p usr lib locale chr US LC NAME ff d b ff d b r p usr lib locale en US utf LC ADDRESS ff d b ff d b r p usr lib locale chr US LC TELEPHONE ff d b ff d b r p usr lib locale chr US LC MEASUREMENT ff d b ff d b r p usr lib locale en US utf LC IDENTIFICATION ff d b ff d b a rw p ff d b a ff d b b r p lib x linux gnu ld so ff d b b ff d b c rw p lib x linux gnu ld so ff d b c ff d b d rw p ffdc f ffdc f b p ffdc ffdc rw p stack ffdc ec ffdc ee r p vvar ffdc ee ffdc f r xp vdso ffffffffff ffffffffff r xp vsyscall Stacktrace at at System Runtime Remoting TypeInfo ctor System Type x b in at System Runtime Remoting ServerIdentity CreateObjRef System Type x in at System MarshalByRefObject CreateObjRef System Type x in at System Runtime Remoting RemotingServices Marshal System MarshalByRefObject string System Type x ff in at System AppDomain GetMarshalledDomainObjRef x in at wrapper runtime invoke runtime invoke object this object intptr intptr intptr x a in at at wrapper managed to native System Reflection MonoMethod InternalInvoke System Reflection MonoMethod object object System Exception x c in at System AppDomain InvokeInDomain System AppDomain System Reflection MethodInfo object object at System Runtime Remoting RemotingServices GetDomainProxy System AppDomain at System AppDomain CreateDomain string System Security Policy Evidence System AppDomainSetup at System AppDomain CreateDomain string at Driver c b int at System Linq Parallel SelectQueryOperator MoveNext int int at System Linq Parallel SelectQueryOperator MoveNext int int at System Linq Parallel PipelineSpoolingTask s s x s at sysdeps posix libc fatal c x ff cfacafc in malloc printerr action str x ff cfbb ef double free or corruption fasttop ptr ar ptr at malloc c x ff cfacb e in int free av x ff bc p x ff bc a have lock at malloc c x ad a c a in mono compile create vars cfg x ff b a at mini c mini method compile method methodopts optsdomain domainflags flagsparts partsaot method index aot method indexat mini c x ad a df in mono jit compile method inner method methodtarget domain target domainopt opterror errorat mini c x ad c in mono jit compile method with opt method x ff b db opt jit only jit onlyerror errorat mini runtime c x ad c f in mono jit compile method jit only method error errorat mini runtime c x ad f in compile special error x ff cc a c target domain x ff b a method x ad b d at mini runtime c mono jit compile method with opt method methodopt jit only jit onlyerror errorat mini runtime c x ad bfc in mono jit compile method method methoderror errorat mini runtime c x ad cc in common call trampoline regs regscode code H Hcs H b m x ad b d vt vtvtable slot error errorat mini trampolines c x ad cd f in mono vcall trampoline regs x ff cc a d code x dd H Hcs H b slot tramp at mini trampolines c x in x ff cc a d in x ff cc a d in x ff cc a ee in x ff cc a d in x ff b a in x ff b b in x ff cf cd in x ff b in x ff cc a in x ff cc a ee in x in Thread Thread x ff cc a LWP x ff d in futex abstimed wait cancelable private abstime x ff cc a de expected futex word x ad f a at sysdeps unix sysv linux futex internal h do futex wait sem sem abstime abstimeat sem waitcommon c x ff d cf in new sem wait slow sem x ad f a abstime x ff cc a de at sem waitcommon c x ff d in sem timedwait sem sem abstime abstimeat sem timedwait c x ad bb ffa in mono os sem timedwait flags MONO SEM FLAGS ALERTABLE timeout ms sem x ad f a at mono utils mono os semaphore h mono coop sem timedwait sem x ad f a flags MONO SEM FLAGS ALERTABLE timeout ms at mono utils mono coop semaphore h worker park at threadpool worker default c worker thread unused unusedat threadpool worker default c x ad b cfe in start wrapper internal stack ptr start info x at threads c start wrapper data x ad efe at threads c x ff d in start thread arg x ff cc a at pthread create c x ff cfb cacf in clone at sysdeps unix sysv linux x clone S Thread Thread x ff cc a LWP x ff d in futex abstimed wait cancelable private abstime x expected futex word x ff c at sysdeps unix sysv linux futex internal h do futex wait sem semabstime x at sem waitcommon c x ff d e in new sem wait slow sem x ff c abstime x at sem waitcommon c x ff d in new sem wait sem semat sem wait c x ad c a in mono os sem wait flags MONO SEM FLAGS NONE sem x ff c at mono utils mono os semaphore h mono thread info wait for resume info infoat mono threads c x ad c in mono threads exit gc safe region unbalanced internal cookie x ff c c stackdata at mono threads coop c x ad c e d in mono coop cond timedwait cond x ad ac mutex x ad b timeout ms at mono utils mono coop mutex h sleep interruptable alerted x ff cc a dfc ms at mono threads c mono thread info sleep ms msalerted alertedat mono threads c x ad bb a in monitor thread unused unusedat threadpool worker default c x ad b cfe in start wrapper internal stack ptr start info x at threads c start wrapper data x ad efe at threads c x ff d in start thread arg x ff cc a at pthread create c x ff cfb cacf in clone at sysdeps unix sysv linux x clone S Thread Thread x ff ccd LWP x ff d in futex abstimed wait cancelable private abstime x expected futex word x ff c at sysdeps unix sysv linux futex internal h do futex wait sem semabstime x at sem waitcommon c x ff d e in new sem wait slow sem x ff c abstime x at sem waitcommon c x ff d in new sem wait sem semat sem wait c x ad c a in mono os sem wait flags MONO SEM FLAGS NONE sem x ff c at mono utils mono os semaphore h mono thread info wait for resume info infoat mono threads c x ad c in mono threads exit gc safe region unbalanced internal cookie x ff c c stackdata at mono threads coop c x ad b cf in threads native thread join lock value tid x ff b dff at threads c mono threads join threads at threads c x ad b f d in mono runtime do background work at gc c finalizer thread unused unusedat gc c x ad b cfe in start wrapper internal stack ptr start info x at threads c start wrapper data x ad e c at threads c x ff d in start thread arg x ff ccd at pthread create c x ff cfb cacf in clone at sysdeps unix sysv linux x clone S Thread Thread x ff cf ff LWP pthread cond wait at sysdeps unix sysv linux x pthread cond wait S x ad bfaedb in mono os cond wait mutex x ad f f cond x ad f ec at mono utils mono os mutex h get work job do idle work context worker index at sgen thread pool c thread func data at sgen thread pool c x ff d in start thread arg x ff cf ff at pthread create c x ff cfb cacf in clone at sysdeps unix sysv linux x clone S Thread Thread x ff d b b LWP pthread cond wait at sysdeps unix sysv linux x pthread cond wait S x ad c db in mono os cond wait mutex x ad c cond x ad c at mono os mutex h mono os cond timedwait cond condmutex mutextimeout ms timeout msat mono os mutex c x ad b d in mono coop cond timedwait timeout ms mutex x ad c cond x ad c at mono utils mono coop mutex h mono w handle timedwait signal naked alerted x ffdc e poll timeout mutex x ad c cond x ad c at w handle c mono w handle timedwait signal handle handle data x ad c f timeout timeoutalerted alertedpoll at w handle c x ad b e f in mono w handle wait one handle handletimeout timeoutalertable alertableat w handle c x ad ba in ves icall System Threading Monitor Monitor wait obj x ff cf ms at monitor c x f in x ff cf in xffffffffffffffff in x in Got a SIGABRT while executing native code This usually indicates a fatal error in the mono runtime or one of the native libraries used by your application xf dd in raise from lib i linux gnu libc so xf in abort from lib i linux gnu libc so xf ad f in from lib i linux gnu libc so xf b fc in from lib i linux gnu libc so xf b in from lib i linux gnu libc so x b f in monoeg g free ptr x c b at gmem c x f in mono bitset free set x c b at monobitset c x be in mono compile create vars cfg at mini c mini method compile method opts domain flags parts aot method index at mini c x c e in mono jit compile method inner method x ed target domain xf opt error xf fe c at mini c MonoMethodHeaderMonoMethodmono mempool alloc cfg mempoolmono image alloc image,Yes
213,issue,Did you forget to push tags to GH repository?,Did you forget to push tags to GH repository Please push tags for versions on to GitHub at least for latest rc Thank you in advance,Damn Yeah I forgot about tags On Fri Oct at PM Zeke Fast notificationsPlease push tags for versions on to GitHub at least for latest rc Thank you in advance Reply to this email directly or view it on GitHub You can just use option with when pushing on GH Do you know what s the easiest way to find sha for releases Do you mean having code find sha for it I think it s impossible exactly determine the commit by code because even same code committed on different time has different hashes If you have no tags for previous releases and I m the only who notice that I d suggest don t bothering with tagging and just pay attention to this in future or use to find commit sure and tag it sure if you have sing of release like version bump in files or release notes I always tag releases I forgot this time because it was a pre release and I was in rush On Sun Oct at PM Zeke Fast notifications Do you mean having code find sha for it I think it s impossible exactly determine the commit by code because even same code committed on different time has different hashes If you have no tags for previous releases and I m the only who notice that I d suggest don t bothering with tagging and just pay attention to this in future or use to find commit sure and tag it sure if you have sing of release like version bump in files or release notes Reply to this email directly or view it on GitHub I try to use but I forget the switch sometimes I wish it was the default or there was a way to configure it to be the default Lets move this to devtools oh right good call Yeah that wouldn t be so bad I guess using an alias will deal with a lot of the pain though I don t use what does it do exactly It s this thing I ditched jeweler for this and I really like it Yeah it s a nice single purpose library It adds the release command to gem With the switch it will add a version tag at the same time it pushes to rubygems I just recalled I used to use it and then I stopped not sure why Seems like just tagging the shas where the version was bumped would do it I m closing this issue now If you need access to these tags for any reason please let me know otherwise I m going to leave it be since has been released Since was released this is Okay Thanks,No
46686,issue,salt.states.file.touch should have user parameter,salt states file touch should have user parameter Description of Issue Question The salt states file touch should have user parameter to specify owner of the created file,Thanks for the report This would be a good feature to include Might this case be better off using and empty rather than expanding out This issue has been automatically marked as stale because it has not had recent activity It will be closed if no further activity occurs Thank you for your contributions If this issue is closed prematurely please leave a comment and we will gladly reopen the issue Thank you for updating this issue It is no longer marked as stale,No
5700,pr,Store JWT in authentication object,Store JWT in authentication object Please make sure the below checklist is followed for Pull Requests x Travis are green x Tests are added where necessary x Coding Rules Commit Guidelines as per our CONTRIBUTING md are followed This is especially useful for aggregate micro services where you want to relay the token to downstream services,what is the use case for having access to the token For me that s adding overhead to each thread as it s stored in thread local and I don t understand the need it is useful when you want to relay the token from a micro service to another Typically when you aggregate micro services Suppose user calls MS A which in turns calls MS B you want to have the token used for the call to A to be used by A to call B See for the way to do it with OAuth But we also need something equivalent for JWT Oh yes I totally agree,Yes
1245,pr,Resolve static analyzer warning about 'Potential leak of an object stored into 'dataProvider'',Resolve static analyzer warning about Potential leak of an object stored into dataProvider Resolved in this manner in an attempt to remain in the spirit of how the code was originally written,Looks like applies the same patch Thanks all the same Ah didn t see Glad it s resolved,Yes
657,pr,add case-sensitive login tests,add case sensitive login tests Specifying a case sensitive field for testing which should help with and,Looks like this is failing in MySQL and passing in PostgreSQL and SQLite which is correct Looks like this is failing in MySQL and passing in PostgreSQL and SQLite which is correct Great I don t want to merge a failing test into master though Can you please combine this into your other PR I ve combined into the other PR so you can feel free to close here I d love your input on and then we can work toward a merge once we re good on that I ve combined into the other PR so you can feel free to close here Closing thanks I d love your input on and then we can work toward a merge once we re good on that I ll take a look,Yes
8974,pr,Allow to offload certificate validation when using BoringSSL,Allow to offload certificate validation when using BoringSSL Motivation BoringSSL supports offloading certificate validation to a different thread This is useful as it may need to do blocking operations and so may block the EventLoop Modification Adjust ReferenceCountedOpenSslEngine to correctly handle offloaded certificate validation just as we already have code for certificate selection Result Be able to offload certificate validation when using BoringSSL,test this please Merging this as the original PR was approved before,Yes
6955,issue,Possible solution for error 65 (missing signature) for XCUITest @ real device,Possible solution for error missing signature for XCUITest real device Currently many people complain they cannot automate tests for real iOS devices using XCUITest driver because of this annoying error The error means that driver source cannot be signed properly and thus cannot be installed on real device even if the same action works as expected from Xcode on the same machine I spent some time investigating the problem and it looks like the main source of it is Accessibility restrictions in Mac OS because I see No user interaction is allowed error in Xcode logs This happens because the private key which the tool tries to use is stored in the system keychain and the parent process has no access to it And here is possible solution For now all that Appium does is just execution of xcodebuild with necessary arguments using Subprocess helper class My proposal is to change it the way that if we run not on a Simulator then a shell script will be executed instead of xcodebuild which includes the following commands The custom keychain should be prepared manually using the following commands MyPrivateKey p is my private development key exported from the system keychain I have tested it via SSH console because it s not reproducible if one just executes xcodebuild via local Terminal and it worked Please think about including that into the next Appium build Information source FYI,Interesting Thanks for this I will look into it First pass at this I am trying to pass these capabilities key chain path and keychainpassword but got this error any idea XCUITest Error Unable to launch WebDriverAgent because of xcodebuild failure Command security v unlock keychain p v Users Chanakya Desktop Certificates p exited with code Make sure you follow the tutorial at Try to remove the WebDriverAgentRunner application from the device if it is installed and reboot the device at XCUITestDriver quitAndUninstall usr local lib node modules appium node modules appium xcuitest driver lib driver js at tryCatch usr local lib node modules appium node modules babel runtime regenerator runtime js at GeneratorFunctionPrototype invoke as invoke usr local lib node modules appium node modules babel runtime regenerator runtime js at GeneratorFunctionPrototype prototype anonymous function as next usr local lib node modules appium node modules babel runtime regenerator runtime js at GeneratorFunctionPrototype invoke usr local lib node modules appium node modules babel runtime regenerator runtime js at at process tickCallback internal process next tick js Error Unable to launch WebDriverAgent because of xcodebuild failure Command security v unlock keychain p v Users Chanakya Desktop Certificates p exited with code Make sure you follow the tutorial at Try to remove the WebDriverAgentRunner application from the device if it is installed and reboot the device at XCUITestDriver quitAndUninstall usr local lib node modules appium node modules appium xcuitest driver lib driver js at tryCatch usr local lib node modules appium node modules babel runtime regenerator runtime js at GeneratorFunctionPrototype invoke as invoke usr local lib node modules appium node modules babel runtime regenerator runtime js at GeneratorFunctionPrototype prototype anonymous function as next usr local lib node modules appium node modules babel runtime regenerator runtime js at GeneratorFunctionPrototype invoke usr local lib node modules appium node modules babel runtime regenerator runtime js at at process tickCallback internal process next tick js debug XCUITest pgrep nif xcodebuild e fc d a a e cbbcb fe fb didn t detect any matching processes Return code debug XCUITest Cannot find xcodebuild s process id so unable to retrieve DerivedData folder path XCUITest No WebDriverAgent derived data available so unable to clear system files debug iOSLog Stopping iOS log capture MJSONWP Encountered internal error running command Error Unable to launch WebDriverAgent because of xcodebuild failure Command security v unlock keychain p v Users Chanakya Desktop Certificates p exited with code Make sure you follow the tutorial at Try to remove the WebDriverAgentRunner application from the device if it is installed and reboot the device at XCUITestDriver quitAndUninstall usr local lib node modules appium node modules appium xcuitest driver lib driver js at tryCatch usr local lib node modules appium node modules babel runtime regenerator runtime js at GeneratorFunctionPrototype invoke as invoke usr local lib node modules appium node modules babel runtime regenerator runtime js at GeneratorFunctionPrototype prototype anonymous function as next usr local lib node modules appium node modules babel runtime regenerator runtime js at GeneratorFunctionPrototype invoke usr local lib node modules appium node modules babel runtime regenerator runtime js at at process tickCallback internal process next tick js HTTP POST wd hub session ms What happens if you manually run the command I got the below error unlock keychain p v Users Chanakya Desktop Certificates p security SecKeychainUnlock Users Chanakya Desktop Certificates p The specified keychain is not a valid keychain file But i am able to build succeed in xcode with this key and in keychain Access it is displayed as valid and expires in may something fishy here my coworker also use exact same configuration inlcuding team id and certificates etc he was able to launch the native app but fails for me with code sign error Finally i was able to find the solution it was actually Apple certificates in key chain access which now i set to system default and previously it was in Always trust mode If anyone had valid code sign dev ids but get messed up with keychains then this is the core solution I tried this configuration but still facing same code sign issue Before i was able to proceed at least on when i do test though terminal with the below command everything is going though xcodebuild project WebDriverAgent xcodeproj scheme WebDriverAgentRunner destination id UDID test but still though jenkins not able to run more than devices,Unsure
1803,issue,即使使用dangerouslyPasteHTML也无法插入video标签。。。,dangerouslyPasteHTML video title title beause I want use private data value i can promise security in server how to insert an video,,Unsure
6970,pr,Use HTTPS to download root certificate in UpdateProjectProvisioningAction 🔒,Use HTTPS to download root certificate in UpdateProjectProvisioningAction This root certificate path is hardcoded to currently which is also available over HTTPS It s almost always better to fetch over HTTPS if available x Run from the subdirectory of each tool you modified Alternatively run from the root directory x Run to ensure the code style is valid x Read the Contribution x We currently don t accept new actions please publish a plugin instead more information in,This makes sense thanks for the PR Can this cause a problem if the certificate is not available locally yet This seems pretty straightforward to me Please ping me if there are concerns here I am missing Looks okay to me,Unsure
61364,pr,Support delegation testing collections with deps.,Support delegation testing collections with deps SUMMARY Support delegation testing collections with deps All collections in the same collection root as the collection being tested will be sent to the remote system container Resolves ISSUE TYPE Feature Pull Request COMPONENT NAME ansible test,,Yes
671,pr,Fixing social logins docs for RC1,Fixing social logins docs for RC Updated docs to reflect new package name for Secret Manager tidied up the text a little for readability,Hi I m your friendly neighborhood NET Foundation Pull Request Bot You can call me DNFBOT Thanks for your contribution In order for us to evaluate and accept your PR we ask that you sign a contribution license agreement It s all electronic and will take just minutes I promise there s no faxing TTYL DNFBOT Thanks for signing the contribution license agreement so quickly Actual humans will now validate the agreement and then evaluate the PR Thanks DNFBOT Thanks b b f daa a dd d,Unsure
10880,issue,Error getting certificate,Error getting certificate Hello developers and community I spent weeks trying to install Zulip on my server and nothing came of it I apologize in advance for my English translator use Here are some details about the server Ubuntu Server on Xen with real IP Installation is clean there are no services on the server for Zulip the whole virtual machine was allocated After installation has been configured FQDN Hostname f view chat nt ru Domain chat nt ru configured and has the correct A record in DNS with the server address UFW status is inactive No nginx or Apache installed I also checked that no one listened to the and ports before running the installation script Every time i m start zulip server scripts setup install certbot email admin hostname chat nt ru I get the same error Failed authorization procedure chat nt ru urn ietf params acme error unauthorized The client lacks sufficient authorization Invalid response from script NOTES The following errors were reported by the server Domain chat nt ru Type unauthorized Detail Invalid response from html class no js script To fix these errors please make sure that your domain name was entered correctly and the DNS A AAAA record s for that domain contain s the right IP address Zulip installation failed The install process is designed to be idempotent so you can retry after resolving whatever issue caused the failure there should be a traceback above A log of this installation is available in var log zulip install log Please help me to understand what could be the problem,Hello members this issue was labeled with the area production installer label so you may want to check it out sorry for the slow reply This appears to be a an issue with using certbot I recommend you use Google and or to get help with that For testing Zulip you can just use the option and then get a cert using Certbot not using our tool or any other way at your convenience,Yes
3822,issue,"calling web service (username, password credentials) from .net core 2.2 web api ",calling web service username password credentials from net core web api Describe the bug I am trying to consume a web service with WS Security defined schema to pass user name and password in clear text on HTTPS in dotnet core tried on as well But I am getting following error Invalid Authentication Username Password not found possible security namespace mismatch To Reproduce Call stack at System ServiceModel Channels ServiceChannel ThrowIfFaultUnderstood Message reply MessageFault fault String action MessageVersion version FaultConverter faultConverter at System ServiceModel Channels ServiceChannel HandleReply ProxyOperationRuntime operation ProxyRpc rpc at System ServiceModel Channels ServiceChannel Call String action Boolean oneway ProxyOperationRuntime operation Object ins Object outs TimeSpan timeout at System ServiceModel Channels ServiceChannelProxy InvokeService MethodCall methodCall ProxyOperationRuntime operation at System ServiceModel Channels ServiceChannelProxy Invoke MethodInfo targetMethod Object args End of stack trace from previous location where exception was thrown at System Reflection DispatchProxyGenerator Invoke Object args at generatedProxy ProcessMessage ProcessMessageRequest Expected behavior If we try to consume same service in Net Framwork it is working Screenshots If applicable add screenshots to help explain your problem Additional context Add any other context about the problem here,Thank you for reporting this issue We need additional information Which WCF Core packages are you using version Can you send us your binding information we need to know how you are using WCF The more client side code you can send us the better thanks for your response I am not using any WCF Core packages I am trying to invoke a rd party service using their WSDL Used Connected Services option to import WSDL The header for the request should be in following format soapenv Envelope soapenv mustUnderstand consume that service following is the my code BasicHttpBinding binding new BasicHttpBinding BasicHttpSecurityMode Transport binding Security Transport ClientCredentialType HttpClientCredentialType Basic ThirdParyService svc new ThirdParyService binding address svc ClientCredentials UserName UserName Username svc ClientCredentials UserName Password Password await svc InvokeMethod But looks like username password are not included in the request from dotnet core and the error says Invalid Authentication Username Password not found possible security namespace mismatch Note The same functionality is already implemented in Net Framework using custom binding But most of the classes used are not exists in dotnet core Following are few classes method used SymmetricSecurityBindingElement CreateSecureConversationBindingElement SecurityBindingElement CreateUserNameOverTransportBindingElement If I tried to follow same custom bindings I am getting following error System PlatformNotSupportedException TransportSecurityBindingElement BuildChannelFactoryCore is not supported I got the issue resolved with help of following interfaces classes MessageHeader IClientMessageInspector IEndpointBehavior Hi I am facing same issue Can you tell us what changes you have done in MessageHeader IClientMessageInspector IEndpointBehavior,Yes
3603,issue,syncbackpro@9.2.39.0: hash check failed,syncbackprohash check failed Checking hash of SyncBackPro Setup NI zip ERROR Hash check failed App extras syncbackpro URL bytes B Expected bd e dcc f d b e b ddfbe c f c a d bb Actual da c dc f a e f e cf e b d ef c aac e,,Yes
34925,issue,Wrong vaultname in the example for storing password in vault,Wrong vaultname in the example for storing password in vault Enter feedback here on this page the example shown to store examplepassword has the wrong vaultname Document Details Do not edit this section It is required for docs microsoft com GitHub issue linking ID f c a a e a b e Version Independent ID c d d ed d c a Content Azure Quickstart Set retrieve a secret from Key Vault using Content Source Service key vault GitHub Login Microsoft Alias barclayn,Thanks for your feedback We will investigate and update as appropriate The PR for the fix has been created and sent to the author for review It will be merged soon Thanks again for pointing this out I am closing the issue based on this update please let us know if there is something else that we can help you with,Yes
17922,pr,[3.8] bpo-25172: Reduce scope of crypt import tests (GH-17881),bpo Reduce scope of crypt import tests GH cherry picked from commit ed eeb c a a a fa e a f c Co authored by Steve Dower,Status check is done and it s a success Status check is done and it s a success Status check is done and it s a success,Unsure
1029,issue,Lottie .json files are not found when they are part of Assets.xcassets ,Lottie json files are not found when they are part of Assets xcassets Lottie iOS Issue Hello Sorry you re having an Issue Please help us make Lottie better by filling everything below out with as much information as you can so we can try to reproduce and fix the issue Check these before submitting X The issue doesn t involve an Unsupported X This issue isn t related to another open issue This issue is a Non Crashing Bug Visual or otherwise Crashing Bug Feature Request X Regression Something that once worked but doesn t work anymore Which Version of Lottie are you using Lottie What Platform are you on MacOS X iOS What Language are you in X Swift Objective C Expected Behavior Lottie files to be found when part of Assets xcassets Actual Behavior Lottie json files cannot be found when they are part of Assets xcassets They don t seem to be located as part of the main bundle This used to work when we were on version In order for the library to find the lottie json files I have to move them to a top level folder,I have same issue please fix it,Unsure
797,issue,Reader: add username autocompletion to comments,Reader add username autocompletion to comments Raised by Usernames with should,dupe of,No
17,pr,Add encrypt support with SQLCipher,Add encrypt support with SQLCipher add SQLCipher use FMDB SQLCipher in Demo with Cocoapods update document,Readme OK I will make a new podspec file for that version,Yes
90,issue,Re-assigning same shortcut triggers it,Re assigning same shortcut triggers it Say I have a hotkey set up with Cmd Ctrl T I focus into the shortcut view I change my mind and just want to assign the same thing so I press Cmd Ctrl T Expected behavior Cmd Ctrl T is assigned shortcut view blurs Actual behavior The shortcut is triggered before the shortcut view can intercept it Workaround would be to manually unbind on shortcut view and re bind after blur This is a regression since x,I think the easiest solution would be to unbind the shortcut automatically when the recording control gets focused By the way did you know that you can also return back to the previous shortcut by pressing escape I think the easiest solution would be to unbind the shortcut automatically when the recording control gets focused Probably yeah By the way did you know that you can also return back to the previous shortcut by pressing escape Yes,Unsure
697,issue,"""Open symbol by name"" not fuzzy matching",Open symbol by name not fuzzy matching Using the Open symbol by name feature in VSCode when fuzzy searching for a symbol with Microsoft Python Language Server enabled the list of symbols returns absolutely nothing In contrast when using Jedi I m getting results With Jedi off python Jedi on jedi for the symbol exactly works just fine,Currently the symbol index we ve implemented uses case insensitive substrings for matching so this is expected but stands to be improved Note that this only applies to workspace symbols which has a query string sent to the language server Document symbols and the outline have no query so VS Code is able to do the fuzzy matching itself over the result we return Hey any ETA on this This is the only thing holding me back from using this extension and it s a pretty big oversight Searching through symbols over a huge repository without fuzzy search is a huge PITA No specific ETA there are other things we re trying to improve and this hasn t been worked on It s not an oversight per se when I implemented the index I just did the minimum working implementation and knew fuzzy matching would be better To add this we ll have to go look at the fuzzy logic the extension uses when looking through its ctags database and do something similar This isn t a real solution but you can also use VS Code s builtin search tool which uses ripgrep under the hood and is very effective but of course will lack any Python specific info Ah it s a shame this isn t priority I will wait for the day it is added because the extension is quite good except for this one grievous oversight I m aware of the search tool but it s quite a bit unwieldy and doesn t fuzzy match I was following this one microsoft vscode but should have followed it here for this feature on this I m very much used to this from PyCharm so right now I basically have to choose between using pycharm and not being able to do proper remote development using vscode JEDI and not being able to autogenerate imports using vscode PLS and not being able to jump to symbols in a fuzzy way index I just did the minimum working implementation and knew fuzzy matching would be better We recommend minimal work from extensions and strongly suggest to simply search for all query characters in their order inside symbol strings We ll then do the rest our implemention of that for reference and Ah thanks Johannes I was wondering why the extension had to do the fuzzy matching Please Python Language Server team I hope this issue can be addressed soon On Wed Mar Johannes Rieken wrote index I just did the minimum working implementation and knew fuzzy matching would be better We recommend minimal work from extensions and strong suggest to simply search for all query characters in their order inside symbol strings We ll then do the rest our implemention of that for reference and copying export function isPatternInWord patternLow string patternPos number patternLen number wordLow string wordPos number wordLen number boolean while patternPos patternLen wordPos wordLen if patternLow patternPos wordLow wordPos patternPos wordPos return patternPos patternLen pattern must be exhausted You are receiving this because you authored the thread Reply to this email directly view it on GitHub or unsubscribe Yeah no fuzzy matching required only very relaxed filtering as described above and in fact with small ish results no filtering is required I think CamelHumps style matching is very useful For example I have classes named and Ideally I d like to find the former when searching for and the latter with I do agree I have described is more relaxed to ensure that VS Code will receive as much results as possible so that we can then filter and sort them which also includes camel hump logic YES thank you Works fine now Is there any way to specify that you want to search for an exact name btw For example I have hundreds of classes named so it s almost impossible to jump to the class named just atm I tried putting it in quotes or adding a regex style at the end but that didn t help Is there any way to specify that you want to search for an exact name btw Type the exact name it filters and scores based on the input text but scoring should put better matches atop So the closer the match the more to the top things should be I tried that Doesn t work for this particular name Is there a minimum length looks like or chars for this to work Hm should work with all length Are you trying this with latest insiders is currently reworking this and it might be a regression or feature request Fyi the new work is not yet enabled in insiders Yes latest insiders If someone wants to try to reproduce it is the codebase where it happens We have our own workspace symbol query limit internally to prevent sending back too many results It s possible is so small that we re not getting to the exact match or a perfect substring match before finding a fuzzy ish match and then it s not in the list I m not sure if the UI displays how many results it was given though Any chance the limit could be made configurable Or even better returning exact whole string matches before applying the limit Not finding some class that just contains a very vague search term is one thing but not finding the class that has this exact name is quite confusing I encountered the issue for another class as well and after finding many classes starting with I get results for other symbol types that aren t even exact at least in a case sensitive way matches I d sooner just make it match exact then substring then fuzzy then limit it without configuration but all of this is a pretty large nested structure in memory that we d have to scan multiple times Maybe that doesn t matter I ll spend a bit of time on it later has the aforementioned behavior If needed I can modify the substring check to be a prefix only in case the exact substring matches are so many that fuzzy stops being useful Or bump the limit if we think we can handle more than of these at a time Please don t match on prefixes but use this logic Then returning only elements seems very conservative should be no problem I am using that method it s what closed this issue See The follow up PR just prioritized exact and substring matches before hitting the limit If there s a limit at all then there s a chance the exact match never shows up if we re only fuzzy matching I ll see if bumping the limit seems sane but there are still other users for the language server than just VS Code I d prefer not to break Symbol values contain full paths it can turn into an incredible amount of data If the user s workspace has a path with characters and we send symbols that s at least half a megabyte of data just on path prefixes alone,Yes
611,issue,Common language runtime issue when injecting endjointpoint before the return instructions,Common language runtime issue when injecting endjointpoint before the return instructions Please provide the following information when submitting an issue where appropriate replace the with a My Framework X NET X NET X NET X NET X NET NET NET NET Core Something else My Environment Windows or below not truly supported due to EOL X Windows X Windows Windows Windows IoT Core Windows Server Windows Server R Windows Server I have already repeated the problem using the latest stable release of OpenCover reviewed the usage and usage have looked at the opencover output xml file in an attempt to resolve the issue reviewed the current to check that the issue isn t already known My issue is related to check only those which apply no coverage being recorded x or bit support feature request Expected Behavior When the method has try catch I m getting this problem End joint point will be the managed method call It should be called when the instrumented method call happen Actual Behavior Common language runtime found invalid program error Steps to reproduce the problem Create a method with try catch For example as follows I m using Method cpp class for injecting the end instruction before return instructions When injecting the endjoint point with last return instruction I m getting this error Note The method I m using InsertSequenceInstructionsAtOffset long offset InstructionList instructions Please let me know if need any clarifications,It looks like you are having problems with code you have taken from OpenCover to do your own custom instrumentation so you will need to describe more about what you are trying to do what the IL looks like before you instrument it what the IL you are trying to introduce does and what it looks like what the IL looks like after instrumentation Hi do you still need any help with this Sorry for the delay response My own custom instrumentation is like adding our managed method call reference into starting and ending of a method by IL injection Using your Method cpp methods I will read the IL instructions Then add my own start IL instructions at offset and end IL instructions at before return ret instructions Then using the SetILFunctionBody I ll rewrite the IL code Before the instrumentation the IL code for my method is method public hidebysig instance void GetSalaryTemp cil managed Method begins at RVA x e Code size x maxstack try IL ldarg IL call instance class System Web System Web HttpResponse System Web System Web UI Page get Response IL ldstr test test test GetSalaryTemp IL b callvirt instance void System Web System Web HttpResponse Write string IL leave s IL end try catch mscorlib System Object IL pop IL leave s IL end handler IL ret end of method Default GetSalaryTemp After instrumentation the IL code is as follows The following static methods are in C managed dll loaded in GAC The same method is working for bit process Getting Common Language Runtime detected an invalid program for bit process I suspect is there any pointer related issue Or What could be the reason when it is working for bit and not working for bit Thanks in advance What do the the exception handler entries look like after the IL has been inserted BEFORE INSTRUMENTATION IL ldarg IL call A DF IL ldstr D IL B callvirt A E IL leave IL B IL pop IL leave IL B IL B ret Section B Exception handler list AFTER INSTRUMENTATION IL ldarg Newly added ins IL ldstr B C Newly added ins IL ldstr B E Newly added ins IL B call A A Newly added ins IL ldarg IL call A DF IL ldstr D IL B callvirt A E IL leave IL B IL pop IL leave IL B IL B nop Newly added ins IL C call A B Newly added ins IL ret Section Exception handler list The line section is got from DumpIL method in method cpp file The syntax for Section handlerType tryStart tryEnd handlerStart handlerEnd filterStart m token Please assist me what will be the issue Okay I think the catch handler is incorrect I think it should be You may need to work with the code taken from OpenCover to get it to produce the IL you need Awesome It works Thanks a lot What did you do to change the code to make it work I have set the newly added instruction nop IL B to tryHandlerEnd instruction of the method Then it is solved Although I m getting Common language runtime error and JIT Compiler encountered an internal limitation for many framework Ex All methods in System Data SqlClient related methods For example the following method has the CLR Runtime found invalid program error Before instrumentation IL Code After Instrumentation IL Code and Original method has been given in a text files separately and uploaded Could you find any root cause on this I think this injection on return statements will not be feasible I have an idea like adding try finally block in all the methods and adding the new end method call instruction in finally block I think this can be possible via adding exception handler instruction in a method IL What about your thought on this Or Do you have any other idea to achieve this okay thanks for the feedback,Unsure
17917,issue,[wasm][http] Support for setting the credentials option on a per-request basis,wasm http Support for setting the credentials option on a per request basis The current version of Mono doesn t provide any per request way to set a credentials option The credentials option is always set to the value of the globally static DefaultCredentials property issue,I really don t like the per request part of this very much as it s inconsistent with the general design pattern where properties may only be modified prior to sending the first request Instead having global static there should be something similar to,Yes
1338,issue,Designing Swift APIs,Designing Swift APIs ,,No
919,issue,E-mail not displayed when there is a PGP signature in the quoted e-mail,E mail not displayed when there is a PGP signature in the quoted e mail I have this issue and cannot find any bugs closed or open here just on the old code google com website As I still have this issue I guess it was not fixed so I would like to report it here I have updated it with my device information What steps will reproduce the problem Using OpenKeychain and K Mail send a signed e mail to someone not using PGP Have them respond to your e mail with their client quoting the entire message K mail receives the message displays it for a moment then the signature is being analyized and from then on only the part below the beginning of the signature is being displayed i e the actual replay can t be displayed in K Mail What do you expect to have happen First of all K mail should not recognize the signature my signature in the quoted part as valid and tell me that the reply e mail is signed Second of all it should in any case also display the rest of the e mail the reply above the quoted e mail If I view the e mail in Thunderbird with the Enigmail addon everything is displayed correctly First the reply then the quote first the info part from to sent subject then the line BEGIN ENCRYPTED or SIGNED PART and then the content of my original e mail What do you see instead Only the quoted part aka my original e mail What version of K are you using version What is your device and what version of Android are you using HTC M Android version Is your email account a POP account Exchange Account or an IMAP account IMAP Original bug report,Seems to be the same as,Yes
6290,pr,added FIDO2 security keys,added FIDO security keys ,kindly do the copy editor review for this PR Thanks PR has been copy edited and is ready for final review This is based on issue Thank you cc Thank you for the interesting points I presume you will be commenting later if anything here can be reused rephrased or otherwise changed to provide some form of support as you noted I commented on the original issue to get more clarity from the poster I will provide an update based on their response on what should be added,Yes
9712,issue,connect to amazon rds over ssl in sequelize,connect to amazon rds over ssl in sequelize I am trying to connect to a mysql amazon RDS connection over ssl from sequelize my config looks like this I am getting a error Do I have to reference the in the or is enough Is there a way to get more logging as to what is going on,is enough For anyone else who comes here the phrase is referring to what needs to go within the section The other outside of does nothing,Yes
1791,issue,Flowplayer 7 issue while playing AES encrypted stream.,Flowplayer issue while playing AES encrypted stream Hi team Below is the reply from flow player support But the stream now throws the same error in JW and hls js namely the range error Additionally I do see a ts fragment format error which also indicates there is something wrong with the encryption of the ts fragments The stream also fails with a media decoding erro in VLC and other desktop players Please post an issue in the hls js bug tracker at or fine tune your encrypter until the stream plays in the demo player Bernd Backhaus Flowplayer Video player and hosting supportAB M ster Samuelsgatan SE Stockholm Sweden VAT ID SE Environment x The stream has correct Access Control Allow Origin headers CORS x There are no network errors such as s in the browser console when trying to play the stream x The issue observed is not already reported by searching on Github under x The issue occurs in the latest reference client on and not just on my page M u link Hls js version Browser name version Chrome Version Official Build bit OS name version Windows Steps to reproduce Url to visit Check network calls Check console for error Expected behavior Should play the stream without fail Actual behavior Getting stuck while playing in the start Console output,This issue has been automatically marked as stale because it has not had recent activity It will be closed if no further activity occurs Thank you for your contributions The same issue Maybe it s caused by FFMPEG x I never got this error before if using FFMPEG x,Yes
1665,issue,use spring session close listener for sending messages to audit and query,use spring session close listener for sending messages to audit and query We found that the activiti session close listener mechanism isn t guaranteed to fire when the spring session closes and might fire before the spring transaction has ended We found and fixed this under by moving to a native spring listener This is not so serious for audit and query feeds as it was for connectors as audit and query are one way But we should switch it anyway as otherwise there s a risk though we ve not actually observed it of sending a message for a transaction that actually gets rolled back Arguably we should change the engine s mechanism but that wouldn t be easy,This depends on the done in the PR That s merged now so I think we can close this,Yes
6746,pr,feat(docs): add gulp task to generate the svg asset cache,feat docs add gulp task to generate the svg asset cache Added Gulp Task for Asset Cache Updated also for Removed old Asset Cache Build Script Updated Asset Cache from the Gulp Task Can you take a look,I am not inclined to accept this PR the file is not a template so is not good this gulp task is fragile Often the definitions in the standalone SVG file need to be modified to be used in a icon set For example see and see its definition entry in the Wow I m surprised I missed a few point I can t detect any schema in the given SVG if there are always other things to modify we need to detect these elements Is there anything I need to know about modifying the SVG s About the template to be honest I don t know what template engine is preferred in this case Closing this PR as too fragile brittle and not related to our core efforts,Unsure
1114,issue,Cannot login via `exp start`,Cannot login via exp start exp version is tried with node and The error,My credentials work on the website and on the windows client My bad I was behind a proxy and I ve omited to turn on my VPN,Yes
42909,pr,Fix cloudflare_dns legacy test,Fix cloudflare dns legacy test SUMMARY Needed to reflect current expected behavior ISSUE TYPE Bugfix Pull Request COMPONENT NAME cloudflare dns ANSIBLE VERSION,cc,Unsure
196,pr,Read oauth2_state from ticket store every time to avoid invalid oauth2_state,Read oauth state from ticket store every time to avoid invalid oauth state oauth state read ticket store ticket,,Yes
9024,issue,require('crypto') & DES inconsistent,require crypto DES inconsistent Version v Platform Darwin Darwin Kernel Version Mon Aug PDT root xnu RELEASE X x Subsystem OpenSSL zh Jan Hello I have an issue with the standard crypto package in node js The output do not always return the correct answer when using the DES algorithm Exemple result iteration key data daae c e f b d e iteration key data daae c e f b d e iteration key data daae c e f b d e iteration key data daae c e f b d e iteration key data daae c e a c a d df iteration key data daae c e f b d e iteration key data daae c e a c a d df iteration key data daae c e aa de e b iteration key data daae c e b ad d b be iteration key data daae c e f b d e,on an other machine debian Extending the exemple to check the success rate i have osx Success rate debian jessie Success rate Tempoary fix use var cipher crypto createCipheriv des ede Buffer concat key key Buffer alloc Instead of var cipher crypto createCipheriv des key Buffer alloc Success rate But this is far from beeing satisfactory gives you nondeterministic output that you use as an IV and you probably even want a random IV so the behaviour here seems pretty okay to me des is ECB Only CBC requires an IV the parameters is here for good looks so that the toBuf function do not throw an error You may use new Buffer hex and you will have the exact same issue i actually tried it before posting the issue on git hub Beside using des ede triple des encrypt decrypt encrypt with key key solves the issue des is ECB Only CBC requires an IV the parameters is here for good looks so that the toBuf function do not throw an error I m not an expert in crypto so I can t tell whether this is a problem in Node or not but the passed IV does seem to be used I get different but consistent results for different byte IVs for So yeah it s still using uninitialized data The valgrind outputs for the above scripts are about what you d expect but for reference here are the full You may use new Buffer hex and you will have the exact same issue i actually tried it before posting the issue on git hub Tried it and it worked consistently when adding one more to have a proper hex string Okay my bad using new Buffer hex does solve the problem That s great to hear I d still be interested to hear from anyone in whether the out of bounds reads for zero length IVs should be considered problematic Yeah that seems like a bug I d expect a zero sized IV to throw an invalid IV length exception Ah Guess we need to fix something there Turns out that yes the logic is faulty there is a misplaced in there For posterity openssl interprets des as DES CBC not DES ECB,Yes
953,issue,StringValues: Inconsistent hashcode for single-valued instances depending on construction,StringValues Inconsistent hashcode for single valued instances depending on construction Describe the bug Two instances initialized in different ways with the same single value may or may not produce the same hashcode depending on the actual value they hold Or given a fixed string value they may produce the same or different hashcodes across different NET runtime executions To Reproduce NET Core Microsoft Extensions Primitive Run this unit test repeatedly The assertion will sporadically fail Expected behavior The assertion should succeed consistently is always true for the many forms of so right now we sometimes end up with equal instances with different hashcodes breaking the contract between and Root cause For single valued instances calculates the hashcode differently according to the internal representation returns the hashcode of the one string value stored in the internal field result uses a for the one value stored in the first element of the internal array field The combiner accumulates hashcodes into a long and then returns the hashcode of that long result Now the hashcode of a long is This returns m value if m value is so the double above is ok when is in that range and the two hashcodes will be the same But a negative ends up producing a different value altogether In other words two instances initialized in different ways with the same single value may or may not produce the same hashcode depending on whether the hashcode of the value they hold by virtue of being negative ends up setting the sign bit of a long Also because hashcodes are seeded differently at every NET runtime execution across different runs hashcodes that were equal in one run won t be in another run Suggested fix This can be fixed in several ways but I think the fix that meshes best with the style of this code would be to go from to I m available to do a pull request incl unit test Additional context output Edits clarifications on which hashcode values produce this bug,We should make sure that with a single element array should be special cased in and have it generate the same kind of hash code as it would if it was a single string just stumbled accross this issue Since got merged this issue could be closed Oops Good catch thanks,Yes
1136,pr,Freeze mutable objects assigned to constants,Freeze mutable objects assigned to constants Automatic fix from rubocop to reduce number of hound error and get closer to green CI,I m not sold on this one as it requires a lot of code change without any clear benefit Especially things like the what do you say Can we disable the rule for all repos Hm I think is the right thing to do as far as ruby is concerned That said if we re not ready to keep up with all the new validations being done by rubocop I think I agree with your earlier suggestion that we lock that version to across all repos until we are ready to move forward So the alternative would It dramatically reduces number of total warnings for latest Closing this one wrt I will try to keep a version with in sync with master just in case,Unsure
283,pr,Check local priv-esc exploits on Linux,Check local priv esc exploits on Linux Does what title says Checks Linux kernel version against the yaml file with information on exploits CVE and possible download locations Yaml file can be expanded easily to keep information up to date as newer privesc s come out Stores returned data as a note but can easily be changed for loot storage I personally think a note is more appropriate,Maybe the results would be better saved using report vuln Just thought of that now but either way let me know what you think The way we use report vuln is more explicit Meaning that we tend to use it only if an attack is successful or the victim machine responds in a specific way that we can tell it s vulnerable Version checking can lead to higher false positives so I m not even sure if report vuln is the best choice or not I am stuck between report note and report vuln to be honest with you I ll wait for Tod s opinion tomorrow morning Okay sounds good report note might make more sense I think since it seems that like you said report vuln is more if the victim machine as been attacked successfully and since there are no priv esc s for Linux available it might be confusing to some Thanks for the input Hi ohdae So Tod and I had a brief discussion about your module We think that the module is interesting but because of how the module relies on an external file that must be manually updated in order to maintain its usefulness we feel it s too much of an overhead for us to keep track of rd party information ie links might be broken eventually or exploit could be fake and we d rather not pursuit that responsibility We d like to go ahead and close this pull request for now But you re more than welcome to keep it in your branch perhaps do a quick blog about it and see how other folks think about it I m sure if the module becomes popular we may reverse our decision In the mean time looking forward to your future contributions Thanks Okay sounds good Thanks for the feedback and explanation I do agree that keeping track of whether the exploits are legitimate links are active etc would be a bit of a pain especially if when the external yaml db started to grow I ll definitely keep this module around and see if I can find a way to improve on it to lower the overhead needed to support it Again thanks for the input,Yes
1049,pr,Add encrypted connection string for blob storage,Add encrypted connection string for blob storage cc,,Yes
16936,pr,[3.8] bpo-38434: Fixes some audit event documentation (GH-16932),bpo Fixes some audit event documentation GH cherry picked from commit e ce bcc c eb c ffa ba d aeaaf Co authored by Steve Dower,Status check is done and it s a success,Unsure
475,issue,InstanceMethodStasher may have a bug related to protected methods,InstanceMethodStasher may have a bug related to protected methods There s this bit of code Notice that it checks for a private method but not for a protected method There may be a bug lurking here Noting it in this issue so we don t forget,Actually there s the same kind of thing in a couple other places Actually that one makes me think that maybe protected methods are included somehow even though there s a that s not being called here or maybe the method here is misnamed and has the same bug Regardless I m seeing a pattern of duplication Looks like there s a concept we haven t named and put into its own object yet I have an in progress PR that will solve this FWIW is doc ed as Returns true if the named method is defined by mod or its included modules and if mod is a class its ancestors Public and protected methods are matched emphasis mine Thanks I found those docs as part of my investigation of this as I was preparing PR I think it s confusing though,Yes
40091,issue,mysql_user module fails when checking current privileges,mysql user module fails when checking current privileges Verify first that your issue request is not already reported on GitHub THIS FORM WILL BE READ BY A MACHINE COMPLETE ALL SECTIONS AS DESCRIBED Also test if the latest release and devel branch are affected too ALWAYS add information AFTER OUTSIDE these html comments Otherwise it may end up being automatically closed by our bot ISSUE TYPE Bug Report COMPONENT NAME mysql user ANSIBLE VERSION CONFIGURATION ANSIBLE PIPELINING etc ansible ansible cfg True OS ENVIRONMENT Ubuntu Server LTS SUMMARY The mysql user module fails when checking a user s current privileges in a MySQL database The creation of the user succeeds because there are no privileges but subsequent runs of the playbook end with an error I traced the error to a failure when parsing the output of a SHOW GRANTS command Ansible expects the server to quote strings with single quotes MySQL instead uses backticks userlocalhostuserlocalhost,Files identified in the description these files are inaccurate please update the section of the description or use the bot command click here for bot cc here for bot resolved by pr,Yes
16287,issue,AbstractEnterpriseBean.BeanFactoryReferenceReleaseListener causes memory leak [SPR-11664],AbstractEnterpriseBean BeanFactoryReferenceReleaseListener causes memory leak SPR Faleh opened and commented org springframework ejb support AbstractEnterpriseBean BeanFactoryReferenceReleaseListener keeps a strong reference beanFactoryReference which prevents the factory to be come weakly reachable solution org springframework util WeakReferenceMonitor trackedEntries should be a weakhashmap Affects votes watchers,Juergen commented Those references are being cleared as the containing EJB instances become weakly reachable With a properly managed EJB pool i e proper ejbRemove calls by the container you should never run into a situation where the BeanFactoryReference isn t otherwise reachable anymore Could you share some details about the specific leak that you were seeing Juergen Bulk closing outdated unresolved issues Please reopen if still relevant,Yes
1437,pr,Fix use of protected name in custom charting algo,Fix use of protected name in custom charting algo Switch away from use of protected chart name which was preventing the example from running Sorry for wrong branch name should be something like,Thats strange it should mean it shows up on the Strategy Equity plot Will try repeating and see if can fix in frontend Oh my bad just before it was reported by in I had also seen the protected chart error in a personal algo and assumed it was related to recent changes in charting framework and therefore systematic,Unsure
305,pr,solve hash problem on map pin click,solve hash problem on map pin click ,Tested LGTM Thanks,Unsure
6323,issue,How to know if crypto can be deposited / withdraw-ed from exchange?,How to know if crypto can be deposited withdraw ed from exchange I was looking at method but the information that crypto can be deposited or withdrawed is not contained there How can we know if crypto can be deposited withdraw ed from exchange,You need and the property loaded automatically by or upon any call to the Unified API plz see the details here Thank you very much Was searching for this question but didn t caught it Just one more question active will be false if only deposit can t be made or only withdraw can t be made or both can t be made And it is true when deposit and withdraw can be made Just one more question active will be false if only deposit can t be made or only withdraw can t be made or both can t be made And it is true when deposit and withdraw can be made Yes that is correct if the currency is not withdrawable and or cannot be deposited the flag is set to false However you may want to pay attention to the data you get from the exchange in question since this really depends on the underlying exchange API and not all exchanges provide that info from their APIs Hope that helps Got it Kroitor you are king,No
18798,pr,specify virtual_delegate types to avoid deadlock,specify virtual delegate types to avoid deadlock the attribute type for delegates required the target method to be loaded This forced a string of load schema calls that introduced a race condition This PR explicitly declares the attribute type so target class no longer needs to be loaded and the race condition and deadlock are avoided,changed the over to that seems to be the type that would be detected it s still failing Checked commits with ruby rubocop haml lint and yamllint files checked offenses detected lib miq expression target rb x warning Line Col Do not chain ordinary method call after safe navigation operator spec lib rbac filterer spec rb x exclamation Line Col Align the elements of a hash literal if they span more than one line A hammer version of this code is put into a separate PR there were conflicts back porting this The main issue is that hammer does not have the virtual attributes functionality as a separate gem,Yes
2478,pr,server https tls 1.0 removal,server https tls removal Info As of February contemporary browsers Chrome v Firefox v IE v Opera v and Safari v support TLS and TLS TLS is still widely used as the best protocol by a lot of browsers that are not patched to the very latest version It suffers from CBC Chaining attacks and Padding Oracle attacks,,Unsure
45084,pr,[2.7] ACME: fixing typo in acme_certificate docs,ACME fixing typo in acme certificate docs SUMMARY Backport of fixes typo in module cross reference name i e fixes broken link ISSUE TYPE Docs Pull Request COMPONENT NAME acme certificate ANSIBLE VERSION,cc here for bot shipit Thanks for reviewing and merging,No
4533,pr,Feature test encoders,Feature test encoders Description Adding tests to encoders py,,Unsure
7179,pr,"fix ""`persistent_cookie_path': undefined method `tmpdir' for Dir:Class (NoMethodError)"" for client.rb ",fix persistent cookie path undefined method tmpdir for Dir Class NoMethodError for client rb fix for issue,,Yes
3736,issue,ufuzz failure,ufuzz failure ,most likely a V bug minus can t reproduce on Node js the reduced test case always gives me on my local copy of Node js and locally gave me The original uglified code produces the correct result on all node versions As you say has to be a V bug for var brake a a length brake brake Suspicious compress options evaluate Where did this test case come from Are you sure it s not the fake evaluate xor bug It s from GitHub Actions of my fork which is an identical copy of this repository So wait it doesn t give any reduced test case for you when you do on Node js No test cases produced on latest master with any NodeJS version I tried Which makes sense because the initial uglified code above also produces the same result as the original Do you see a different result Wow that s messed up The globals must have changed between node v and Node js v and later versions Wow that s messed up Interesting same version of Node produces different results Some random transient global s or perhaps a non deterministic for in order for globals But we aren t probing the content of the global object though that evaluates to either or throughout all iterations Side note if a given version of NodeJS produces a different result each time then all bets are off for the reduced test case It breaks a basic assumption of the reduce test algo Fully explains why it gave difference reduced test cases between Github Actions and locally a this Good point Odd Do you see anything odd on Node if you apply the following patch to the reduced test case That s how I work out what gives minus just a big bunch of them sometimes with the negative sign sometimes don t In case of an extraneous space might need So the sign is not deterministic That seems to be the issue yes v Just curious why you prefer Node v for ufuzz over v Is it faster keeps tripping over the latest version of Node js e g so ended up with v for stability I assumed letting job fetch the latest version of v is safe enough but I guess this is being challenged as well,Unsure
410,issue,'ciphers' is undefined when run ./algo update-users,ciphers is undefined when run algo update users OS Environment Ubuntu LTS Ansible version don t know Version of components from pip show all the packages from requirements txt PUT THE OUTPUT HERE DON T NEED TO PASTE requirements txt Summary of the problem Run algo update users it shows failure TASK Build the client ipsec config file failed localhost item dan failed true item dan msg AnsibleUndefinedVariable ciphers is undefined failed localhost item jack failed true item jack msg AnsibleUndefinedVariable ciphers is undefined Steps to reproduce the behavior The way of deployment cloud or local Expected behavior Actual behavior Full log,,Unsure
13415,issue,Memory leak OpenRA,Memory leak OpenRA Hey guys I have a GB ram system it seems that OpenRa is just inflating till it runs out of memory This happens both in the mainscreen and during play System OutOfMemoryException T set Capacity System Int value x a in private tmp source mono bockbuild mono branch profiles mono mac xamarin build root mono x mcs class referencesource mscorlib system collections generic list cs at System Collections Generic List T Add T item x in private tmp source mono bockbuild mono branch profiles mono mac xamarin build root mono x mcs class referencesource mscorlib system collections generic list cs at OpenRA Network SyncReport GenerateSyncReport OpenRA Network SyncReport Report report x d in at OpenRA Network SyncReport UpdateSyncReport x in at OpenRA Network OrderManager Tick x e in at OpenRA Game InnerLogicTick OpenRA Network OrderManager orderManager x fd in at OpenRA Game LogicTick x in at OpenRA Game Loop x d in at OpenRA Game Run x in at OpenRA Program Run System String args x in at OpenRA Program Main System String args x f in Red Alert Mod at Version release on map ab e a cc feaf d b d d ca God s Great Divide Fixed Non Faction by Vigor God Stex AMHOLE Date Z Operating System OSX Unix Runtime Version Mono mono branch d CLR Exception of type Out of memory GC Memory post collect GC Memory pre collect Working Set Private Memory Virtual Memory at wrapper alloc System Object AllocVector intptr intptr at System Linq Buffer T source x in private tmp source mono bockbuild mono branch profiles mono mac xamarin build root mono x mcs class referencesource System Core System Linq Enumerable cs at System Linq Enumerable ToArray TSource System Collections Generic IEnumerable T x x in at wrapper delegate invoke System Action OpenRA Traits ITick invoke void T OpenRA TraitPair T e System Action,Duplicate of,Yes
759,issue,"in iPhone X above models , menu goes to safeArea ",in iPhone X above models menu goes to safeArea Screen Shot at,Same problem Any solutions For me it is not clear enough what is wrong on the screenshot Check the pull requests section there are some with safe area issues e x your right I should be more specific here is the screenshot of iPhone XLPagerTabStrip should be shown like this Hello Now it more clear Title Trailer is under the notch Can you attach minimal project where issue is visible To check the layout constraints I assume it depends on layout as not many people encountered it I think this issue still exists and it s affecting ios where view controllers are shown modally in a page sheet the title is not visible even though the top of the page sheet is below the notch when I change the view controller s presentation to full screen the title appears again The question is how do we support the new ios page sheet style Yes I am also facing the same issue In Demo the view controller is presented so there is no issues But When I present modally It works fine One workaround I found is to use separate view for the buttonBarView Empty ButtonBarView and attach it to the outlet in the controller then you can place it right in the view,Yes
2434,issue,Wrong signature for FlyoutBase events,Wrong signature for FlyoutBase events Current behavior Uno s and events have the signature while UWP s have Expected behavior Though you can discuss the poor design decision of choosing Uno should have followed that signature How to reproduce it as minimally and precisely as possible Create a new Uno application Add a somewhere Handle the event with Compile for all platforms Result It only compiles for UWP On other platforms you get error CS Cannot implicitly convert type System EventHandler to System EventHandler Environment Nuget Package Affected platform s x iOS assumed x Android x WebAssembly x macOS assumed Windows Build tasks Solution Templates Visual Studio version x version for Mac version,Thanks Martin That s indeed not a discussion we re having I ll add reference this issue in that will be used to adjust signatures In the meantime the define can be used to discriminate APIs in user code,Yes
1244,pr,tls_wrap: fix BIO leak on SSL error,tls wrap fix BIO leak on SSL error Fix,cc Cecil May ask you to gist a test case that your are using Thank you On Monday March Cecil Worsley notificationswrote I found a pretty simple way to reproduce this I created an HTTPS hello world server and another process that produces hundreds of HTTPS get requests sec In io js I found the memory leaking exponentially but not in node Perhaps this could make it easier to test this issue I m not a C guy but seems like a simple way to test the hypotheses Reply to this email directly or view it on GitHub Shoot I accidentally deleted my comment But sure I can do that I have been running the test for a few minutes and on node memory climbs and then flattens out io js consumes multiple gigs after running for the same amount of time I ll post the gist in a few Example gist have to generate your own SSL Cert but this should pretty clearly running it locally now will report back here do not let this stop you though This commit is surely fixing some leak just to make sure what io js version are you using I just duplicated the issue in and Interesting I see some leaks in a client code Will check it in a bit Leaks in the code I provided Not sure about containment yet but I am able to confirm it with your test case Thank you On Tuesday March Cecil Worsley notificationswrote Leaks in the code I provided Reply to this email directly or view it on GitHub I m glad to hear it Of course let us know what you find or if I can provide anything else to the effort Update PR with a fix thank you so much You helped a lot this should fix your leak guys cc at least I have lots of hope for this Haha Deploying Do you guys think this PR will make it into CI for the comments Redeploying grinning The CI appears to be blue LGTM Landed in e b d ccc f Thank you,Yes
5769,issue,Root password problem,Root password problem A star is visible before configuring the password Root password BLANK auto generate it After introducing the root password I got the message below Exception in thread main com orientechnologies orient core exception OSecurityException Cannot create a key with PBKDF WithHmacSHA algorithm at com orientechnologies orient core security OSecurityManager getPbkdf OSecurityManager java at com orientechnologies orient core security OSecurityManager createHashWithSalt OSecurityManager java at com orientechnologies orient core security OSecurityManager createHash OSecurityManager java at com orientechnologies orient server OServer addUser OServer java at com orientechnologies orient server OServer createDefaultServerUsers OServer java at com orientechnologies orient server OServer loadUsers OServer java at com orientechnologies orient server OServer activate OServer java at com orientechnologies orient server OServerMain main OServerMain java Caused by java security NoSuchAlgorithmException PBKDF WithHmacSHA SecretKeyFactory not available at javax crypto SecretKeyFactory SecretKeyFactory java at javax crypto SecretKeyFactory getInstance SecretKeyFactory java at com orientechnologies orient core security OSecurityManager getPbkdf OSecurityManager java more,hi I was going to write this in the changelog right now java does not have the PBKDF WithHmacSHA algorithm embedded so you have to choose a differnet one with Dsecurity userPasswordDefaultAlgorithm PBKDF WithHmacSHA or adding an entry in the orientdb server config xml in properties block Time to upgrade to Java stuck out tongue winking eye Scott Right I moved to JDK and everything is oke Root password BLANK auto generate it The first star is it normal looks like a space Yes the first start is it normal,Yes
1861,pr,[1847] Activator.CreateInstance call protected constructor,Activator CreateInstance call protected constructor Fixes is still limited Constructor with will not be found Constructors with similar number types like byte and int will be considered as similar If no metadata then constructor search will use parameters count only as base If several constructors found then exception is thrown If constructor is not found then default constructor will be used,,Yes
8182,pr,Fix concurrent tarball resolution race condition,Fix concurrent tarball resolution race condition Summary Partially fixes The original issue root cause is a case where we use a specific temp folder while another async piece of code decides to delete it This root cause happens in two occasions when resolving tarballs using and when resolving packages from github that have a prepare script which uses although I m not sure it happens only in this case This PR is attempting to fix the tarball resolving scenario I described the exact scenario in this my company we started using a generic storage for npm packages that shouldn t be in the registry thus using urls to tarballs and installations keep failing randomly which drove us to find this issue and fix it Test plan Since this issue is sporadic it might be hard to test it on an integration level Furthermore we need to create a custom setup as described in the comment above I have a thought about how to do the setup using a local static file server although I first wanted to see if my approach is valid before I invest a few hours on it Thank you for taking the time to read and review the PR This issue is blocking us and we ll do whatever we can to fix it we just ask your attention and guidance where needed,,Yes
110,pr,"Use name, not signature of the symbol",Use name not signature of the symbol Use name not signature SourceKit return signature rather than nameeg for function,Can you clarify what behaviour you are seeing vs what you expect In Swift the argument labels are part of the name so I would expect them to show up for functions a signature is or while the name is or LSP defines just a name for and signature for In Swift the terminology would be base name name signature Is there a concrete issue showing the full name in editors VSCode has no trouble with it for example SourceKit return parameters as children see below that could be a separate symbol as far as I understand In Swift the terminology would be base name foo name foo x signature foo x Int Float Is there a concrete issue showing the full name in editors VSCode has no trouble with it for example I didn t look what VSCode is doing with the name Where this call is used in VSCode I expect here base name eg to locate the function name not the function declaration Now I have doubts though I may be wrong in spec interpretation I didn t look what VSCode is doing with the name Where this call is used in VSCode The Outline view I expect here base name eg to locate the function name not the function declaration Now I have doubts though I may be wrong in spec interpretation The LSP spec doesn t really say anything about this it just requires that it s a displayable string below I think it s reasonable for a language server to use its own semantics for what is a name and in Swift I think the full name is a better choice than the base name I think it s reasonable for a language server to use its own semantics for what is a name and in Swift I think the full name is a better choice than the base name Agree Thanks for pointing this out,Yes
101,issue,Question about jekyll-assets and site.static_files array,Question about jekyll assets and site static files array Background I use jekyll assets and I have written a plugin of my own which optimized images This plugin depends on array which Jekyll exposes for image optimization plugin used to work as all my images were located outside of jekyll asset s sources in folder at project root As jekyll assets makes handling image assets easier as well and I moved my images to Jekyll and jekyll assets work fine and serve my posts with images correctly BUT now the array does not contain my images anymore which means that my image optimization plugin doesn t optimize anything The actual question s Is it by design that jekyll assets plugin does not include assets handled by it into If it s by design could there be anyother way of tapping into the assets used or in my image optimization plugin should I just glob through the folder and collect the files with that Or could this be a bug in jekyll assets or just misconfiguration on my project,It actually includes them Right before they are not normal StaticFiles of Jekyll The best option you have is to hook right into sprockets to post process your images and jekyll assets will respect that Here s for example how to use I could not have hoped for better answer I was using image optim as well and you just basically gave me a ready made solution I only had to add some of my envinronment checking logic etc configs project specific and I m done now Seriosly thanks You re awesome I m glad that helped D Do preprocessors run before or after proxies I use magick to resize crop the images and was considering the solution in however not having to add a proxy to each img tag makes this solution quite attractive Does the optimized images replace the old images or they are created in another folder because I don t see other folders and size change for the moment I have for example KB and KB too and this in build script Optimized images aren t replaced in your source in that we don t alter your actual source files we alter them and store them in or whatever your cache folder is and then we use that You should check your cache folder and you should see a folder for the actions we do outside of Sprockets Thanks hmm ok I had that folder in gitignore so that might be the problem well no it s just used at build time but I still don t know why the served images have same size I ve checked the content of asset cache I don t see anything that looks like an image I deploy site and site assets with different options I don t understand well where I could find the optimized images Following up on first question concerning the order of preprocessors and proxies the image optimization solution posted on the works perfectly except in cases where an image magick proxy is used to resize the image I believe what happens is the image is optimized and then resized effectively producing an unoptimized image The solution proposed in avoids this issue but requires adding a new proxy to every image Is it possible to use the wiki solution but postpone optimization until the images have been resized,Unsure
7919,issue,Inclrease CloudFlare captcha verification timeout,Inclrease CloudFlare captcha verification timeout Issue Description Browsing freecodecamp behind an IP blacklisted by CloudFlare triggers the captcha challenge too often every minutes in my experience I ve been experiencing it since last week I left some time pass to be sure that it wasn t a measure against an attack Could you consider increasing the revalidation time to day or at least some hours It s very frustrating to be interrupted by captchas often in a row while working on the exercises,I ll look into it Can you give me some information Location Are you using a VPN If so which Yes VPN Most major commercial VPNs are affected by CF captchas on all locations see reports at reddit for instance it won t help to whitelist IP ranges for a particular one if you remember I was am also affected by this wink Location Pune INDIA VPN None ISP Doesnt stay fixed it keeps changing between networks because my vendor randomly assigns each subscriber to a different ISP Network depending upon load time etc IP Willing to provide over chat Fix I have a tested fix for this I checked on my own domains for that and seemingly it works Can discuss more on it I ve increased the timeout to an hour Do you mind send me a PM on that fix,Yes
29723,pr,Clarify db_user and db_password kwargs for postgres_user.present state function,Clarify db user and db password kwargs for postgres user present state function Fixes,,Yes
36,pr,Custom Keyed Subscripting,Custom Keyed Subscripting Implementing Custom Keyed Subscripting to not have to call objectForKey,Any more issues with my commit,Unsure
61,issue,Support the openssl standard library,Support the openssl standard library We are implementing support for using as described in our RubyConf talk Ruby s C Extension Problem and How We re Fixing comment on progress in this issue Feel free to ask questions or contribute in any other way,looks tremendous Where can we follow along the progress of getting OpenSSL to work via Sulong From what I quickly gathered and perhaps I m wrong there will be some kind of a fork of or commits to OpenSSL that will get it prepped to compile properly with and this is where your effort is going to come in in terms of what you re saying here Ultimately it would seem that this will be a support step for installation as it will have to grab this version of OpenSSL or compile it itself via during the install process This is quite a selfish inquiry as I d love to follow along and probably many others so that we could get a feel for how to convert other programs or libraries over with and this seems like a perfect opportunity Where can we follow along the progress of getting OpenSSL to work via Sulong That s what this issue is for From what I quickly gathered and perhaps I m wrong there will be some kind of a fork of or commits to OpenSSL that will get it prepped to compile properly with sulong and this is where your effort is going to come in in terms of what you re saying here Yes I may modify openssl in place I then hope to go back and fix the need for any modifications later on Ultimately it would seem that this will be a support step for rvm installation as it will have to grab this version of OpenSSL or compile it itself via sulong during the install process It should come ready to use in the GraalVM bundle Where can we follow along the progress of getting OpenSSL to work via Sulong If you mean how to build it yourself Yes wanting to follow along with your code changes in order to get an idea of the workflow at converting our own C etc projects over to run via Sulong Thanks I ll post things here next time I do some commits so you can see concretely what I m doing From what I quickly gathered and perhaps I m wrong there will be some kind of a fork of or commits to OpenSSL that will get it prepped to compile properly with sulong and this is where your effort is going to come in in terms of what you re saying here Just to clarify we might need to modify the code of the openssl C extension but we do not plan on touching the OpenSSL library itself but rather use the system installed library Today I m looking at how to implement It s a simple function but happens to trip up a few things that Sulong doesn t implement as well as we d Trying to implement as a macro Related to C extensions I m looking at implementing in We ve been working on C extension specs for the last week to hopefully make it easier to run openssl without encountering so many bugs It really looks like you re mowing down rather quickly We can now load the C extension and the associated Ruby code that sets it up We pass most of the specs for it but can t even successfully run the setup for the MRI tests for it And actually trying to use it doesn t work Progress is pretty quick now though You re doing fantastic Been tracking your updates and commits Several of us have been here in the background silently and cautiously cheering you on and are very excited We can now run the setup for the MRI tests so we ve got a large number of fine grained tests we can now work through All the specs now pass There s still lots of tests and it still doesn t actually work I m having some trouble with what I think is undefined behaviour in which Clang happens to accept but Sulong is more strict about and detects as seems to basically work now for making requests that use We still need to integrate so it s available by default I am glad that the system provided OpenSSL library is being used A lot of the crypto stuff makes assumptions regarding timing that might break on a JIT and besides much of it is in assembly anyway And none of it accesses Ruby objects yes definitely right for OpenSSL but I should just also mention that Sulong can actually handle inline assembly as well Nice Does it treat it the same way as ex GCC or Clang I think it still interprets and just in time compiles the assembly instructions rather than copying them into machine code It all has to work on a standard JVM where you can t just emit machine code whenever you want is now enabled by default on master We re now merging this into the next GraalVM release Great work guys Really excited to see you forging ahead here Giving you a little love over on think Rails users will be most interested in this at the moment for server purposes and I think that s your primary target right now from listening to your talks etc Please correct me if I m wrong The next version of GraalVM will include this by default,Yes
31,pr,Fix XSS vulnerability in sanitization filter,Fix XSS vulnerability in sanitization filter The default settings for the class was whitelisting list and table child elements living outside of their containers li tr td th This fix which removes the illegal elements in the default whitelist Thanks to for the patch This fix will be released in version cc,,Yes
386,issue,Allow HTTPS with self-signed certificates if SUPublicDSAKeyFile provided,Allow HTTPS with self signed certificates if SUPublicDSAKeyFile provided Reviving with the slight twist of allowing self signed certs if is provided This is just as secure as CA signed certs Only difference is that it doesn t require developers to shell out to CAs,OK I think that makes sense This is just as secure as CA signed certs Erm I meant to say it is just as secure as CA signed cert It is significantly more secure than HTTPS with CA signed cert without Is that still needed given we have Let s Encrypt and also ATS restrictions,Yes
773,issue,LinkedIn authorised calls,LinkedIn authorised calls Hello According to this apidoc way I make authorised called to LinkedIn API v is done appending the Header But I can see that the current implementation append a query parameter called to the endpoint called Here And here I call any endpoint with this way I get Forbidden response code,Thanks the master Hello I ve made the changes on my project with scribejava library updated and I keep receiving the same response as always errorCode message Invalid access token requestId PK SG IT status timestamp Everything seems to be ok with my access token since I use the same token on Linkedin j Api to make a Profile post and it is done successfully Do you have any update on that Obs After updated scribejava library ServiceBuilder is now deprecated do you have an alternative for it My code OAuth Service service new ServiceBuilder apiKey InsertByLinkedInAction CLIENT ID apiSecret InsertByLinkedInAction CLIENT SECRET scope r basicprofile r emailaddress rw company admin w share build LinkedInApi instance OAuth AccessToken accessToken new OAuth AccessToken profile getToken JSONObject obj new JSONObject obj put code anyone JSONObject obj new JSONObject obj put title Test Share with Content obj put description content description JSONObject obj new JSONObject obj put visibility obj obj put comment Check out developer linkedin com obj OAuthRequest request new OAuthRequest Verb POST profile getIdProfile shares OAuthRequest request new OAuthRequest Verb POST application json request addHeader x li format json service signRequest accessToken request Response response service execute request Any comment would be appreciated and I thank you guys in advance Obs After updated scribejava library ServiceBuilder is now deprecated do you have an alternative for it read javadoc on this constructor for the answer As for the main question can you see raw request from Linkedin j Api and compare it with ScribeJava request,Yes
137,issue,Error handling - Add login error,Error handling Add login error Add a message when the user performs an unsuccessful login in the manager UI,,Yyes
7360,issue,Fix multi-tenant login subscription list in CloudSHell,Fix multi tenant login subscription list in CloudSHell Description CloudShell uses a special implementation of MSI credentials which have permissions across multiple tenants Unfortunatey the MSI endpoint does not allow listing getting tokens for multiple tenants WHen listing subscriptions this causes the subscriptions in the current tenant to be listed multiple times x Skip listing subscriptions for each tenant in MSI list subscriptions only for the given tenant x Verify execution in CloudShell with a subscription with multiple tenant access Cost,Done,Yes
20276,issue,Extend null-safety to field level [SPR-15720],Extend null safety to field level SPR Juergen opened and commented After the measures in we have consistent declarations at the method parameter and return type level already It turns out that at the field level is an essential companion avoiding mismatches between methods and the fields that they access Also Eclipse only supports full nullability through annotations that is it doesn t differentiate between parameter level and field level Extending our semantics to the field level makes it easier to set those up for Eclipse as well Affects RC Issue Links Introduce null safety of Spring Framework API ExceptionHandlerMethodResolver loses all handler methods Exporting a lazily initialized bean which implements SelfNaming and is annotated with ManagedResource annotation gives IllegalStateException org apache tomcat websocket WsSession requestUri can be null JSP tags doesn t pick up JSTL defined time zone at page level SpEL Indexed access within an expression with null variables is no longer a SpelEvaluationException Revisit nullability annotations towards GA Backport selected refinements from the nullability efforts in Make getters and setters null safety consistent Referenced from commits,,Yes
2654,pr,Don't hide skipped assets during precompile.,Don t hide skipped assets during precompile It s hard to know your assets are being skipped because we don t print it by default,Hopefully this will make it more obvious when we aren t precompiling assets Checked commit with rubocop file checked offenses detected Everything looks good cake,Unsure
6075,pr,SslHandlerTest ByteBuf leak,SslHandlerTest ByteBuf leak Motivation We are now more careful to flush alerts that are generated when errors occur We should also be more careful in unit tests to release any buffers that may be queued due to potential errors wich result in alerts Modifications When SslHandlerTest uses EmbeddedChannel we should always call finishAndReleaseAll Results Fixes,FYI thanks a lot Cherry picked into c ae bdb ac c f ca aaaba fe and d f d d bb e ee e c f dbe e,Yes
56,issue,String cache is not thread-safe,String cache is not thread safe SBJsonStreamWriter is currently safe to use only from one thread due to the shared stringCache variable A few possible solutions in my favorite order Move the cache into the instance This makes sense since it frees up the memory as soon as it is done as suggested in Use NSCache instead of NSMutableDictionary It is explicitly thread safe though requires iOS OS X Use OSSpinLock or a mutex around dictionary accesses This makes the cache thread safe though imposes a performance penalty Use a per thread dictionary e g using pthread key t This will have about the same performance as the current implementation with additional memory overhead,An alternative to suggestion is to use which is a per thread that keeps automatically You can use it much the same way you would a but without the hassle of managing a pthread key This should be fixed by,Yes
11207,issue,dialog: leaking detached DOM nodes,dialog leaking detached DOM nodes Bug feature request or proposal Bug What is the expected behavior Using mdDialog with custom template should not result in detached DOM nodes What is the current behavior When using mdDialog and after closing it via mdDialog hide the heap snapshots show lot of detached DOM nodes which point to in mdDialog service Check out the heap snapshot screenshot screenshot from tried to figure out the internals and i think mdDialog is setting up some kind of internal cache which re uses things when same modal s are opened multiple times but i failed to identify it concretely and clear those detached nodes from memory I target to run my application on raspberry pi and it has quite a few modals hence increasing detached dom node count is warning signal for me leading to memory exhaustion over time Hence i guess i need someone to familiar with internals to point me in right direction and if at all there is something leaking with mdDialog CodePen and steps to reproduce the issue CodePen which shows your issue I will try to reproduce this issue on codepen but as of now i don t have a pen Detailed Reproduction Steps I am using ui router and while switching between states if i open a modal with custom template and close it and then check the snapshot it shows detached nodes Those nodes don t show if i don t open modal at all Which versions of AngularJS Material OS and browsers are affected Angular js OS linux ubuntu browser chrome,What version of AngularJS Material is in use Please provide a demo and reproduction steps for checking the heap and observing detached nodes Also are the nodes eventually garbage collected over time or do they keep accumulating Angular material version forked I have created a basic repro must note that although there are detached nodes in the pen i mentioned above the retainer graph is for them is not the same as i have in my angular application But maybe this example might help in debugging Steps to reproduce open pen and take a heap snapshot open dialog by clicking TEST button and close it by pressing ESC or area outside the modal again take a heap snapshot and notice the newly added detached dom nodes more than nodes approx show up also check out Scope tree in last heapshot and we find the whole controller for mdDialog is present even though it is destroyed Check out the images below showcasing both the issues Also are the nodes even garbage collected over time or do they keep accumulating From what i see they are not being gc ed even though i fired it manually but at the same time when they do not keep accumulating if it open the same dialog multiple times Maybe its caching at play here screenshot from from also mentions that is leaking memory has some additional debugging information that is related to this issue Here s a link to the original built on Here s that same CodePen upgraded to and I see the new instance created on the Scope for each time the dialog is opened and closed but the previous instance s Scope has been removed As for the Detached DOM tree mentioned above I m still working on finding this as it appears the Chrome DevTools have renamed these and made the Detached nodes more granular It looks like they may be listed under Detached HTMLDivElement now If I look at Detached HTMLDivElement in I see the following trend with heap snapshots after each open close of the dialog x x x x x x x x Heap snapshot size starts at MB and increases to MB where it stabilizes between MB With I see the following trend x x x x x x x x Heap snapshot size starts at MB and increases to MB where it stabilizes between MB So there does appear to still be an issue with leaking detached DOM nodes related to opening and closing of s However it s not clear that this is actually leading to a significant JS Heap memory leak as the JS associated with these nodes does appear to be getting GC d I did a profiling run where I opened and closed the dialog every few seconds This is the result Screen Shot at can see that the JS Heap isn t leaking but that we keep generating more and more DOM Nodes and listeners each time the dialog is opened and closed We start at DOM nodes and listeners and end up with DOM nodes and listeners after just s,Unsure
605,pr,Catch timeout exceptions on login,Catch timeout exceptions on login Issue,,Yes
424,issue,[Security] Dapp browser check if url is blacklisted,Security Dapp browser check if url is blacklisted some references,Infura provide access to the MetaMask blacklist Documentation Thanks Sounds like we might fetch this list of startup of the app and then do checking As author of H EtherAddressLookup please use metamask eth phishing detect lists i also maintain that list too but I am deprecating the EAL list in some months in favour of metamask eth phishing detect will be placing notices shortly We could also explore the possibility of using to display notices to people when sending ETH to a known blacklisted x address We can also push to get product owners to push their legitimate x addresses to EtherScamDB for Trust Wallet to use and show a small VERIFIED icon Happy to discuss anything relating to EtherScamDB and metamask eth phishing detect when you have time,Yes
7555,issue,Improve informations about module nginx failing create or renew certificates,Improve informations about module nginx failing create or renew certificates All Operating Systems All certbot version Certbot s behavior differed from what I expected because Sometimes nginx has too much configurations files which lead it to reach its open files limits At this point doesn t reload configuration but it exits with the state and do not print errors messages You have to check in var log nginx error log to see that it fails reloading the configuration because too much open files So certbot fails to reload nginx while changing the configuration for authentification So let sencrypt fails authenticating So certbot give you Authentication fails What is expected nginx reload must exit with state error Certbot may Informs user that error comes from nginx reload failed and stop without trying auth Try restart if reload is not enough,To be clear when this happens nginx claims that it exited successfully and doesn t print any errors This seems difficult for Certbot to catch in that case To be clear when this happens nginx claims that it exited successfully and doesn t print any errors This seems difficult for Certbot to catch in that case I think this is the same problem that is at the root of All does is There is no mechanism for actually knowing whether relevant to this issue or when relevant to the other issue the reload actually succeeded A potential but probably too complex solution Certbot could put a canary virtual host in the configuration not a public domain only listens on loopback that it could use to verify that the configuration has reloaded up to some timeout A potential but probably too complex solution Certbot could put a canary virtual host in the configuration not a public domain only listens on loopback that it could use to verify that the configuration has reloaded up to some timeout Ok maybe it could be part of the explanation of the error at least,Yes
1012,pr,Define Nanoc::Int::Context checksum,Define Nanoc Int Context checksum Fix for,,Yes
187,issue,where is the css asset ?,where is the css asset only support js bundle,What do you want to see inside a CSS chunk just like the js chunk I guess the size the dependencies don t know whether it s doable Yeah I also expected to see all assets that webpack emits so fonts images css html js That way I can get a sense of size and dependencies for all of these things If someone wants to take a stab at this it would help a lot Even a small sample repository using CSS assets fonts images what have you would be nice as then we could discuss how would an output for such a project look like I ve been looking into this and would like to see if I can help on this I ve spent the day understanding how this plugin works interacts with webpack I ll start working on a sample repo with multiple asset inclusion I assume the plan would be to use that to generate a webpack stats file to write tests for I ve been looking into this and would like to see if I can help on this Thanks I ll start working on a sample repo with multiple asset inclusion Sounds great I assume the plan would be to use that to generate a webpack stats file to write tests for I m not sure how we will end up using the sample repository yet Writing tests might not be enough as we will also want to figure out how we d like the output to be displayed in the generated treemap So it might need some design iteration first before we write tests After a bit more investigation I think we can split this up into problems Singular assets e g images fonts Concatenated assets e g css js The first problem only requires us to find which src asset was turned into which output asset From there it could be displayed in the visualiser in the correct chunk s The second problem requires us to have this mapping for each file For JS this is done by creating an AST from the output asset and reverse engineering the webpack bundling process This won t be possible for styles as they re just concatenated and this won t let us know where they came from I agree this needs more design before we move forward but I ll continue to make a helper repo that bundles assets in different ways I ve got a couple ideas of how to solve these Singular We can still make progress on images fonts We can treat css as a single asset it won t say where it came from but better than nothing Concatenated We could offer this if people provide source maps We d be able to find out exactly what src styles end up in the css assets This might work for js too This would mean re writing all the parsing internals Would be interesting to see how the output will look like once you get the helper repo in place relaxed I m not sure if the concatenated version would require re writing all parsing internals we already do support concatenated modules but it just might need some additional work to work for CSS too any news about this amazing feature Quick repo that builds scripts images and styles This has index css importing a css and b css This shows the size of the css asset created but doesn t show the src files inside and this suggested feature would solve that I think I used concatenate badly in the previous comment and didn t mean concatenated modules I was trying to say that the output files leave behind how webpack bundled them But with css they re just concatenated and there isn t a way to tell where they came from that I know of I would love to see a chunked view of my app css I have over scss files and some of them look deceivingly simple but include a while loops so at a glance they don t look that large It would also help me to reduce redundant CSS being served If you don t use a css and b css will show in is that CSS extracted from Javascript or processed from SCSS I think its that causes the problem I will look into these loaders and find out why only use use css loader and webpack explains why In the case of the less loader it cannot transform each to a require because all less files must be compiled in one pass for variables and mixin tracking Therefore the less loader extends the less compiler with custom path resolving logic It then takes advantage of the second approach this resolve to resolve the dependency through webpack less loader or sass loader transform to instead of maybe webpack can t work out the relationship between style files without,Unsure
4287,pr,renovatebot(deps): update dependency org.owasp:dependency-check-gradle to v5.2.2,renovatebot deps update dependency org owasp dependency check gradle to v This PR contains the following updates Package Update Change patch Release Notes jeremylong dependency check gradle Renovate configuration date Schedule At any time no schedule defined vertical traffic light Automerge Disabled by config Please merge this manually once you are satisfied recycle Rebasing Whenever PR becomes conflicted or if you modify the PR title to begin with no bell Ignore Close this PR and you won t be reminded about this update again If you want to rebase retry this PR check this box This PR has been generated by Renovate,,Yes
422,pr,Change ZipOutputStream.PutNextEntry to explicity validate the requested compression method,Change ZipOutputStream PutNextEntry to explicity validate the requested compression method Equivalent of but for ZipOutputStream I added this to throw NotImplementedException and then wondered again if it should be that or NotSupportedException PR Doesn t add a unit test as the CompressionMethod property setter on ZipEntry currently prevents it so the only way to try it would be to use a ZipEntry with a different type from an existing file I certify that I own and have sufficient rights to contribute all source code and related material intended to be compiled or integrated with the source code for the SharpZipLib open source product the Contribution My Contribution is licensed under the MIT License,,Unsure
346,pr,updated target platform to include jax-rs security provider,updated target platform to include jax rs security provider Signed off by Kai Kreuzer,fixes,Yes
16612,issue,Can't connect to self-hosted server with self-signed certificate from android app,Can t connect to self hosted server with self signed certificate from android app Description Can t connect to self hosted server with self signed certificate from android app I did also tried to manually add the certificate in android Steps to reproduce install rocketchat server snap enable connect with the android app Expected behavior Should ask if accept un trusted authority Just like the desktop app Server Setup Information Version of Rocket Chat Server Operating System Ubuntu Deployment Method snap NodeJS Version v MongoDB Version Client Setup Information Desktop App or Browser Version Operating System,To clarify have you Have configured a reverse proxy Used when attempting to connect,Yes
195,issue,invalidateAllHeightCache:和invalidateHeightAtIndexPath:无效,invalidateAllHeightCache invalidateHeightAtIndexPath CGFloat tableView UITableView tableView heightForRowAtIndexPath NSIndexPath indexPath if self isGetCacheHeight tableView fd indexPathHeightCache invalidateAllHeightCache CGFloat height tableView fd heightForCellWithIdentifier NSStringFromClass Demo class cacheByIndexPath indexPath configuration id cell self configureCell cell atIndexPath indexPath return height kDefaultCellHeight height kDefaultCellHeight invalidateAllHeightCache invalidateHeightAtIndexPath,,Unsure
4561,issue,App is crashing when using FieldArray with 'validate' props,App is crashing when using FieldArray with validate props Are you submitting a bug report or a feature request bug report What is the current behavior My app throws when using with props in versions What is the expected behavior Be able to use FieldArray with custom validator Sandbox Link Working What s your environment,I was trying to find the problem with my suggestion input and I never thought can be the validate prop Finally found thanks So I also have this problem,Unsure
24088,pr,lib: move internalBinding whitelisting into loaders.js,lib move internalBinding whitelisting into loaders js Instead of setting the internalBinding white list in node js and wrapping process binding twice put it directly in loaders js where the user land process binding is defined,build started CI Landed in bd bba Applied don t land labels because this is building on top of,Yes
1262,issue,no-danger-with-children false positive with newline in element,no danger with children false positive with newline in element The following reports an error on the rule I would expect if there is a newline between the opening and closing tag that the rule would not complain,That s still considered children afaik why not Ah I didn t realize we could do self closing divs in jsx Still I don t think newlines between tags are considered children Hacked together this quick test undefinedundefinedundefined undefined foo ReactDOM and then fell back to what I knew off the top of my head,Yes
1074,issue,"please add ""last used"" column to oauth_clients website",please add last used column to oauth clients website I have quite a list are quite outdated but i have for example no clue which JOSM or iD auth is still used by me It would be nice if the list has a column last used additional to the created column,I don t believe we have that information Than we should collect this information ref,Yes
3957,issue,Support early freezing of forge registries,Support early freezing of forge registries Some registries need early freezing An example is a registry for tile entity block state property they should be frozen right before the registry of textures Currently all registries are frozen around load completion if you agree I might make a pull request to allow registries to freeze early,You say need in the first sentence then follow with should Which is it Can you give details why it s need It is needed An example is Railcraft s track kit track type registry in which registered entries need to provide textures It was decided that we are not making a registry sorting prioritization system All registries could be frozen at pre init as all registry functions are fired by then so you should be fine relying on the data in them at the time However in reality you should only ever trust whats in the registry at world load as thats after all id syncing and the like,Yes
2411,pr,browser(webkit): revert all changes and hacks to Page.navigate,browser webkit revert all changes and hacks to Page navigate use more robust Playwright navigate that supports PSON,,Unsure
7873,issue,Windows security alert when running the examples,Windows security alert when running the examples Description Do we have a way to get rid of this security alert when running the,this is not related to the installers you can notice this issue when you are installing ballerina without the installers with fresh JRE as well Removing the installer tag based on the previous comment Isn t this a standard warning because Ballerina tries to open ports Don t you get the same with Tomcat as well for example but we can notice this warning even when running Ballerina only in command prompt without any command But seems to be no network call or port opening in that,Yes
24663,issue,HttpListener on Unix. Windows authentication.,HttpListener on Unix Windows authentication Hello Are there plans to implement Windows authentication in HttpListener on Unix It is necessary to migrate my project on Linux,There are no such plans HttpListener is consider legacy API for compat only We recommend to use KestrelHttpServer for full cross platform HTTP server API surface I have created to document the obsoletion For more details see also our Networking Technical roadmap there is long discussion about this topic,Yes
56278,pr,[2.7] connection/docker: add privilege escalation support,connection docker add privilege escalation support SUMMARY Backport of to stable Fixes privilege escalation for docker connection plugin if a passphrase is required ISSUE TYPE Bugfix Pull Request COMPONENT NAME lib ansible plugins connection docker py,cc here for bot Merged for thanks for creating the backport thanks for merging this and all the others,Yes
81,issue,Crash dialog cannot send comments - java.lang.IllegalArgumentException: nces_decode_QR=true,Crash dialog cannot send comments java lang IllegalArgumentException nces decode QR true I ve configured ACRA to report errors to Acralyzer and the TOAST reporter seems to work fine But when I enter a comment into the crash dialog activity ReportingInteractionMode DIALOG the entire application crashes with the following stack trace Since the persister is unable to load the saved strack trace and add a comment I figured you might need to see the saved stack trace too I ve uploaded it to let me know if you need any additional information And thanks for making such an awesome tool,It s crashing on line of CrashReportPersister where it s trying convert a String into an instance of ReportField Fork ACRA and wrap that line in a try catch and log the String it s trying to convert That ll steer us in the right direction I think this might be due to some device data or settings that are included in the error report but aren t properly escaped You see I can t seem to reproduce the problem anymore Yesterday it seemed to occur all the time but now I can only trigger it now and again I just tried times in a row with no luck Here s a couple error messages I did mange to extract RuntimeException are from my code It s interesting that the first couple of character eferences instead of references ntinuous instead of continous are missing It is possible that there s a similar problem with the TOAST reporter but that the IllegalArgumentException is suppressed instead So I don t think I can avoid this by simply switching to TOAST I don t really think the KEY VALUE INI format is such a good idea yes it s human readable but having to deal with all the complexity of escaping unicode is quite troubling Perhaps JSON or XML could be a better alternative Or if performance becomes an issue a raw binary format EDIT I see you ve based it on Android s java util Properties It s hard to imagine it could be the source of the problem but it is a possibility Which version of ACRA are you using ACRA I ve also tried the latest commit on GitHub In which report field these ZXing library settings are supposed to be stored CustomData Ah they re probably taken from the app s shared preferences Here s the full error Just scroll down to SHARED PREFERENCES and you ll see the different keys mentioned in the error reports above Thanks a lot for giving access to your reports I noticed a common pattern in your logcats just before ACRA crashes when inserting comments There are multiple occurences of After googling this error message I found an SO thread leading to looks like an issue with Swiftkey which you are using on your test device which seem to generate zero lengh spans in text fields which could then lead to corrupted data in the ACRA report There is a suggested workaround in adding a flag to the property of the text field I can add this or just wait for Swiftkey to fix it Hm it s possible I guess I can try uninstalling Swipe and see if I m still able to reproduce the problem Problem is I weren t able to reproduce it earlier either so it s possible that the value triggering the error has changed The test web server is down for the moment though but I think I ll be able to get it up and running on Wednesday I ll try testing the app without Swipe then I could probably get more of those saved log files perhaps by copying them to the memory card instead of outputting them to LogCat That might make it possible to spot the actual error whether caused by Swipe or not OBSOLETE,Unsure
859,issue,"Setup Postgraphile on my VPS but can't seem to access, firewall opened",Setup Postgraphile on my VPS but can t seem to access firewall opened So the firewall is open and it s the same settings as PostgreSQL I can access PSQL remotely but I can t seem to access myserver graphiql went to but it where can we get support Is this the only place I can t seem to a find a forum Thanks,n host the hostname to be used Defaults to localhost This is what you need set it to to expose to all interfaces We have chat for support going to close this as I think it s solved but feel free to keep asking questions here,Yes
2981,issue,Joplin terminal client is missing retry logic for new encryption algorithm re-keying,Joplin terminal client is missing retry logic for new encryption algorithm re keying I recall a prompt to update an outdated key within e ee settings on the desktop app and it appears this step is missing in the terminal client Could you add an issue any this in GitHub please I think I just need to enable the same Retry logic as on the other clients For additional details please see this discourse forum Environment Joplin version joplin prod Platform terminal client linux OS specifics Ubuntu LTS bionic Steps to reproduce Run joplin terminal client Modify or create note on iOS client with new encryption algorithm Sync with joplin terminal client Run joplin terminal client Notes modified and synced with old client fail to decrypt re encrypt retry fails even with upgraded terminal client Describe what you expected to happen Decryption for all notes,To close this out for anyone else finding this issue with or later run from the command line joplin e ee retry failed items decrypt Starting decryption Please wait as it may take several minutes depending on how much there is to decrypt,Yes
88,issue,PcoketLogger_API: 'require' and oauth errors,PcoketLogger API require and oauth errors When trying to run the PocketLogger API plugin I get the following errors path to slogger plugins pocketlogger api rb in require from path to slogger slogger rb in each from path to slogger slogger rb in each from path to slogger slogger rb in require from slogger,The API version is incomplete but if you wanted to play with it you could install the oauth gem in Ruby I d recommend just sticking to the pocketlogger rb plugin in the main plugins folder right now though,Yes
2699,issue,"New server, login fails",New server login fails x I understand that GitHub issues are not for tech support but for questions specific to this generator bug reports and feature requests My app was built with afs version or close to that working fine on a digital ocean server for over a year I have moved it to a new server also DO backed up the database and restored to the new server Everything works except the logins People including me cannot login to the website new registrations works Obviously i cannot see the passwords but the databases seems to be identical and the api s are working all the functionality works api etc so i can t understand what can be the reason for the login to fail Any idea The only direction i can think of is the versions Mongodb for example is now and in the old server it is Also the nodejs is newer How would you debug this thanks,What error message do you get when the login fails or or some other error message is password is not correct But the information i gave you was not complete sorry My partner did the move and he encountered an error with crypto the new version of crypto requires a new param like this the sha was not there before something is required there and he found that in the crypto expamples and that prevents the error the param name is digest you can see it who knows maybe the digest have other options and sha is not the right one I see there that you can use crypto getHashes to get all the available hashes So if i only new which one we used in the older version of crypto that would help me I believe the default used to be Yes that did the trick Thank you,Yes
126,pr,Update how HTML entities are decoded,Update how HTML entities are decoded This now includes the standard library s built in but with an extra fix up for nonstandardly uppercased entities such as itself covers some ugly cases we didn t previously cover such as long HTML entity names like entities that are missing the semicolon but unambiguous like,,Yes
18013,pr,[FIX] website_sale_option: disable csrf token for route update_option,FIX website sale option disable csrf token for route update option As this is also handled the same way in website sale routes shop cart update shop cart update json and the required token is blocking the correct workflow we just disable the token for this specific route Seems to be an oversight in refactoring after introduction of the CSRF Token May I ask you Nicolas to merge this in case Jeremy does not have the time to do so I confirm I have signed the CLA and read the PR guidelines at www odoo com submit pr,Hello Which workflow is blocked Hi to add the product to the cart the request is just blocked EDIT Well I found the reason it is a migrated instance and obviously the noupdate was set to true so the view was not updated correctly and therefore the non existing CSRF token in the form is blocking Therefore it is not needed to change the code and I close the PR Is there a reason for the other routes to have disabled tokens,Yes
60,issue,Angular REST example doesn't say username and password,Angular REST example doesn t say username and password in the README so user cannot login,,Yes
25317,pr,Fix API controller tests by assigning them the encoding type,Fix API controller tests by assigning them the encoding type Fixes The feature was added in and recommended to use for JSON endpoints so let s use it by default for API controller tests r,Lets assert the behaviour in Good point Updated tests Can confirm this fixes the issue will let tests run and merge if green This fixes the symptom but not the problem shouldn t be changing in behavior by adding a gem regardless of the request content type Yeah there re some things Jbuilder integration does specifically for rails that look nasty I don t use Rails much these days and don t really have time to dig into that but it looks like a huge timesink Would definitely appreciate any help resolving this on the Jbuilder s side Backported to stable a c agreed It s a fine temporary solution but deeper digging is required would you be interested in looking in to that Yeah why not On Tuesday June Kasper Timm Hansen notificationswrote agreed It s a fine temporary solution but deeper digging is required would you be interested in looking in to that You are receiving this because you were mentioned Reply to this email directly view it on GitHub or mute the thread prathamesh GITHUB agreed It s a fine temporary solution but deeper digging is required I d prefer to avoid adding bandaid fixes if we can avoid it I d argue this isn t even really a great temporary solution it just covers it up Is this a temporary solution If the helpers defaults to html and this is a api controller test so this code is in the correct place in my opinion It should not be handled by jbuilder or any serialization strategy you choose but from the api configuration In that case without the change the error should occur with or without jbuilder The fact that adding jbuilder is the variable here is what s concerning On Tue Jun PM Rafael Fran a notificationswrote Is this a temporary solution If the helpers defaults to html and this is a api controller test so this code is in the correct place in my opinion It should not be handled by jbuilder or any serialization strategy you choose but from the api configuration You are receiving this because you were mentioned Reply to this email directly view it on GitHub or mute the thread Without jbuilder there is no generated view and you get a No Content With jbuilder you get a generated JSON view which means an HTML wanting request is an error Steps to reproduce generate before adding jbuilder The JBuilder view gets generated as part of scaffold The issue mentioned in is fixed with JBuilder release The issue mentioned by is fixed in this commit I pushed an example app demonstrating this This is first step jbuilder tests pass before and after installing jbuilder for above commit Then I performed steps from result can be seen here the change in the controller Now we no longer have Instead we are expecting to render view In this case if the request does not have any formats set then it will still render the JSON template For eg But because we set the request encoder as HTML if none is provided in integration tests then the implicit render tries to find HTML template resulting into failure But because we set the request encoder as HTML Not exactly the error case Looking in you can see that the encoder defaults to output the values from before like content type not appending a format to the request and allowing the params through unscathed Appending is the right fix Though you could say there s a regression in the format not defaulting to,Yes
817,issue,Option to whitelist email domains,Option to whitelist email domains The env production configuration file contains a space to blacklist email domains to forbid them from signing up to an instance For those persons who would like to run an instance associated with their specific organization a whitelist might be more helpful here so only those who have email accounts with that organization can be permitted to register Would this be a feasible addition,Can anyone show a working example of this I can t seem to get my whitelist to work correctly Thank you,Yes
21807,issue,"""Invoke-WebRequest : Unable to retrieve certificates because the thumbprint is not valid. Verify the thumbprint and retry""",Invoke WebRequest Unable to retrieve certificates because the thumbprint is not valid Verify the thumbprint and retry Hello This is in regards to the previous problem I discussed Invoke WebRequest Unable to retrieve certificates because the thumbprint is not valid Verify the thumbprint and retry This problem was reproduced but the solution will not work because according to DigiCert I cannot get a SSL cert on any Microsoft Domain Hello I just tried registering my Service Fabric Cluster through DigiCert based on instructions in this post and could not I just tried to secure a CERT for my Service Fabric Cluster which I own According to DigiCert who is an Integrated partner with Microsoft when acquiring SSL You cannot request a cert on any Microsoft Domain name See Below For legal reasons we unfortunately are not allowed to issue any certificates to any domain names that are using any of Microsoft s trademarks This included azure You can review the General Trademark Guidelines issued by Microsoft themselves In the Additional Guidelines for Advertising Collateral Marketing and Product Packaging and then Websites section it reads Do not use any Microsoft trademark in the title of your website or as a second level domain name You may not use any Microsoft logo without a license or written specifications from Microsoft Sorry about the inconvenience Let us know how you would like to proceed with this order So since you CANNOT get a cert on a Microsoft Domain your solution for my WebInvoke issue will not work Import PfxCertificate FilePath lt YOUR CERT NAME gt pfx CertStoreLocation Cert CurrentUser My Password ConvertTo SecureString AsPlainText Force cannot work because I cannot obtain a CERT As I have stated before a CA verifies ownership of a DOMAIN a few ways TXT Record placing a HTML file in a certain location on the server or email ADMIN of the domain SO who can Help me get backup working properly because you cannot have as your CN an azure com domain and get a CERT Document Details Do not edit this section It is required for docs microsoft com GitHub issue linking ID f bc a c afead Version Independent ID f e d f fa aa Content Periodic backup and restore in Azure Service Content Source Service service fabric GitHub Login Microsoft Alias hrushib,please just continue the conversation you had started on your other issue That way we do not have to work on multiple issue links for the same problem user CC How do you un close an Isssue I reopened your other issue for you,Yes
56058,issue,helm: support HTTP repository authentication,helm support HTTP repository authentication SUMMARY I cannot use the helm module to deploy charts from a private repo The helm CLI has command line flags for and related documentation ISSUE TYPE Feature Idea COMPONENT NAME helm ADDITIONAL INFORMATION This would be used where someone has a private helm repository in Artifactory or similar,related issue I created on the upstream pyhelm module cc here for bot Same issue For instance if one were to us Harbor with ChartMuseum setup on a private K s cluster then this Ansible Helm module will not work as it s missing feature for authentication to private chart repos A workaround is not to use the Ansible Helm module and just use A clean example is in this,Yes
859,issue,Expand support for KeyInfo when signing and validating xml,Expand support for KeyInfo when signing and validating xml Current support for KeyInfo is limited to X Data SecurityTokenReference is used for thumbprints Others may be useful such as Subject etc See for additional types,,Yes
1655,issue,Made a change to wiki for dual username/email logins,Made a change to wiki for dual username email logins I am not intimately familiar with Devise internals so can someone please confirm it s a sane,Yup looks good Thanks,Yes
1434,pr,Schemas are now only validated once across threads.,Schemas are now only validated once across threads Fixes Prevents a long living write transaction on a background thread blocking opening Realm on the UI thread if it is the same file as we then are sure that the schema has already been validated,Any good idea to handle the multi process case This should not really effect multi process nor solve it I would much rather take that discussion in This does however prevent the number of times we do require a write transaction which will also help with multi process support Updated with feedback from,Yes
627,issue,Document reauthentication,Document reauthentication added reauthentication in need to add documentation to in the branch,This should have been closed a while ago,Yes
729,issue,Block All Cookies in shields doesn't truly block all cookies,Block All Cookies in shields doesn t truly block all cookies Have you searched for similar issues Before submitting this issue please check the open issues and add a note before logging a new issue NOTE THAT THIS IS THE REPOSITORY FOR THE UPCOMING VERSION OF BRAVE SEE THE CURRENT PRODUCTION VERSION OF BRAVE ON MACOS WINDOWS AND LINUX PLEASE USE THE TEMPLATE BELOW TO PROVIDE INFORMATION ABOUT THE ISSUE INSUFFICIENT INFO WILL GET THE ISSUE CLOSED IT WILL ONLY BE REOPENED AFTER SUFFICIENT INFO IS PROVIDED Description Block All Cookies in shields doesn t truly block all cookies Steps to Reproduce Start with a clean profile on with default global settings Visit a site and change Cookie setting to in shields Wait for the page to reload click on the connection info popup shows x is number of cookies in used varies from site to site Open Settings Privacy Content Settings Cookies toggle to blocked Reload the page from step and click on the connection info popup shows Actual result Chrome vs Brave block Expected result Shields settings should override the global settings for Cookies Reproduces how often on all sites Brave version about brave info Reproducible on current release N A Website problems only Does the issue resolve itself when disabling Brave Shields Is the issue reproducible on the latest version of Chrome Additional Information cc,Can reproduce on I have been digging into the issue and on how all the cookies were being blocked and was a bit confused because all the functionality seemed that it should be working as expected Once the shield flag was changed and the view was reloaded there were just a subset of the Cookies shown as on the connection details Once the tab was closed and reopened all were blocked as they should While all the header management for the cookies was seeming to be correctly working the elements that were not blocked were duplicate and had been set directly with a direct JS call So I will be ensuring from the extension instead that it gets cleaned after enabling the shield flag I m going to move this to x because I think it is working as expected but it just doesn t clear already existing cookies I think this should block the releasable builds milestone since it s a privacy bug Users who select block all cookies from shields would expect it to not send any cookies I think Yan wanted in Releasable builds milestone and not so bumping it up there So I have been investigating this a bit more but haven t been able to get a fix for it The problem seems to be happening with just the uncleaned cookies set as commented for the case of on just on as commented this is only affecting the tab reload happening called from the extension changing the setting or manually reloading the tab If the tab is closed and recreated the bubble shows correctly just all the blocked cookies I had been trying but wasn t able to fix it by manually calling a js script from the extension to cleanup that tab content when the combo option was modified but couldn t manage to have it working On the other hand I was still digging on what flag could be doing differently and how that could eventually have different behaviour on i think this should not have been auto closed probably related but not a blocker appears that turning on the allow all cookies switch doesn t allow all cookies either STR go to it should say p cookies are blocked switch the cookie setting in shields to allow all the page reloads and still shows p cookies blocked,Yes
667,pr,Downcase shop domains on login,Downcase shop domains on login There s no reason why we should error on an uppercase shop domain since they are technically valid Closes,,Yes
5518,issue,ZAP might not use outgoing proxy authentication credentials,ZAP might not use outgoing proxy authentication credentials From OWASP ZAP User Group to reproduce the issue Run ZAP Configure an outgoing proxy with authentication Options Connection Start the spider and note that ZAP does not authenticate to the proxy ZAP Version,This thread has been automatically locked since there has not been any recent activity after it was closed Please open a new issue for related bugs,Yes
25731,pr,Framework: `dispatchRequest` update (account recovery validate),Framework dispatchRequest update account recovery validate See In this patch we re replacing the use of dispatchRequest in the data layer handler to use the newer API exposed as dispatchRequestEx This should have no change in actual effect or interaction,Test live Which user facing flows are affected for these changes Would you mind giving some testing instructions I could use some help with that I m just refactoring the code but I m not familiar with it all In this case it looks like the only code that should be calling the affected API handlers are and,Yes
1879,issue,SparkleShare (v3.28) doesn't ask for password on encrypted repository,SparkleShare v doesn t ask for password on encrypted repository You can find session logs by date and version information in Fedora Flatpak v Gnome Xorg Encrypted Bitbucket repository created with v Full log details at the bottom What happened Synced encrypted repo created in v no password requested the repo is synced but all files are encrypted This is similar to but in this case I have made sure that the encrypted repository was created with v as well What I expected to happen The application asks for a password and decrypts the repo locally This happens when On Ubuntu machine with SparkleShare v create encrypted project Brand new installation on Fedora Added Computer ID to bitbucket Synced Remote Project Specify Bitbucket project log,Hi I have the same issue with the same version of SparkleShare gives the same commit ID I have used to create the repository once using and once using Both times SparkleShare has asked for the password only on the first client I linked Subsequent links succeed but files are encrypted Edit It is the same OpenSSL version on all clients g in reference to issue Do you get a chance to access the files I think I just threw away the repository and switched to an un encrypted repository,Yes
2304,issue,How to remove Top level document security,How to remove Top level document security I m adding JWT authorization to the document and for some reason in the swagger json it appends the security to the whole document Ex is there a way to remove that section,I think that this security section is always needed if securitySchemes are defined no I just want to put some context Values Endpoints don t need authorization at all As you can see I have a security schemes definition and those endpoints remains without I add the security section it affects the entire doc As you can see in the image only way to remove the security icon is append in all endpoints definition I dont know if there is a way to specify that because i tried with and didn t work Did you add AspNetCoreOperationSecurityScopeProcessor I think you can also add the appender instead of AddSecurity without I changed the code to and still getting the same issue Remove the second enumerable parameter you mean like this Yep this way security should not be generated not sure if this is correct though Yes you are right but now is not generating security for controllers that require authentication And now i got it Here is the final code And this works as expected yes but i have a warning because the overload is obsolete Ok then both overloads are valid and obsolete has to be removed right Will create a pr for review tomorrow yes that s right thank you so much for your help Created PR do you think,Yes
3851,pr,cli: load assets from server if cdn is disabled (close #3382),cli load assets from server if cdn is disabled close or fix Description Currently the console run via the CLI uses CDN assets even if the server is configured to use local assets This PR changes this behaviour and will load assets from server if the server is configured to do so ie if set on the server Affected components Server Console x CLI Docs Community Content Build System Tests Other list it Related Issues Steps to test and verify Start server with set to a valid directory Open console with check if assets are loaded from server Breaking changes x No Breaking changes There are breaking changes,Deploy preview for hasura docs ready Built with commit Quick suggestion can we not introduce a new flag and instead just use assets from server if the HASURA GRAPHQL CONSOLE ASSETS DIR env var is set I as a user would expect the ENV var to apply to both server and cli consoles without having to specify a flag again Review app for commit e d f f e db d f e cd b ba deployed to Heroku image for server Review app for commit b a fb adc dc c ad c cf deployed to Heroku image for server Review app for commit f e cb f f c ed b bd ecba d deployed to Heroku image for server I think that makes sense updated the PR to address that Review app for commit d de a b bd ae f fd c a d c deployed to Heroku image for server Review app for commit f f a f feeebafb f d fd deployed to Heroku image for server Can you review this Review app for commit e c b b bbc f aee e ce deployed to Heroku image for server Review app for commit fb f cf b ea c d f f deployed to Heroku image for server Review app for commit fcf e fe d d e a e f a a deployed to Heroku image for server Review app for commit fde ffccf f f f ce f d dae deployed to Heroku image for server Review app for commit ea a d c a a e c f c deployed to Heroku image for server Review app for commit f b a b c d ea fdbfb ddeef bfc d deployed to Heroku image for server Since we are going to force use header we can remove check Review app for commit da fb cfe e a f b b acfee deployed to Heroku image for server Review app for commit c b e ffbc d ef aa f c c deployed to Heroku image for server Review app for commit f eeb b a fccc d fcbcf bad b e deployed to Heroku image for server Review app for commit e f f a c caa b aa a c add deployed to Heroku image for server Review app for commit b dab f b c e ddc b fac deployed to Heroku image for server Review app for commit b a fbbbf c c aa d c b daa deployed to Heroku image for server Review app for commit d c cd e f ef a add f bc deployed to Heroku image for server Review app for commit beb f a f cfa faef f c d a cf deployed to Heroku image for server Review app for commit d d afed fb be ce a cae d deployed to Heroku image for server Review app for commit f cbf e f b d bd e b b deployed to Heroku image for server Review app for commit ff b cc bc d cd f f da fefe deployed to Heroku image for server Will CLI fallback to if config api is disabled Yes the following commits should address that let me know if you feel otherwise Review app for commit f bb d d bbf ba fc a a deployed to Heroku image for server Review app for commit e ca f f e e b a c deployed to Heroku image for server Review app for commit d e d d f e c e c fb e d deployed to Heroku image for server Review app is deleted,Unsure
556,issue,[CLOSED] Bundle any assets that are required by core,CLOSED Bundle any assets that are required by core Issue by Oct at GMT Originally opened as the PBR masks aren t bundled and have a hardcoded reference to our examples directory Hopefully there s a browserify image loader out there,Comment by Oct at GMT I filed issue for this a while ago but we can use this one Comment by Nov at GMT no more images we need to bundle Comment by Nov at GMT Related to MozVR aframe Comment by Nov at Comment by Nov at GMT ok thanks,Yes
443,issue,Change signature of validating functions to use objects instead of positional arguments,Change signature of validating functions to use objects instead of positional arguments Problem Compiled validating functions and validating functions used in custom keywords currently have arguments data dataPath parentData parentDataProperty rootData If the custom keyword is validate kind then the function has arguments schema data parentSchema dataPath parentData parentDataProperty rootData All these arguments are positional so there are usual problems that functions with large number of positional arguments have need to remember order all arguments have to be used etc I also need to add at least one more parameter Solution Change function signatures Validating functions data an object with properties data dataPath parentData parentDataProperty rootData etc Custom keyword validate function schema data an object with properties schema data parentSchema dataPath parentData parentDataProperty rootData etc Pros these signatures will still allow one or two positional arguments in the most common cases other arguments can be used in any order using destructuring easy to extend and no need to remember the order Cons some performance impact constructing objects and destructuring although the most performant custom keywords inline and macro will not be affected uglier code in Ajv itself it will remain ES compatible so no destructuring inside Ajv Questions Should objects contain positional arguments as well as above or only the properties that are not available as positional arguments,As long as you validate the shape of the configuration object then it is a good change My biggest grudge with using simple objects for configuration is when there are no assertions made about their content e g For all you know by scanning the code this is valid configuration If does not throw an error about unknown configurations then you d not know that is not a valid configuration here is a typo and therefore will have no effect etc i e If you do this you need to use JSON schema to validate the shape of the validate instructions At least in part this can be avoided using type annotations e g Flow This has no runtime costs Though the benefits are restricted to the few who are using static type checking thank you I think both positional arguments and objects are equally affected by the lack of validation So the main question is whether to use positional or objects rather than whether to validate or not to validate I think both positional arguments and objects are equally affected by the lack of validation No You cannot make a typo in a parameter name when using positional arguments You can put them in a wrong order sure but thats likely to cause a runtime error Putting an unknown property to the configuration object will go unnoticed You may be right I ll leave it as is I think,Yes
26577,pr,util: prevent tampering with internals in `inspect()`,util prevent tampering with internals in inspect This makes sure user options passed to will not override any internal properties besides Fixes marked as semver major PTAL Thank you for your pull request Please provide a description above and review the requirements below Bug fixes and new features should include tests and possibly benchmarks Contributors guide Checklist x UNIX or Windows passes x tests and or benchmarks are included x documentation is changed or added x commit message follows commit,build started CI PTAL CI just pushed another commit as I messed up a condition earlier and added a test case for that as well Resumed CI please confirm your LG due to the fix I had to push Landed in ab d afe d eb d ee c e tada,Yes
16008,issue,Login attempt or request with invalid authentication from ::ffff:ac1e:2001,Login attempt or request with invalid authentication from ffff ac e Home Assistant release with the issue b Last working Home Assistant release if known pre Operating environment Hass io Docker Windows etc Hass io HassOS Component platform NGINX Addon Description of problem From time to time I get the message Login attempt or request with invalid authentication from ffff ac e which is I m not sure but I think it is from the NGINX Proxy which I use the official addon for Problem relevant entries and fill out even if it seems if applicable Additional information Some time ago with that config it worked and I saw the public IP addresses of invalid logins I always get the above error message and see no messages with other IPs I already reinstalled the official NGINX addon,That is known issue in release prior b if you only got one notification each time and never lock yourself out And you may still see it once after you upgrade It should gone after all browser cache got cleared Please provide more details when and how you get this notification ONLY if you are running on b above and had cleared all browser cache and NOT use iOS app they have known issue as well I completely cleared browser cache but it still persists I m not sure what leads to those We already logged warning there someone still call with legacy api password It caused the invalid authentication log That come from openwrt hass devicetracker which is referred in the OpenWRT component docs But it still updates the device tracker how is that possible if the invalid login comes from that login with API password It is even not using NGINX but the local IP shown is the NGINX instance right The device tracker script is using direct connection without going over NGINX need to change to use oauth access token or you need enable legacy api password auth provider legacy api password is enabled besides the homeassistant provider since it was introduced I use both Since I upgraded to today I see the original source IP in failed attempts again It seems that there was a fix on this between b and Not really However I did caught an unexpected login failed attempts message on my dev environment today under investigating Alright I almost forget that we have a known issue in websocket connection it will log one login failed attempts event if you restart homeassistant which is running last at least minutes The has been checked in long time ago however it has not been released yet due the is under major version upgrade Hope it will be landing in next HA release Above is just an answer for my own question not directly related with original issue in this thread I think it may help other people who is wondering the failed login attempts message,Yes
119,pr,Changed username/password validation regexp so you can use a blank username,Changed username password validation regexp so you can use a blank username Changed username password validation regexp so you can use a blank username useful when using the heroku API with an api key f xml H Accept application xml u api key,,Yes
60,pr,Added support for `domain: 'all'` which sets the cookie on the top most domain possible,Added support for domain all which sets the cookie on the top most domain possible This functionality is present in various server side frameworks e g Rails and can be quite useful especially if your site run on multiple TLDs which in turn has several subdomains,seems much more expressive to me and doesn t require to add more code thus I am reluctant to add more I m going to add default options soon so there will also no longer be a problem with repeating yourself Hardcoding example com won t help if the site runs on stage example se dk no The all feature is implemented in other cookie libraries including Ruby on Rails as i mentioned because of this use case I meant example com more of a placeholder for something like Though yes that won t catch a domain like example co uk,Yes
1274,pr,update bootstrap-sass to 3.4.1 to patch XSS vulnerability,update bootstrap sass to to patch XSS vulnerability GitHub detected vulnerability XSS possible in tooltips popovers in bootstrap bootstrap sass Vulnerable versions Patched version,thanks,Yes
373,issue,Azure RMS AADRM.Format.ps1xml has expired signature,Azure RMS AADRM Format ps xml has expired signature I tried to install latest version of Azure AD RMS PS but it failed as signature is expired Can you update repository or route this to proper department Not sure where this should be reported so you fix it Br Alex Pawlak,Hello thanks for your feedback Installed and verified with the same method as you and got a Valid status Thank you Thank you very much for the contribution and sharing this explanation Hope this comment is helpful for you Thanks for taking out some time to open the issue Appreciate and encourage you to do the same in future also close,Yes
293,issue,Implementations of IDisposable should check private disposed field in public/internal/protected methods,Implementations of IDisposable should check private disposed field in public internal protected methods Essentially if a class correctly implements the IDisposable pattern then public internal protected methods should throw ObjectDisposedException this GetType FullName as per the majority of NET framework classes e g Socket Optionally an XML comment should be declared to reflect this,,Yes
27,pr,Allow URL authentication,Allow URL authentication Context As an alternative to passing the token via the request header we want to be able to pass the token via the query parameters example Implementation The method now looks for a param before falling back to the request header Notes This closes,Great work Sorry couldn t get a PR turned around quickly No worries Finally found some time to work on this Could this also look for an in the params I think that is what Auth call the URL param when signing in as I guess it should be possible to configure this seems like a reasonable default I agree would also make good sense,Yes
769,issue,Bug: Note editor doesn't take into account bottom safe area insets when opened for the first time,Bug Note editor doesn t take into account bottom safe area insets when opened for the first time Expected Expected note editor to respect bottom safe area insets and have some space between bottom edge of my device and text or tags view Observed Opening a note after cold start of the app shows text or tags behind the home indicator Which means that safe area wasn t taken into account On subsequent opening of any of the notes or after editing an opened one the issue fixes itself Reproduced Cold start the app kill it if it s running and open again Tap on any note Depends on how much text the note has either text or tags is shown behind the home indicator On a screenshot red is a frame of the editor green is a frame of the tags view Simulator Screen Shot iPhone Xs at Version App Version iPhone Xs,I took a quick look at the code The following code in doesn t work as expected because when is called isn t yet added to its superview which results in a values being A quick and easy solution would be to call with a delay either using or via But I think less magic and better solution would be to convert current editor view to use constraints,Yes
2757,pr,Remove exclude of private packages from signing.,Remove exclude of private packages from signing In corefx they don t publish private packages to NuGet WCF does publish to NuGet our one private package,I verified that all the other packages that were signed yesterday were correctly signed Confirmed it passed in VSTS Not waiting on OSX CIs,Yes
2183,pr,Fix Action Sheet safe area on iPhone X,Fix Action Sheet safe area on iPhone X This fixes a small typo related to iPhone X support and the action sheet component,Thanks,Yes
1190,issue,SEC-941: Embedded ldap-server uses hard-coded ldap url for importing ldif files,SEC Embedded ldap server uses hard coded ldap url for importing ldif files Ren from said When the embedded ldap server is started by using the tag without url attribute it may be given a pattern of ldif files to be loaded after starting up Unfortunately the is not able to re use a SpringSecurityContextSource for connecting to the embedded LDAP Instead it constructs a separate one with a hard coded connection address of ldap On my machine connections to addresses other than localhost are prohibited by the firewall which I cannot re configure by myself for security policies in my company So I m stuck and have to fall back to painstakingly configure an own ApacheDS server since the org springframework security config ApacheDSContainer class is package scoped and may not be used outside the tag stuff So please either make the ApacheDSContainer public to be used outside of or make the actuial ldap address configurable or use localhost since that s what it is Thank you,Luke said Why is there a problem with using the loopback address localhost should normally resolve to this in any case Ren said It s only a problem on machines where the loopback address is not allowed to be used to connect to localhost As I already said my company s firewall settings prohibit connections to only localhost is allowed Luke said localhost should be resolved to the loopback address so I don t really understand what you mean when you say your company firewall doesn t allow access to it What firewall are you using and how is it configured Can you ping localhost Does it resolve to Can you access the default port for the embedded server Luke said No further input and this shouldn t be an issue as far as I can see,Yes
1845,issue,undefined method `password_digest=' for User while User Registration,undefined method password digest for User while User Registration Hi I am getting this error undefined method password digest for User when I am trying to Sign up Steps I did Deployed Rails application on Heroku Using Devise My user model file looks like this class User ActiveRecord Base Include default devise modules Others available are token authenticatable encryptable confirmable lockable timeoutable and omniauthable devise database authenticatable registerable recoverable rememberable trackable validatable confirmable Setup accessible or protected attributes for your model attr accessible email password password confirmation remember me password digest end,Did you run the database migrations on Heroku I had loaded the database from schema heroku rake db load schema It creates the database and does not requires any migration Actually I think I might see the problem what does your migration look like It looks like you re trying to use which ActiveModel s uses by default when Devise uses instead BTW you probably shouldn t include the encrypted password in with Devise and with the model handles that internally and it shouldn t be mass assignable grin Please provide the backtrace it may help finding the error If not we would like to ask for a way to reproduce the issue This is how migration file looks like class DeviseCreateUsers ActiveRecord Migration def create create table users do t Database authenticatable t string email null false default t string encrypted password null false default end end And this is the backtrace bundle gems ruby gems activemodel lib active model attribute methods rb in method missing bundle gems ruby gems activemodel lib active model secure password rb in reset password bundle gems ruby gems devise lib devise models recoverable rb in update bundle gems ruby gems actionpack lib action controller metal implicit render rb in process action bundle gems ruby gems actionpack lib action controller metal rendering rb in block in process action bundle gems ruby gems activesupport lib active support callbacks rb in run process action callbacks bundle gems ruby gems activesupport lib active support callbacks rb in process action bundle gems ruby gems actionpack lib action controller metal rescue rb in block in process action bundle gems ruby gems activesupport lib active support notifications rb in instrument bundle gems ruby gems activesupport lib active support notifications rb in process action bundle gems ruby gems actionpack lib action controller metal params wrapper rb in process action bundle gems ruby gems actionpack lib abstract controller base rb in process bundle gems ruby gems actionpack lib action controller metal rb in dispatch bundle gems ruby gems actionpack lib action controller metal rb in call bundle gems ruby gems actionpack lib action dispatch routing route set rb in call bundle gems ruby gems actionpack lib action dispatch routing mapper rb in block in call bundle gems ruby gems rack mount lib rack mount code generation rb in optimized each bundle gems ruby gems rack mount lib rack mount code generation rb in call bundle gems ruby gems actionpack lib action dispatch routing route set rb in block in call bundle gems ruby gems warden lib warden manager rb in call bundle gems ruby gems actionpack lib action dispatch middleware best standards support rb in call bundle gems ruby gems rack lib rack conditionalget rb in call bundle gems ruby gems actionpack lib action dispatch middleware params parser rb in call bundle gems ruby gems rack lib rack session abstract id rb in call bundle gems ruby gems actionpack lib action dispatch middleware cookies rb in call bundle gems ruby gems activerecord lib active record connection adapters abstract connection pool rb in block in call bundle gems ruby gems activesupport lib active support callbacks rb in run callbacks bundle gems ruby gems actionpack lib action dispatch middleware callbacks rb in call bundle gems ruby gems actionpack lib action dispatch middleware remote ip rb in call bundle gems ruby gems railties lib rails rack logger rb in call bundle gems ruby gems rack lib rack runtime rb in call bundle gems ruby gems rack lib rack lock rb in call bundle gems ruby gems rack cache lib rack cache context rb in pass bundle gems ruby gems rack cache lib rack cache context rb in call bundle gems ruby gems rack cache lib rack cache context rb in call bundle gems ruby gems railties lib rails railtie configurable rb in call home heroku rack lib last access rb in block in call bundle gems ruby gems rack lib rack urlmap rb in call home heroku rack lib date header rb in call thin lib thin connection rb in catch thin lib thin connection rb in process thin lib thin connection rb in run machine eventmachine lib eventmachine rb in start thin lib thin server rb in start thin lib thin runner rb in run thin bin thin in load usr ruby bin thin in password digesthas secure passwordencrypted password password digestattr accessiblepassword digestencrypted passwordhas secure password bundle gems ruby gems activemodel lib active model secure password rb I don t have access to your code base I cannot tell you where it is being included Thank You Guys I was actually having an another User model file user old rb which had used has secure password in it I removed that file and it worked You guys Rock Thanks once again,Yes
306,issue,Error: Methods must be security critical or security safe-critical to call native code,Error Methods must be security critical or security safe critical to call native code Prerequisites x I have written a descriptive issue title x I have verified that I am using the latest version of Magick NET Question Hello friend I m getting a error Dim settings As New MagickReadSettings Any ideas Occurred after a server migration was working you know any configuration to set on server to fix this,I have no idea in what kind of environment you are running this but I am guessing that is is IIS Running your application in full trust might solve the issue Thanks Cloud Host is saying is in full trust I ll double check They had to enable Fulltrust Now is working Thank you for point this,Yes
14277,issue,Change match certificates repo url,Change match certificates repo url This seems like the simplest question in the world and I can t find an answer for git I am using protocol I want to use ssh How do I change my certificates repository,To answer my own question repo can be changed in fastfile Matchfile,Unsure
3329,issue,Memory leak in plugin system,Memory leak in plugin system An assembly Plugin is current being loaded more then once into current application domain Every time user click to invoke action of a plugin a new instance of assembly is being loading into AppDomain Tip Open windows task manager then open SubtitleEdit keep opening and closing PluginGet you will see how fast SE memory in task starts increasing Make sure you have plugins installed I d recommend installing several plugin in order to see it happening more quickly I have fixed the problem by creating an AppDomain specially for plugins then when done getting needed infos from plugins the appdomain is unloaded CLICK Note this approch doesn t totaly fixe the problem but it s how it can be fixed both for PluginGet form and the entire Plugin System,,Yes
3644,issue,The windows mitmdump can‘t download file，Always in the link,The windows mitmdump can t download file Always in the link Steps to reproduce the problem Start mitmdump on Windows Listen for localhost domain qq com Open the download button on the web page Any other comments What have you tried so far It s always on the link It can t be downloaded is the same set flow response stream True Also is invalid System information Mitmproxy binary Python OpenSSL OpenSSL h Mar Platform Windows ServerR SP,use inspect element ctrl shift i I can t really reproduce this sorry Closing for now,Unsure
16153,pr,Update security.md,Update security md Fixes,cc to explain why credentials are enabled while I m out,Yes
7685,pr,bpo-33630: Fix memory leak in old versions of glicb for `posix_spawn`.,bpo Fix memory leak in old versions of glicb for posix spawn Thanks for your contribution Please read this comment in its entirety It s quite important Pull Request title It should be in the following format Where bpo NNNN refers to the issue number in the PRs will require an issue number Trivial changes like fixing a typo do not need an issue Backport Pull Request title If this is a backport PR PR made against branches other than please ensure that the PR title is in the following format Where X Y is the branch name e g GH NNNN refers to the PR number from,This is complementing I have addressed your feedback in e I can confirm again that this fixes the buildbot problems Tested on the buildbot itself It seems that the problem covered by the race in the test disappears once this is fixed As is a race condition I am not sure but running test suites in parallel that executes times does not raise any problem on the buildbot I have rewritten a bit the comment in e e to make it more clear,Yes
4303,issue,Remove AuthenticationActions and replace with `register` boolean on username/password credential constructor,Remove AuthenticationActions and replace with register boolean on username password credential constructor See realm realm mobile platform,,Yes
17160,pr,scamper: Build a bottle for Linux,scamper Build a bottle for Linux This is an automated pull request to build a new bottle for linuxbrew core based on the existing bottle block from homebrew core,,No
789,pr,Experimental ssl pinning,Experimental ssl pinning Some minor improvements for SSL pinning,Based on insight I cherry picked c Also I just merged the SSL pinning into master finally Seriously sorry for the holdup on that I really don t know what my mental blocker on all of that was Thanks again for all of your amazing work Seriously this is first class functionality I m extremely happy at what a great feature this is for AFNetworking I don t see how c relates to my comment about not implementing a hash function Could you please explain That was to say that I cherry picked the one commit and left out the ones that switched over to an,Yes
1282,issue,"""Guests"" should be a fake system group for access control",Guests should be a fake system group for access control Sub issue related to in the access control modal Guests should be shown as well so administrators can allow guest posting on a category by category basis x Remove use of Allow guests to post without logging in x Add meta system group to Access Control modals x Upgrade script to migrate existing installations if is enabled add the guests group to all existing active categories Write unit tests,,Yes
326,pr,Support Iterable and Array on query and form url encoded parameters,Support Iterable and Array on query and form url encoded parameters This allows retrofit to send query and form parameters that are represented as an Array or a Iterable on Java For example Will get serialized as It is important to note that this is not an official standard but it is used by many frameworks to pass array parameters,I need this I d like to vote for it getting merged Any reason not to Just did a rebase from retrofit master to maintain the pull request updated I also need support for this This would be a huge help Looking forward to this Hello thanks for your feedback I believe I just fixed enhanced everything I also added unit tests for primitive array serialization Also I did a rebase so this should be up to date with the current retrofit master branch Thanks There s still the star imports and whatever is causing the build failure Otherwise LGTM Hello Here are my latest changes Reverted all imports back to how they were before my changes and only added the new clases my code requires Fixed the new comments they were surpassing the column width Rebased again from square retrofit master Maven build is passing Thanks What is the next step to get this merge Hi I also need this Any news on this request I think got all of this and support Can you please verify and let me know if anything you need is missing looks like he had support for Array as well which wasn t included in also doesn t support Form parameters only Query parameters,Yes
1774,issue,Characters after pipe character show up as user name,Characters after pipe character show up as user name Originally reported on Google Code with ID Reported by on Attachment Attachment,Reported by on Reported by on Labels added Component Client Reported by on Status changed Merged into,Yes
1491,issue,Transfer the cookies to Github API,Transfer the cookies to Github API Do you want to request a feature or report a bug Feature I develop the Editor with own authorization founded on JWT tokens The Netlify CMS I ve put to the iframe Also I use own OAuth server and Github proxy therefore I ve set and to the own endpoints To authorize clients in a own API I m checking JWT token stored in the cookie or in header The OAuth request successfully send cookies to the my OAuth server and I m authorizing client But the Github requests the Netlify CMS execute via Fetch API and it don t send the cookies to endpoint To make that is necessary to add the option to all fetch API requests I can to create PR what do you think,oh I ve found graceful way to return from OAuth endpoint my JWT token and then Github requests will put it to Authorization header which I will check Great glad you were able to get it working For future reference there is also an open source platform called that is built for that exact purpose and it already integrates with the CMS The has connect with third party identity server I believe it s possible to use it yourself without a third party Can you explain I m wanting to know myself even if has his set up I also have set up my solution so that I more don t input username password for log in to CMS I e when I log in to the my Editor I m also doing log in to the Github REST API to get And when I log in to the CMS I just return received before from But with I didn t find how to implement similar because it always ask first to input the Also would be ideally if I can log in to CMS without click on button I hope the my trick will work further also well and the developers won t break current implementation of the backend further Therefore many thanks for their work,Yes
1004,issue,Add content_security_policy.rb initializer.,Add content security policy rb initializer Description and as fixed by leave open the part of adding a Content Security Policy file header It should be added and configured properly for the application In addition the missing Content Security Policy header requires the additional file content security policy rb which is missing from config initializers Do you want to be the assignee to work on this,Maybe this is of some help This might also be I also feel like this is relevant It s old but it could potentially be a threat It details methods of bypassing HTTP HSTS the max age parameter I added at the last line of the header config via NTP exploits Theoretically it shouldn t work because attempting to use the version of the site should throw a redirect but it could be worth testing just in I can take a pass as this I m not super security savvy per se are there any particular gotchas I should look out for For example would the default settings from the Twitter tool be appropriate It would be your best start I think it will mostly work try it and browse around your dev instance At first glance it shouldn t cause any major issues I ended up using the Laboratory add on for Firefox to generate a list I ve opened a PR for it If that doesn t pass muster I ll fall back to see what the defaults are in the Twitter tool Thanks for this I ll have to postpone looking at this but maybe can verify and test This was addressed by,Yes
6452,pr,Fix signed distance to bounding sphere.,Fix signed distance to bounding sphere Fixes CC,Signed CLA is on thanks for the pull request Maintainers we have a signed CLA from so you can review this at any time warning I noticed that has not been updated If this change updates the public API in any way fixes a bug or makes any non trivial update please add a bullet point to and comment on this pull request so we know it was updated For more info see the Pull Request Guidelines am a bot who helps you make Cesium awesome Contributions to my configuration are earth americas earth asia Will wait for Travis Hmm Are there test failures here Looks like it I couldn t reproduce it locally though Scene LabelCollection computes bounding sphere in D Expected to equal I was able to see it in Jasmine locally when running the whole test suite but not running in isolation It could be some bad interaction with other tests It s too much of a red flag that this is a bounding sphere related test fail and I don t see it in master or other recent PRs I think it s local to this branch unfortunately Also Travis didn t get the same result as Jasmine Here s Travis Expected to equal Just to confirm I can reproduce the failure locally every time with it does not happen at all for me in master I reverted the changes to what was in The distance to bounding sphere wasn t needed for log depth but I noticed that it was returning a size for volumes behind the camera Looks good tests pass Thanks,Yes
2104,issue,Cubemap asset loading from blob url throws an error,Cubemap asset loading from blob url throws an error Engine seems to fail loading an asset from a blob url This happens when I want to load all my static assets in cache and then serve them to my application from blobUrls some part of my application uses playcanvas and I am getting an error when I try to load cubemap from blob URL Then after when getting from cache asset name Error loading Texture from,Can you check if the latest version of the engine fixes this I think the PR I did and merged yesterday fixes this Alright thanks I ll check and confirm this Sorry It don t seem to me like it is sorting the issue Here is a simple demo with the updated script still throws same error Had a look and realised that the texture loader for the DDS file is dependent on the URL having a dds as a file extension However as it is a blob URL there s no extension so it tries to load it as a normal image file any ideas on this one Hello Sorry just getting to this now You can provide a filename and url This is now loadFromUrl works See I have tried something like this to load the cubemap from the blob URL but it doesn t look like it works It s crashing Also upgraded my playcanvas script to Hi the filename argument to must include the image file extension This is used to determine which format handler to load the image with ohhh cool let me try with that oh wait you re loading a cubemap Sorry I thought this was a texture Not sure about this will have to check yeah as it seems not to work If the blob contains a regular dds file you can load it as a regular resource instead of and set that as the skybox If the dds file contains prefiltered lighting data it s a little more complicated and unfortunately right now I don t believe it s possible,Unsure
954,issue,Setting rejectUnauthorized to false is not ignoring certificate error,Setting rejectUnauthorized to false is not ignoring certificate error I ve a self signed certificate setup with a different hostname on my server I get a on IE I tried setting rejectUnauthorized to false but it still gives me the same error Am I doing this right,using process env NODE TLS REJECT UNAUTHORIZED does it works does this only work on nodejs but not with the client on browser I can t get it work from browser Still pop out in chrome,Yes
23,issue,Can't audit Windows 10 1703,Can t audit Windows Hi When I attempt to audit patches on PC running Windows I got following error message WARNING Access is denied Exception from HRESULT x E ACCESSDENIED I m running PoshPAIG script as domain admin I tried to audit patches on workstations with UAC enabled and with UAC disabled both gives same error result When I attempted to audit patches by running PoshPAIG directly on workstation with Windows error message was different WARNING Exception from HRESULT x,,Yes
4507,issue,mobx inject & observer 的class 类被继承时小程序和H5表现不一致,mobx inject observer class H inject observer log log log Scroll down to See error jsx interface Index props PageStateProps Index extends Comp render console log this name sub child const counterStore counter this props return counter export default Index as ComponentType log taro info Taro v Taro CLI environment info System OS macOS Shell bin zsh Binaries Node nvm versions node v bin node Yarn yarn bin yarn npm nvm versions node v bin npm mobx,Issue bug Issue issue issue Good luck and happy coding CC Hello issue Issue Good luck and happy coding Hello issue Issue Good luck and happy coding,Unsure
4861,issue,Removing needed reference causes race condition.,Removing needed reference causes race condition Rubberduck version information Version OS Microsoft Windows NT x Host Product Microsoft Office x Host Version Host Executable MSACCESS EXE Description I noticed that I had in my project but didn t think I needed it so I used RD s dialogue to remove it When I hit my code immediately started executing hit an error caused by an unknown reference and the VBE hung with paused but running code at an error and the dialogue open I can t close the dialogue box and I can t stop the running code To Reproduce Steps to reproduce the behavior Add a reference Use something from that DLL Use the RD dialogue to remove the reference Click button See error Expected behavior I wouldn t expect code to start running when applying a reference change Screenshots Microsoft Visual Basic for Applications ROIReport break TextWriter context I do have a Main form that auto opens It was the only form open at the time I removed the reference There are no timer events on the main form that would have fired any code The RD status bar indicates that it thinks the code is in a different form than the one that s open but the actual execution point is in my logging code I was able to exit Access by clicking the on the main Access window It told me there was an error in my code but eventually shut itself down I restarted Access holding down the shift key to prevent the form from opening On opening the VBE I got a warning from RD that the code wouldn t compile and asked if I wanted to continue parsing I said but didn t get a parse I went to the dialog but it was disabled in the menu Forcing it to parse again and getting the same won t compile error did get a clean ish parse and I was able to open the The reference that I d tried to add back in prior to shutting down Access had not actually been added but I was able to add it back in get a clean compile and a clean parse,,Yes
6001,pr,Add requests-toolbelt hashes to requirements.,Add requests toolbelt hashes to requirements Attempts to fix certbot certbot I think this covers the updates from Note that s specifies which is the first version I saw with the included But I ve included the hash for May That seems consistent with how some of the other packages are configured between and but I m not familiar enough with the build systems to be totally sure it s correct Also happy to adjust the requirement if there s a preferred approach,,Unsure
76,issue,"当有循环引用时, 调用JSONArray.hashCode()堆栈溢出",JSONArray hashCode JSON JSON parse json MAP KEY map containsKey,bug java util ArrayList bug,Yes
125,pr,Possible solution to memory leak #124,Possible solution to memory leak ,thx I m noticing the memory leaks too is this project being managed I see a bunch of open pull requests good question Thanks for that Sure thing I could use more of your help keep the fixes coming,Yes
690,pr,vsts: null credentials are invalid.,vsts null credentials are invalid Treat credentials and tokens as invalid not as exception errors,,Yes
7449,pr,  Provided a fix for issue #7140 - Minor discrepancy in hashing feature,Provided a fix for issue Minor discrepancy in hashing feature Thanks for contributing a pull request Please ensure you have taken a look at the contribution guidelines Reference Issue What does this implement fix Explain your changes Fixes small documentation discrepancy reported as issue Changes made to the examples ensemble plot random forest embedding py The made changes are to reflect that the example uses truncated SVD rather than PCA The nd graph now has a new title which may be a little long Any other comments Please be aware that we are a loose team of volunteers so patience is necessary assistance handling other issues is very welcome We value all user contributions no matter how minor they are If we are slow to review either the pull request needs some benchmarking tinkering convincing etc or more likely the reviewers are simply busy In either case we ask for your understanding during the review process For more information see our FAQ on this for contributing transformation example,As discussed in this fixed a small documentation discrepancy Thanks,Yes
3057,issue,"Encryption specification does not detail the ""new"" encryption method",Encryption specification does not detail the new encryption method I updated Joplin on Linux today to It suggested I re encrypt my data You may use the tool below to re encrypt your data for example if you know that some of your notes are encrypted with an obsolete encryption method The following master keys use an out dated encryption algorithm What is the new encryption method What was the old method Should I be worried This should be detailed in the encryption or in about End To End found the commit ed f f ddb cf f ac c but it does not detail why the change took place I can update the docs but don t know what to write,It was detailed there and also posted on the forum but otherwise it s true that the in app message is quite generic as it s meant for any type of encryption upgrade,Yes
167,pr,respect transport_options in manticore transport,respect transport options in manticore transport Elasticsearch Client new can have a transport options hash and manticore transport wasn t respecting that This patch takes that hash and forwards it to Manticore Client new,Included in release v a a,Unsure
4020,issue,Determine the used route when multiple MVC routes are assigned to one action method.,Determine the used route when multiple MVC routes are assigned to one action method Is your feature request related to a problem Please describe I have the following code Route item up id Route item down id public IActionResult Move FromRoute string action FromRoute int id Consider The problem is that when I check the value of then it does not contain the value but the value It may be by design but it seems odd to me as the controller name is not transformed into Describe the solution you d like I would like to have the value of the actual route parameter not the value of the action method Describe alternatives you ve considered I can parse Request Path Value item up but I d prefer not to as I would like to keep things simple,You might be able to find what you need from A very low tech solution would be to make this two separate action methods and put the implementation in a third private method that they both call If you want to handle both of these URLs but slightly differently that would be my suggestion The solution you mention is what I originally had I just tried to refactor the code When I look at the value of action is As expected because that s the value I see in the parameter of the method RouteData Values id action Move controller Item But why does have the value It makes no sense to me as is not a value in the route And it seems not consistent compared to controller Then I would ve expected controller to be The question is should this considered to be a bug I would prefer to have the routes registered so it doesn t reach the action method in case of a mismatch When I use then this would catch everything inside the controller Being an MVC controller other actions like Create Edit become unreachable I can solve this by either placing it in a seperate controller or moving it to a sub path In that case has the value The downside is that I need to check direction for a valid value as all requests now enter the action method But since I need to do this anyway this may not be a problem The question is should this considered to be a bug This is how routing works in MVC Actions and controllers are assigned names those names are used for URL generation and view lookup In that case direction has the value up The downside is that I need to check direction for a valid value as all requests now enter the action method But since I need to do this anyway this may not be a problem Implementing a route constraint might be what you want you start from the beginning and explain what it is that you re trying to accomplish Code samples will help In my project I use default mvc routes I have an mvc controller which contains something like this There is absolutely nothing wrong with the code It works and is easy to maintain But I thought that it could be refactored Like documented I can add multiple routes to one method I want to do something similar but with one difference I need to know which route was taken In order to register the and route I use Route attributes If I m not mistaken then in both versions the same routes are registered And actually this works but there is one problem There is no easy way to find out what the exact route was When I look at RouteData Values then is instead of I understand that this is not a bug and that these values are meant for other purposes but I am missing the equivalent of the taken route Usually you won t need it as the routes have the same meaning But not in this case Solution The only information I found was but I would need to parse it I haven t found an easy way to do this but it may be quite easy to create a PathString extension to parse the path which can be used like Solution I ve tried other options like The main difference here is that accepts all values instead of only and Since I do have to check the value in all cases this may not be an issue but I would prefer not to enter the action method at all if the route is invalid Another problem is that all actions are routed to this method so my method becomes unreachable In that case I would need to split the controller or add a sub path Solution Use route constraints To narrow the possible paths I can use a regular expression The value of is and contains the value of the taken route So this works Thanks for suggesting route constrains I didn t think of it BTW in the was used as parameter name but that doesn t seem to work Solution Leave it as it is Option needs extra work option is not really an option considering all issues so I have two options left use regex as route constraint or leave it as it is I think both options are equally easy but with the regex I have less lines I will go for option Thanks again for suggesting route constraints Thank you for your comments It really helped me But why does have the value Moveactioncontrollercontroller Itemaction MoveItemController Moveactionupdown something very long with many parts that could be parameters action regex list get create Route Home Route controller action direction regex up down id except that action is now part of the path I think that it depends on the situation and in this case the chosen solution is fine It s clear what happens and seperate actions have no added value Solution Use route constraints To narrow the possible paths I can use a regular expression Route controller direction regex up down id public IActionResult Move string action string direction int id Having read through the background information you provided this is what I d recommend One thing I want to mention about this is that it means that a URL that provides an invalid value for a direction will result in a rather than you action method being called so that you can decide how to respond The distinction here is whether you want to return a meaningful error message when invalid data is passed this way or if you were prefer to not handle the request and have it Thanks for contacting us We believe that the question you ve raised have been answered If you still feel a need to continue the discussion feel free to reopen it and add your comments,Unsure
1017,issue,FR: (Autotype) Support only pasting username or password,FR Autotype Support only pasting username or password Autotype currently supports only a default sequence or specific sequences by entry For some situations like services that use separated username and password fields in two steps it would be great to use the great autotype filter window to not do the sequence but instead only paste the password or the username separately,Thanks I think it makes sense added a comment about implementation there Closed by Any idea when will be released No idea for now I hope it will be there soon,Yes
884,issue,org.elasticsearch.client.transport.NoNodeAvailableException: no cluster nodes available,org elasticsearch client transport NoNodeAvailableException no cluster nodes available hi when I connect to es this happeed how can I fixs it Thank you,Are you still experiencing this issue Thanks,Unsure
910,issue,"Mac App is not signed: cannot find valid ""Developer ID Application""",Mac App is not signed cannot find valid Developer ID Application Version Target OSX I have tried to sign my app with Developer ID Application cert which was generated in developer account and it s cert But when I build mac I receive warning in And as a result app is not signed,Please update to Please set env Updated to With use of DEBUG I try security find identity v p codesigning on other machine and receive only keys from My Certificates category but Developer ID Application cert is under Certificates Category Your identity is not valid because no private key only public cert without private key Please use Xcode to retrieve identity Now all clear Thank you I have created my public private keys and generated a request for certificate certSigningRequest My team administrator generate new Developer ID Application cert with use of certSigningRequest file After that I add it to my Certificates in Keychain,Yes
5945,pr,Make RazorPages respect IgnoreAntiforgeryToken,Make RazorPages respect IgnoreAntiforgeryToken Fixes This fix works and all tests pass but please double check me on the design as I feel it could be cleaner,According to having attributes on these handlers isn t something that s going to be possible,Yes
456,issue,Filter name MustHaveTenant not found.  Unable to login into application.,Filter name MustHaveTenant not found Unable to login into application I just upgraded to all the latest Abp and Zero module and I can no longer login to my application My application is configured for multi tenancy In my AccountController I m making the following call loginModel TenancyName Default var loginResult await userManager LoginAsync loginModel UsernameOrEmailAddress loginModel Password loginModel TenancyName I have Tenant in my AbpTenants database with the name of Default The exception I m getting is Additional information Filter name MustHaveTenant not found In the AbpUserManager LoginAsync I see where it disables the MayHaveTenant Filter public virtual async Task LoginAsync string userNameOrEmailAddress string plainPassword string tenancyName null using unitOfWorkManager Current DisableFilter AbpDataFilters MayHaveTenant This is the line that throws the exception Log in as tenant user var tenant await tenantRepository FirstOrDefaultAsync t t TenancyName tenancyName At the bottom is my stack trace What do I need to setup or configure to login and use the application I see where this change went with feature at EntityFramework DynamicFilters DynamicFilterExtensions GetOrCreateScopedFilterParameters DbContext context String filterName at EntityFramework DynamicFilters DynamicFilterExtensions SetFilterScopedParameterValue DbContext context String filterName String parameterName Object value at Abp EntityFramework AbpDbContext Initialize in f bb dev capture Abp aspnetboilerplate src Abp EntityFramework EntityFramework AbpDbContext cs line at Castle MicroKernel LifecycleConcerns InitializationConcern Apply ComponentModel model Object component,Hi Can you share your DbContext Certainly using System Data Entity using Abp EntityFramework using Abp Zero EntityFramework using Capture Authorization using Capture Campaigns using Capture MultiTenancy using Capture Notifications using Capture Packages using Capture Payments using Capture Questions using Capture Users using Abp Configuration namespace Capture EntityFramework public class CaptureDbContext AbpZeroDbContext public virtual IDbSet CampaignAnswers get set public virtual IDbSet CampaignParticipantAnalytics get set public virtual IDbSet CampaignParticipants get set public virtual IDbSet Campaigns get set public virtual IDbSet CampaignStatistics get set public virtual IDbSet CampaignTypes get set public virtual IDbSet CommunicationIntervalTypes get set public virtual IDbSet CommunicationSchedules get set public virtual IDbSet DataTypes get set public virtual IDbSet Features get set public virtual IDbSet Languages get set public virtual IDbSet PackageFeatures get set public virtual IDbSet Packages get set public virtual IDbSet Participants get set public virtual IDbSet PaymentHistories get set public virtual IDbSet PaymentIntervals get set public virtual IDbSet PaymentPlans get set public virtual IDbSet Profiles get set public virtual IDbSet ProfileStatuses get set public virtual IDbSet QuestionOptions get set public virtual IDbSet Questions get set public virtual IDbSet QuestionTypes get set public virtual IDbSet TimeZones get set public virtual IDbSet PaymentProcessorEvents get set public virtual IDbSet NotificationDetailTypes get set I think I ve solved my issue You asking for my DbContext made me see where i had commented out the call to base OnModelCreating modelBuilder I can now see down in the base AbpContext where you are leveraging the OnModelCreating modelBuilder to perform filtering I appreciate your willingness to assist Chris Yes I thought so You re welcome Hello langman Can you write here your solution I run into the same problem after upgrading In my case I have multitenancy desabled If you override OnModelCreating then call base OnModelCreating first Same is true for Initialize method Fixed thanks I am running into a similar issue Which Initialize method are we talking about havae you tried the suggestion for OnModelCreating Which Initialize method are we talking about It s the one in of Note that its counterpart in does not have an method,Yes
52,issue,"High CPU, memory leak when running VS Code extension on Linux",High CPU memory leak when running VS Code extension on Linux Version insider Commit a de ac f e e d cc eeb dc cde Date T Z Electron Chrome Node js V electron OS Linux x generic VS Online extension version Repro steps Install VS Code Insiders and the VS Online extension on a Linux machine in my case Ubuntu Budgie Start VS Code with a new window Expected CPU close to idle memory consumption reasonable Actual CPU at likely single thread memory use constantly increases until machine hangs up and bombs Uninstalling the extension resolves the problem Have not observed this on Windows or macOS Might be related to or but symptoms slightly different so logging separate,Debugged this and it looks like there was something going on with my Linux machine and pre launch bits causing a problem For reference the resolution was to install and use aka Passwords and Keys to delete the secret in the keyring and then restart VS Code and sign in,Yes
16381,issue,@Value annotation should be able to inject List<String> from YAML properties [SPR-11759],annotation should be able to inject List String from YAML properties SPR Adam opened and commented Yaml file mdash Class mdash Error mdash Reference URL votes watchers,Adam commented Any thoughts Ping Adam commented This feature would be nice for one of our current projects We have a little hack to get around this limitation but we d love to get rid of it Adil commented Berlin Would you mind sharing the hack please Adil Adam commented I no longer have access to our client s codebase so I cannot provide the workaround As I remember we configured the list with a comma delimited string and tokenized the string into a list We d definitely prefer that the standard YAML syntax for creating a list would translate into a List when using Adam Bob commented This would certainly be a welcomed addition to semantics Please see this thread for further Tongliang commented I think at least one level array should be supported By one level I mean each item in the array is of a simple type integer boolean or string and all items are of the same type in the array for example Therefore in the code one can use the following code to bind the above YAML arrays to a But in order to bind more complex array structures i e items in the array are of compound types arrays maps etc one should use If this is acceptable I ll create a pull request to make this happen It is fairly easy to make this happen Diego commented Hey guys Just encountered that and got help in the gitter spring boot channel that led me here Sample code Looking at env shows that ConfigurationProperties worked as expected now the controler Calling test returns an empty list So to verify that won t work as well let s change it for Error Changing the controller code to Works like charm for the yaml bellow the result is exe St phane commented Yeah well your code there reproduces the limitation described in this issue And this issue is not fixed so what you re experiencing is pretty much the current state yeah You are using Spring Boot so please do you a favour and stop using does a lot more and does support that use case Wenjie commented I encountered this problem when I was using spring framework to load yaml configuration I can see the properties get loaded into the PropertySources object like platforms platforms However I still get following exception Wenjie commented Do you guys think making the to support regular expression is a good idea to resolve this bug Romero commented Yeah and I m still facing that same issue the bug is not fixed Do you guys think you can assign this issue to me so I get it sorted St phane commented Feel free to give that a try Romero no need to be assigned for that Bulk closing outdated unresolved issues Please reopen if still relevant and I need this feature when there is only one field Why I need a Class when I only have one field,Unsure
390,issue,The password for the private PGP key is wrong,The password for the private PGP key is wrong Hello I have noticed that passwords for PGP keys must not exceed a maximum length I have tried passwords with and without special characters with a length of characters and with these I was able to decrypt my passwords J passwords not working ec v UD Hz i RxBB tj A would be great if the documentation contained a hint about the maximum password length or removed the limitation for the maximum number of cannot be displayed The password for the private PGP key is wrong,I can actually not reproduce what you described With a new key with standard settings i e RSA with length and the first of your lengthy passwords everything work as expected Which kind of key did you use I ve used a RSA Bit key And on several iOS devices the password could not unlock the RSA Key Which version of the app do you use Which version of the app do you use I m using It works for me even with the old version If you want I can have another try with a key pair and a password which do not work for you Just attach them to the issue And please tell which method you use to import the keys,Yes
1735,pr,Fix: memory leak in ssr,Fix memory leak in ssr After about reloads the memory snapshot is like,CF Passed,Yes
8936,pr,"Review, please: Capture block so content won't leak.",Review please Capture block so content won t leak Beware tests are red The following pull fixed the block being passed to the appropriate helper method However the content being passed into the block is generating repeated markup on the page due to some weird ERb evaluation This commit tries to capture the block s generated output so the page isn t flooded with markup but I m not able to make the tests pass due to a missing output buffer Please help me review this behavior Example it leaks markup to the page Example doesn t leak,can you help me with this This fix seems correct Indeed but it breaks half a dozen tests and I m not sure how to fix them Seems like is cause of a problem I think that there problem inside example If you use builder you shouldn t use as builder method will not return markup usually it expected to return self Correct usage is That s the short term correct answer I thought of that too Thanks However captures the passed block and it should be the same in here imo Developers shouldn t be confused about whether to use one or another yes agree Could you add some tests cases for the raw template method and for the form helper OK I ll give it a stab and see if I can pull it off So I m picking on the topic and as I said I m getting failing tests that look exactly the same output buffer for I m not understanding the meaning of this should the helper contain that writer method and it does not anguished I feel obligated to make these tests green again before moving on can anyone point me somewhere so I can take a better look Thank you I updated your commit with tests and the proper fix Thank you so much Thanks apologize for not being able to solve the problem that was at hand I really wanted to grasp the whole situation Thanks for giving me a hint I look forward to contributing more No problem Thank you for the bug report and the fixes I applied because I want this fixes ASAP since I ll need to release simple form smile,Yes
1271,issue,SEC-1017: org.springframework.security.vote.UnanimousBased,SEC org springframework security vote UnanimousBased Manav from said I am using org springframework security vote UnanimousBased with follwoing voters roleVoter customVoter and have the following constraint on a method say getName getName ROLE ONE ROLE TWO CUSTOM ADMIN CUSTOM READ I am logged as a User with ROLE TWO and CUSTOM ADMIN permission But I get Access denied because Role Voter fails after it finds out that I do not have ROLE ONE and does not check for ROLE TWO instead throws Access Denied,Luke said This isn t a bug but the documented behaviour of the UnanimousBased AccessDecisionManager read the Javadoc for the class The issue has been dealt with and discussed before search Jira for UnanimousBased and please do a search before raising new issues,Yes
627,pr,Apply regex based whitelists to new uid auto-creation,Apply regex based whitelists to new uid auto creation I did some very basic testing in our environment A good metric name DEBUG OpenTSDB I O Worker UniqueId Accepted name for UID testing metrics foo based on test INFO OpenTSDB I O Worker UniqueId Creating an ID for kind metrics name testing metrics foo A bad metric name DEBUG OpenTSDB I O Worker UniqueId Rejected name for UID tbadmetrics foo INFO OpenTSDB I O Worker UniqueId UID cannot be assigned name is not acceptable tbadmetrics foo ERROR OpenTSDB I O Worker RpcHandler id xe Unexpected exception caught while serving null tbadmetrics foo domain test java lang RuntimeException UID cannot be assigned name is not acceptable tbadmetrics foo,Will re open when I have time to add some tests and see why the build failed,Yes
266,issue,Windows assigned to all Spaces get messed up after starting AltTab,Windows assigned to all Spaces get messed up after starting AltTab This issue was opened by a bot after a user submitted feedback through the in app form Message I have Finder and Chrome set to Dock Assign All Desktops If you start the Alt Tab app in that state the screen will move to one of the desktops when you select Finder or Chrome In that case it is solved by assigning to All Desktops Is there a way to solve this Debug profile App version App preferences NSWindow Frame SUStatusFrame NSWindow Frame SUUpdateAlert NSWindow Frame com sindresorhus Preferences FrameAutosaveName SUHasLaunchedBefore SULastCheckTime SUUpdateGroupIdentifier SUUpdateRelaunchingMarker arrowKeysEnabled true cancelShortcut closeWindowShortcut W hideShowAppShortcut H hideSpaceNumberLabels true holdShortcut maxCellsPerRow maxScreenUsage minCellsPerRow minDeminWindowShortcut M mouseHoverEnabled false nextWindowShortcut preferencesVersion previousWindowShortcut quitAppShortcut Q screensToShow showHiddenWindows true showMinimizedWindows true showOnScreen spacesToShow theme windowDisplayDelay Applications count Windows isMinimized false isHidden false isOnAllSpaces false spaceId spaceIndex isMinimized false isHidden false isOnAllSpaces false spaceId spaceIndex isMinimized false isHidden false isOnAllSpaces false spaceId spaceIndex isMinimized false isHidden false isOnAllSpaces false spaceId spaceIndex isMinimized false isHidden false isOnAllSpaces false spaceId spaceIndex isMinimized false isHidden false isOnAllSpaces false spaceId spaceIndex isMinimized false isHidden false isOnAllSpaces false spaceId spaceIndex isMinimized false isHidden false isOnAllSpaces true spaceId spaceIndex isMinimized false isHidden false isOnAllSpaces false spaceId spaceIndex isMinimized false isHidden false isOnAllSpaces false spaceId spaceIndex isMinimized false isHidden false isOnAllSpaces false spaceId spaceIndex OS version E OS architecture x Locale ja JP current Spaces count Dark mode Dark Displays have separate Spaces checked Hardware model MacBookAir Screens count CPU model Intel R Core TM i NG CPU GHz Memory size GB Active CPU count Current CPU frequency Ghz,,No
69984,issue,Unable to set idempotent firewall rule on windows firewall.,Unable to set idempotent firewall rule on windows firewall SUMMARY When using win firewall rule it seems that when you try to re run the ansible code it fails saying the rule exists but has different values ISSUE TYPE Bug Report COMPONENT NAME win firewall rule ANSIBLE VERSION CONFIGURATION OS ENVIRONMENT Target OS version Windows Server STEPS TO REPRODUCE EXPECTED RESULTS I d expect the firewall rule to apply the very first time It does Subsequent applies it should see the rule exists and ignore it or if it s different to change it ACTUAL RESULTS,Additional information Deleting the rule from the server and letting ansible re run it yields Re Running the task after this yields the same error Additionally it seems to be ignoring the section Thank you very much for your interest in Ansible This plugin is no longer maintained in this repository and has been migrated to re submit this issue in the above repository If you have further questions please stop by IRC or the mailing list IRC ansible on irc freenode net mailing list,Yes
2618,issue,heap-buffer-overflow detected when running with Address Sanitizer on,heap buffer overflow detected when running with Address Sanitizer on If you turn on Address Sanitizer in Xcode and type any character into the query field you ll get a crash in utf strlen on this line u size t s,Yes that is technically an out of bounds read However this is an intentional optimization made for performance reasons The same technique is used by Apple s own code See,Yes
347,issue,Saving a session while perfroming an active scan dangerous?,Saving a session while perfroming an active scan dangerous Original issue reported on code google com by on,Original issue reported on code google com by on Was this ever investigated further The scans are now stopped before saving the session it s possible that a scanner that has not fully stopped fails to persist a message but that shouldn t affect the session being saved Closing as insufficient evidence This thread has been automatically locked since there has not been any recent activity after it was closed Please open a new issue for related bugs,Yes
4224,issue,MVC application supporting both oidc (cookie) and token authentication (for api),MVC application supporting both oidc cookie and token authentication for api I am using Identity Server and use quickstarts as reference I have the following samples working including console client server to server mvc login Now I created a vue client based on sample the Idp server my client configuration for my js client is as follows I can log in to the client just fine The issue comes when I am calling an API on my MVC application Within MVC my start up class looks like Here is the confusing part When calling the API from js I am getting unauthorized if my accesstokentype is reference it fails idp client configuration AccessTokenType AccessTokenType Reference If however my accesstokentype which is Jwt the API call from javascript works It is my understanding based on accesstokentypes that reference would imply that my mvc application will validate the token with the idp server while type does not do this lookup against the idp server I would seem that I really do want the reference type token to be more secure How can I determine why accesstokentype reference is failing I am just getting unauthorized and stumped as to why I am hoping this is clear and someone can give me a clue or two thanks dave,This issue has been automatically marked as stale because it has not had recent activity It will be closed if no further activity occurs Questions are community supported only and the authors maintainers may or may not have time to reply If you or your company would like commercial support please see for more information This thread has been automatically locked since there has not been any recent activity after it was closed Please open a new issue for related bugs,Yes
33643,pr,[DOCS] Moves security reference to docs folder,DOCS Moves security reference to docs folder Related to This PR moves the reference content from x pack docs security to docs reference security NOTE There is no code snippet testing in this content so no changes are required to the gradle checks,Pinging,Yes
100,issue,"not threadsafe? in puma every so many requests, empty gon data",not threadsafe in puma every so many requests empty gon data Looking at the code and it s use of class methods and data it seems pretty clear that this gem isn t safe for use in a threaded Rails environment I m guessing that s what all the checks for wrong request are about Anyway in our environment it seemed to work fine under unicorn not threaded but under puma randomly the include gon render would just have empty data and the only thing I could find to explain that was your check for request object id Gon Request id and it s side effects in include gon in helpers rb,We are seeing in JRuby ActionView Template Error can t add a new key into hash during iteration set variable rent vendor bundle jruby gems gon lib gon rb in rabl request uuidrequest idrequest id id for ActionView Template Error I m using Rails with Puma Ruby and gon,Yes
746,pr,Fix: #745 Tyepscript definition wrong return type on hash(),Fix Tyepscript definition wrong return type on hash What s Changing and Why According to is having wrong return type on which should be This PR fixed this What else might be affected Nothing Tasks Add tests Update Documentation x Update Add Label closes,rocket PR was released in v rocket,Yes
761,issue,Password reset does not reset password,Password reset does not reset password I have used the password reset functionality to reset the password to an account I am creating For one particular user the password reset functionality does not work I can not even set the password for the user within Parse,Hey thanks for the report Looks like there are few separate issues you are experiencing here Password reset doesn t send a verification email Inability to set a password for the user via dashboard Since both of them sound to be disconnected from the SDK could you file an issue on since we are using FB Bug Tool to track both backend and dashboard issues Let me know if there is anything here that involves the SDK and I ll do my best to help you with that Thank you for your feedback This repository only contains code for the SDK so we only handle SDK issues here Your issue seems to be a backend issue Our backend issues are tracked through where you can provide more information about the exact app where this is happening and attach confidential data for reproducing the issue Could you please file a bug there,Yes
1732,issue,"when S3 client side decryption, does sdk support to check aes key whether consistent to encryption",when S client side decryption does sdk support to check aes key whether consistent to encryption Hi all developers Our company plan use AWS S client side encryption feature we plan to use Client Side Master Key to encrypt our data and use RSA to encrypt the AES key But because our business the RSA private key was store in our customers So when they want to get the data we need use their private key to encrypt aws data But we don t ensure our customers give us the right key So My questions is when aws sdk decrypt the data do you support to check the key whether consistent to encrypt If the key is inconsistent do you will return a garbled data or will explicitly to tell customer that you upload a inconsistent key please do check Thanks,I am not fully clear on the question To decrypt the object you should use the same encryption materials Otherwise you will get an error Is that what you are looking for I would suggest you to try to upload download a sample object using the and see if this is the behavior you are looking for The following page has some examples to get you me know if you have follow up questions Thanks for reply Yes I understand we need use same EncryptionMaterials to decrypt the object but I can t predict my customer s behavior I mean if the customer use materials A Instantiation with one KeyPair to encrypt and use materials B Instantiation with another KeyPair to decrypt does S will explicitly throw an exception that the materials B is wrong or just use B to decrypt the object and return a garbled data Is there something like a keyPair fingerprint in the class EncryptionMaterials to determine KeyPair inconsistent Sorry if I ask a question that is too amateur Actually i am not java developer I am a python developer my work is package S api and adapt to our customer with python i will try to use java sdk to verify this ASAP Your question is just fine no need to apologize The SDK stores a symmetric secret key in the S object metadata We ll attempt to decrypt it but it will likely fail You ll get this exception where the cause will vary based upon the type of key you re using but it s usually related to bad padding Let me know if you have any further questions,Yes
1353,issue,"error in codesandbox from v5.1.0: ""sh: opencollective: command not found""",error in codesandbox from v sh opencollective command not found Observed Behaviour dependency error in default codesandbox with Current Behaviour ok in codesandbox with inferno and previous,Hi Thanks for reporting this issue I think this is bug in open collective package I opened ticket for has the opencollective version from v to v oddly HTTP errors seem to occur when downloading infernofrom cloudfront before the opencollective error when following the corresponding are no such errors with could this be an issue with caching npm packages by We cache the dependencies using Amazon Cloudfront all over the world Our sandbox also runs faster because we now only parse and execute the relevant JS files for your sandbox or is the json file absent from the npm package filed a corresponding issue with codesandbox issue solved in codesandbox,Unsure
887,pr,Use Hamster::Set in checksummer for speed,Use Hamster Set in checksummer for speed Using Ruby s in an immutable way is slow from is significantly faster Example s rarr s Fixes,,Yes
538,issue,Memory leak due to unsubcribption of events,Memory leak due to unsubcribption of events gqqnbig CodePlex I used ChildWindow in version and found ChildWindow couldn t be garbage collected because it subscribed parentContainer LayoutUpdated and other events and didn t unsubcribe them Now I update to version and there is still no unsubcribption statements Please examine the issue in the whole project and fix it,,Yes
1751,issue,Should API consumer send id_token or access_token for openIDConnect security scheme,Should API consumer send id token or access token for openIDConnect security scheme With the addition of the security scheme object type in v I find the spec ambiguous on whether the API consumer should be sending an or an to the API From my understanding this may not have been an issue in v since there was only instead of and Since OpenIDConnect flows can provide both id tokens and access which token type should be sent to the API Does specifying an auth type of imply that an should be used while implies that an should be used If so I think this information should be explicit in the spec instead of implied If not could you comment on whether or not consumers should always be sending an for both and security scheme types,Ping do we need more clarity in the spec here My understanding was that the such as was used in place of the fields to obtain the necessary oAuth configuration flows scopes etc to connect with the described API Though I m not sure on the specific question of vs posed above Whether the consumer should be sending an vs an seems like an important part of the spec can anyone comment on whether OASv can does tell the consumer which token type should be sent to the API Hi there The problem is complex is the OpenID Connect Provider also an OAuth Authorization Server for the API Are the access token opaque tokens or JWTs etc but in short id tokens are JWTs intended for Client Applications use not for Resource Server API use id tokens are there so that the Client Application can authenticate the end user they contain potentially sensitive information about the end user that you as the Client Application developer owner might not be allowed to transmit to the Resource Server the API So don t send id tokens but access tokens to the API The API can then invoke the token introspection endpoint to get information about the end user and the scopes the client application requested Hope it helps Phil Thanks for the detailed reply Phil It would be great to see this guidance appear within the spec itself to help eliminate confusion for API consumers Yes it would be helpful to include this guidance specs This is an important aspect that is often not understood,Yes
2,issue,NotImplemented exception when doing a challenge for cookies middleware,NotImplemented exception when doing a challenge for cookies middleware Looks like K has a IdnMapping class stub with no implementation An unhandled exception occurred while processing the request NotImplementedException The method or operation is not implemented Microsoft AspNet Abstractions HostString IdnMapping GetAscii String unicode Int index Int count Stack Query Cookies Headers Environment NotImplementedException The method or operation is not implemented Microsoft AspNet Abstractions HostString IdnMapping GetAscii String unicode Int index Int count Microsoft AspNet Abstractions HostString ToUriComponent Microsoft AspNet Abstractions HostString ToString System String Concat Object args Microsoft AspNet Security Cookies CookieAuthenticationHandler ApplyResponseChallenge Microsoft AspNet Security Infrastructure AuthenticationHandler ApplyResponseCore Microsoft AspNet Security Infrastructure AuthenticationHandler b System Threading LazyInitializer EnsureInitializedCore T T target Boolean initialized Object syncLock Func valueFactory Microsoft AspNet Security Infrastructure AuthenticationHandler ApplyResponse Microsoft AspNet Security Infrastructure AuthenticationHandler OnSendingHeaderCallback Object state Microsoft AspNet Server WebListener Response NotifyOnSendingHeaders Microsoft AspNet Server WebListener Response ComputeHeaders Boolean endOfRequest Microsoft AspNet Server WebListener ResponseStream ComputeLeftToWrite Boolean endOfRequest Microsoft AspNet Server WebListener ResponseStream WriteAsync Byte buffer Int offset Int size CancellationToken cancel System IO Stream WriteAsync Byte buffer Int offset Int count Microsoft AspNet PipelineCore DefaultHttpResponse WriteAsync String data Startup b HttpContext context in Startup cs return context Response WriteAsync Authenticate,Fixed,Yes
17616,pr,bpo-39055: Reject a trailing \n in base64.b64decode() with validate=True.,bpo Reject a trailing in base b decode with validate True ,Thanks for the PR I m working now to backport this PR to is a backport of this pull request to the is a backport of this pull request to the,Yes
7136,issue,static URL containing parameters re encoded ,static URL containing parameters re encoded When providing a string URL for an image resource for an entitiy material or a SingleTileImageryProvider where the url includes query parameters the URL that is fetched has parameters extracted url encoded and the recombined to form a new url a url defined as has the endpoint fetched a hash code is needed that is generated from the url parameter string hashCode someHashFunction imageApi location the url requested should be hash code is becomes invalid because the following is things to work hashCode someHashFunction imageApi location C,Hi I m sorry I don t entirely understand the problem here What is making your second query parameter invalid,Yes
2619,pr,[hp|compute_v2] added security group support,hp compute v added security group support This PR adds security groups to the compute v services for the HP A lot of this code was re used from the compute service Do you want to give this a quick glance I also noticed that out of the providers that support security groups aws hp and openstack all three of have a slightly different interface I added to match the aws interface but I wonder if we should take the time to define a common interface for SecurityGroups I am leaning towards the OpenStack implementation as it has a much more OO interface Thoughts,could you review yeah seems like it might be about time to think more about a consistent security group interface Doing it now and maintaining backwards compatibility will be somewhat challenging but probably worth doing Coverage remained the same when pulling e e faa e f b af b a on rackspace hp security groups into de f f e c ef f ffca ad on fog master Coverage increased when pulling ec b bce d f b bf e c d on rackspace hp security groups into aa a f b d ac ad cda e a on fog master could you take a look We were hoping to get this in prior to release and hoping to release in the next day or two Thanks I don t want to slow down the next release and I don t foresee this causing negative impacts in the next release so I am just going to merge no worries not a big rush just like to keep the ball rolling The main reason why security groups are missing in the new compute v provider is that we want to discourage the use of the old Nova security groups and want users to use the new Neutron security groups If you want to use the old security groups we intend users to use the older compute provider I was curious why you wanted to add security groups to the new compute v provider sorry I kept you guys waiting but I was travelling No problem I totally missed security groups in the network service Basically I am working on a workshop for sxsw that demonstrates how fog allows you to easily switch between AWS HP and Rackspace Security Groups seems to be one of the areas that fog differs between providers Let me see if I can rework my example and revert this commit BTW what are the differences between the v and v versions of the provider Mostly the differences are in compute and blockstorage which have a V version The security groups being the majority of the change with some subtle API changes based on what was changed in Grizzly Backup Volumes API changed in BlockStorage otherwise it is the same Rest is in the changelog Let me know if you want any more details Thanks can you let me know when this is sorted out I presume I should wait for this before I cut a release Thanks Will do I should have time to look at this in the next hour Chances are I am just going to revert these changes sure no hurry really I d like to release some time this week but doesn t have to be today I am tempted to use the v provider for my workshop because the abstraction works better with the current aws implementation How long is the v provider going to be around it won t be there too long V is way much better I reverted this changes in pr thanks a lot,Yes
2758,issue,OAuth._redirectUri not using OAuth._loginStyle,OAuth redirectUri not using OAuth loginStyle line in OAuth redirectUri implementation is using directly the service config document loginStyle property which might be NOT defined when you use the service configuration package directly by code the docs use this here you happen to define your own login system without service configuration wizard which is always setting a valid loginStyle and setting up service config by hand in the server code you probably won t define the loginStyle property because you want Meteor to guess it by itself using the OAuth loginStyle logic Long story short you ll end up having a bad redirect URI with close appended and your oauth will fail The solution is quite simple the code should use OAuth loginStyle instead of tapping directly in the service config doc,You re right We forgot to update our docs to encourage users manually configuring their services to include their default login style Your suggestion doesn t quite work because the point of the line in question is to tell the difference between old style configuration and new style configuration Your code should just be using new style configuration Thanks for this clarification,Yes
625,issue,Problem re-signing application due to provision profile name inconsistency,Problem re signing application due to provision profile name inconsistency What App Center service does this affect Name of service or sdk with the issue Describe the bug If provision profile in app center is not named exactly that of the application on iOS it will fail to resign app for a tester I think Further info found,this shouldn t happen we match the provisioning profile in the app with one in your developer portal We don t store the provisioning profile only download them from Apple s developer portal Can you share the error message or a screenshot This issue has been automatically closed because there has been no response to our request for more information within days If you still need any assistance please reopen the issue or submit a new one,Yes
1229,issue,Review *ToMessageDecoder.decode(...)  and *ToMessageEncoder.encode(..) methods,Review ToMessageDecoder decode and ToMessageEncoder encode methods While and me talked about some issue which is related to folding we agreed that our current way to handle folding is kind of a design flaw We want to remove folding completely if possible to simplify things For this we also want to revisit the ToMessageDecoder decode and ToMessageEncoder encode method At the moment they look like this for example This may should more look like There are few issues that may make it hard It is not so easy to extend and intercept the decoded message to change it This is for example done by MarshallingDecoder We could fix this by using some kind of MessageBuf wrapper that does the convert under the hood It is harder to handle the case of handling ByteBufs which may need to get written to a ByteBuf if the next handler in the pipeline is of type Channel ByteHandler We could do this again by some special wrapper which will intercept add offer and just write it to the next ByteBuf if needed,I also start to wonder if it may not give sometimes bad side effects when we automatically write ByteBuf messages to the next ByteBuf in the pipeline I think for encoders outbound it may not so much an issue But I wonder for inbound as it may screw up framing WDYT I think it is fine A decoder could provide an overridable factory method like this Note that we should not add a decoded message to the next handler s buffer directly because we have to handler s we have to allow a user filtering messages like you mentioned and the decoder has to determine if the decode method decoded anything easily I should have mention that I started to work on this already damn Hope you not also started I used something similar to newDecoderOutput The only downside is that we need to make now the double amount of offer poll then before and also allocate extra objects memory But those should be relative cheap An other issue is where to store the reference If we store the reference in a field we will force all sub classes to be non We could also store it in the attributes of the context put this would allocate the map and so also take up memory wdyt In fact in our ByteToMessageEncoder we use fields and so not allow But I think we should fix it here ok I had some more thoughts on this and also did some prototyping I think we should not allow the user to intercept MessageBuf calls What we should do is to just have an extra decode method in the classes that we think that should be extendable which return one object at one time So in this case the user could just override this method and use it like before This would for example be true for FixedLengthFrameDecoder Why I think we should not allow to intercept is for a few reasons The conversion from one type to an other while be in the MessageBuf add method may want to throw an exception Which must be wrapped in a RuntimeException then The intercepter may surpress a message but the implementation he extend may depend on the fact that it is added So I think it is more clear if we just not allow it Re having a field I wonder if we can rely on escape analysis i e allocate decoder encoderOutput for every decode encode Re Throwing an exception we could allow to throw any exception and then use internally Re An interceptor that suppresses a message that s obviously a user fault Usually a user just should use so I don t think this is a problem By the way there s no in our API If you meant why should we make it sharable,Unsure
25678,pr,doc: remove outdated s_client information in tls.md,doc remove outdated s client information in tls md There is a description of how to use s client for testing of renegotiation limits in the module documentation The information is somewhat out of scope but it also may be somewhat problematic due to changes peculiarities bugs in recent s client Remove the text Refs you for your pull request Please provide a description above and review the requirements below Bug fixes and new features should include tests and possibly benchmarks Contributors guide Checklist x UNIX or Windows passes x documentation is changed or added x commit message follows commit,build started Landed in cb,Unsure
2430,issue,"After upgrading to traccar server 3.7, I can not login.",After upgrading to traccar server I can not login Hi After upgrading to traccar server I can not login I get Incorrect email address or password Any help,Looking better at log files can you send me an mysql script to create missing field and tables and when I try to register a new user I get and another error You clearly haven t done update correctly If you use correct configuration it should automatically update database schema using I have fixed database issues but I can t connect I have reset admin password with and tried to login with admin and password and I still get Incorrect email address or password Check the API call error in the browser developer console,Yes
23365,issue,General low level primitive for ciphers (AES-GCM being the first),General low level primitive for ciphers AES GCM being the first Rationale There is a general need for a number of ciphers for encryption Todays mix of interfaces and classes has become a little disjointed Also there is no support for AEAD style ciphers as they need the ability to provide extra authentication information The current designs are also prone to allocation and these are hard to avoid due to the returning arrays Proposed API A general purpose abstract base class that will be implemented by concrete classes This will allow for expansion and also by having a class rather than static methods we have the ability to make extension methods as well as hold state between calls The API should allow for recycling of the class to allow for lower allocations not needing a new instance each time and to catch say unmanaged keys Due to the often unmanaged nature of resources that are tracked the class should implement IDisposable Example Usage the input output source is a mythical span based stream like IO source API Behaviour If get tag is called before finish a exception type should be thrown and the internal state should be set to invalid If the tag is invalid on finish for decrypt it should be an exception thrown Once finished is called a call to anything other than one of the Init methods will throw Once Init is called a second call without finishing will throw If the type expects an key supplied a straight new d up instance if the Initial Init call only has an IV it will throw If the type was generated say from a store based key and you attempt to change the key via Init and not just the IV it will throw If get tag is not called before dispose or Init should an exception be thrown To stop the user not collecting the tag by accident Reference dotnet corefx Updates Changed nonce to IV Added behaviour section Removed the single input output span cases from finish and update they can just be extension methods Changed a number of spans to readonlyspan as suggested by Removed Reset Init with IV should be used instead,Quick to judge feedback on the proposed API trying to be helpful is not in Nonce is very implementation specific ie smells of GCM However even GCM docs ex NIST SP D refer to it as IV which in case of GCM happens to be a nonce However in case of other AEAD implementations the IV does not have to be a nonce ex repeating IV under CBC HMAC is not catastrophic Streaming AEAD should either work seamlessly with or provide its own AEADCryptoStream which is just as easy to stream in out as CryptoStream AEAD API imlementations should be allowed to do internal key derivation based on AAD Associated Data Using AAD purely for tag calculation verification is too restrictive and prevents a stronger AEAD model Get methods should return something GetTag If they are void they must be setting something changing state Trying to obtain a tag before finishing is probably a bad idea so IsFinished might be helpful Folks that designed thought about reuse multi block support and differently sized input output block sizes These concerns are not captured As a proof of AEAD API sanity the first implementation of such proposed API should not be AES GCM but the classic default AES CBC with an HMAC tag The simple reason for it is that anyone can build AES CBC HMAC AEAD implementation today with simple existing well known NET classes Let s get a boring old AES CBC HMAC working over the new AEAD APIs first since that s easy for everyone to MVP and test drive The nonce IV naming issue was something I was undecided about happy with a change to IV so will change As for Get methods returning something this avoids any allocations There could be an overload Get that returns something Maybe it requires a naming change but I am pretty married to the idea that the whole API needs to be basically allocation free As for streams etc I am not overly bothered with that as they are higher level API s that can easily be constructed from the lower level primitives Obtaining a Tag before you have finished should not be allowed however you should know when you have called finish so I am not sure it should be in the API however it should be a defined behaviour so I have updated the API design to include a behaviour section so we can capture any others that are thought of As for which cipher I don t think any specific cipher should be the sole target in order to prove out a new general purpose API it needs to fit a number AES GCM and CBC should both be covered all on topic feedback good or bad is always helpful Class or interface How if at all do the current SymmetricAlgorithm classes interact with this How would this be used for persisted keys like TripleDESCng and AesCng can do Many of these Spans seem like they could be ReadOnlySpan thanks for getting the ball rolling on this API A few thoughts Tag generation and verification is a very important part of this API since misuse of tags can defeat the whole purpose If possible I d like to see tags built into the initialize and finish operations to ensure they can t be accidentally ignored That likely implies that encrypt and decrypt shouldn t use the same initialize and finalize methods I have mixed feelings about outputting blocks during decryption before getting to the end since the data isn t trustworthy until the tag has been checked which can t be done until all data has been processed We ll need to evaluate that tradeoff very carefully Is Reset necessary Should finish just reset We do that on incremental hashes but they don t need new IVs Class as has often been seen in the BCL with an interface you can t expand it later without breaking everything An interface is like a puppy for life unless default interface methods can be considered as a solution to that problem Also a sealed class from a abstract type is actually faster as of now because the jitt can devirtualise the methods now So it s basically free interface dispatch isn t as good still good just not as good I dunno how would you like that to work I have little interest in the current stuff as it s so confusing I would just patch all reasonable modern algos straight in leave DES in The other classes But I don t have all the answers so do you have any further thoughts on this Persisted keys should be easy Make an extension method on the key method or persistence store It s not initialized It s disposable so any refs can be dropped by normal disposable pattern If they try to set the key throw an invalid operation exception Yes to the read only spans I will adjust when I am not on the tube on my phone no problem I just want to see it happen more than anything Can you give a code snippet on how you see that working Not sure it does but code always brings clarity It s unfortunate but you really have to spit out the blocks early With hmac and hashing you don t but you don t have interim data just the state So in this case you would have to buffer an unknown amount of data Let s take a look at the pipelines example and TLS We can write k of plaintext but the pipeline buffers are today the size of a k page So we would at best want to encrypt decrypt k Of you don t give me the answer until the end you need to allocate internal memory to store all of that and then I presume throw it away when I get the result Or will you wipe it What if I decrypt mb and you hold that memory after I now have to worry about latent memory use Not on the init reset thing not your ideas my current API shape it doesn t sit well with me so I am open to a new suggestion I have little interest in the current stuff as it s so confusing I would just patch all reasonable modern algos straight in leave DES in The other classes The problem would be that container formats like EnvelopedCms or EncryptedXml may need to work with DES CBC AES CBC etc Someone wanting to decrypt something encrypted with ECIES AES CBC PKCS HMAC SHA probably wouldn t feel that they re doing old and crufty things If it s only supposed to be for AE then that should be reflected somewhere in the name Right now it s generic cipher which I was am at some point going to sit down with a dictionary glossary and find out if there s a word for an encryption algorithm in a mode of operation since I think that cipher algorithm therefore Aes I was merely pointing out that it s not my subject area or of much interest to me so I am willing to defer to you and the community on this topic I haven t thought through the implications for this After quickly scanning through these one option is allow them to take an instance of the Cipher or whatever it s called class This might not be done in the first wave but could quickly follow it up If the API is super efficient then I see no reason they should do their own thing internally and is exactly the use case for this API As a side bar on the naming I must admit its a tough one however Openssl cipher Ruby cipher Go cipher package with ducktyped interfaces for AEAD etc Java cipher Now I am all for being different but there is a trend If something better is possible that is cool Possibly BlockModeCipher I have made a few changes I will change naming if a better name is decided upon When I started trying to answer questions I realized the API is already missing encryption decryption differentiation so in your example it doesn t know whether to encrypt or decrypt data Getting that put in might add some clarity I could imagine a couple ways that the API could enforce proper tag usage based on the assumption that this is an AEAD API not just symmetric encryption since we already have SymmetricAlgorithm ICryptoTransform CryptoStream Don t take these as prescriptive just as an example of enforcing the tagging By method By class That said if it doesn t buffer on decryption is it practical to ensure decryption actually gets finished and the tag gets checked Can Update somehow figure out that it s time to check Is that something Dispose should do Dispose is a bit dangerous since you may have already trusted the data by the time you dispose the object As far as naming our precedent is SymmetricAlgorithm and AsymmetricAlgorithm If this is intended for AEAD some ideas could be AuthenticatedSymmetricAlgorithm or AuthenticatedEncryptionAlgorithm Some thoughts API ideas thanks for contributing thoughts Where should tags go in your API Are they implicitly part of the ciphertext If so that implies a protocol that some algorithms don t actually have I d like to understand what protocols people might care about to see whether implicit tag placement is acceptable or if it needs to be carried separately I noticed the encrypt decrypt issue as well but hadn t had time tonight to fix so glad for your design I prefer the methods over the class as it allows better aggressive recycling buffers for keys and IV s can add up As for a check before the dispose It s not possible to tell the end of an operation unfortunately interfaces I would say are a no go due to the version problem mentioned previously Unless we rely on default implantation in the future Also interface dispatch is slower the array segments also are our as span is the more versatile lower primitive However extension methods could be added for arraysegment to span if there was demand later Some of your properties are of interest so will update when I am at a computer rather than on my phone Good feedback all round Tags are part of ciphertext This is modelled after CAESAR which includes AES GCM I ve used interfaces to illustrate thoughts only I m perfectly ok with static methods classes Span does not exist I don t care about what may or may not be coming it is not in NetStandard and it is not in the normal NET that serious projects actually use yeah yeah I know it s in Core but Core is a toy for now I d be happy to personally consider Span when I see it until then ArraySegment is the closest NetStandard API that actually ships I will take a deeper look athe CAESAR API that is useful As for Span it is shipping around the time frame I believe which is hopefully the same time the first implementation of this API would ship or at least the earliest possible time it could If you take a look at the current prerelease nuget package it supports down to net standard and there is no plans to change that on release Maybe can confirm that as he is doing work to add Span based API s across the framework as we speak Nuget for I would say it s the only real choice for a brand new API Then extension methods etc can be added to take an ArraySegment if you so chose and if it is useful enough then it could be added to the framework but it s trivial to turn an ArraySegment into a Span but the other way requires copying data The problem I see with that API above is it will be a disaster for performance on any chunked data Say for instance network traffic if a single authenticated block is split over multiple reads from an existing stream I need to buffer it all into a single insert data structure and encrypt decrypt all at once The defeats all attempts to do any kind of zero copy on that data Networking frameworks such as those that Pipelines provides manage to avoid almost all copies but then if they hit any kind of crypto in this API all of that is gone The separate configuration object or bag has actually been involved in a recent discussion on another API I have been having I am not opposed to it in principle as if it grows in future it can become a mess to have large numbers of properties on the main object A couple of things have occurred to me The current proposal calls TagSize an out value well a get only property But for both GCM and CCM it s an input to encryption and derivable from decryption since you ve supplied the actual tag The proposal assumes that input and output can happen at the same time and piecemeal IIRC CCM can t do streaming encryption the length of the plaintext is an input into the first step of the algorithm Padded modes lag decryption by at least one block since until Final is called they don t know if more data is coming if the current block needs the padding removed Some algorithms might consider the AD element to be required at the beginning of the operation making it more like an Init ctor parameter than a late bound association I don t know if container formats EnvelopedCms EncryptedXml would need to extract the key or if it would simply be up to them to generate it and remember it for as long as they need to to write it down Apparently I didn t hit the comment button on this yesterday so it won t be acknowledging anything after I have made a few changes at Z True tag size would need to be variable Agreed If we just look at encryption for now to simplify the use case You are correct that some ciphers will return nothing less or more There is a general question around what happens if you don t provide a big enough buffer On the new TextEncoding interfaces using span there was a suggestion around having the return type an enum to define if there was enough space to output or not and the size actually written in an out param instead This is a possibility In the CCM case I would just say it returns nothing and will have to internally buffer until you call finish at which point it would want to dump the whole lot Nothing precludes you from just calling finish as your first call if you have all the data in a single block In which case there might be a better name Or it is possible to throw if you try an update on those ciphers CNG returns an invalid size error if you try to do a continuation on CCM for instance As for when the tag is set on decryption you often don t know it until you have read the entire packet if we take TLS as an example we might have to read k network packets to get to the tag at the end of a k block So we now have to buffer the entire k before we can start decryption and there is no chance to overlap I am not saying this would be used for TLS just that an IO bound process is common for these types of ciphers be it disk or network re chunked streams and buffering limits You have to pick your battles You won t be able to create a unifying API aligned with every singe nice to have goal in the AE world and there are many such goals Ex there is a decent chunked AEAD streaming in but it s not a standard by any stretch and such a standard does not exist At a higher level the goal is secure channels see this and we need to think smaller for now Chunking buffer limiting are not even on the radar for standardisation efforts AEADs with large section Encryption Decryption operations are fundamentally about transforms These transforms require buffers and are not in place output buffers must be larger than input buffers at least for Encrypt transform RFC might also be of interest interesting that you bring up TLS I would argue that SSLStream were it to use this API must not return any unauthenticated results to an application since the application won t have any way to defend itself Sure but that is SSLStreams problem I have prototyped this exact thing managed TLS at the protocol level calling out to CNG and OpenSSL for the crypto bits on top of pipelines The logic was pretty simple encrypted data comes in decrypt the buffer in place attach to the out bound and repeat until you get to the tag At the tag call finished If it throws close the pipeline If it doesn t throw then flush allowing the next stage to go to work either on the same thread or via dispatch My proof of concept was not ready for primetime but by using this and avoiding alot of copies etc it showed a very decent perf increase The problem with any networking is where things in the pipeline start allocating their own buffers and not using as much as possible the ones moving through the system already OpenSsl s crypt and CNG have this same method Update Update Finish Finish can ouput the tag as discussed Updates must be in block size for CNG and for OpenSsl it does minimal buffering to get to a block size As they are primitives I am not sure we would expect higher level functionality from them If we were designing a user level API rather than primitives to construct those I would then argue that key generation IV construction and entire authenticated chunks should all be implemented so I guess it depends what the target level of this API really is Wrong button who had some interesting ideas on nonce management So nonce management is basically a user problem and is specific to their setup So make it a requirement You must plug in nonce management and don t supply a default implementation or any implementations at all This rather than a simple cipher Init myKey nonce forces users to make a specific gesture that the understand the risks idea might help with both nonce management problems and differences between algorithms I agree that it s likely important not to have built in implementation to ensure that users understand that nonce management is a problem they need to solve How does something like this look But whats the point of the INonceProvider It s just an extra inteface type if the Init just takes a none and is needed to be called before you start any block isn t that the same thing without an extra interface Also I am no crypto expert but doesn t AES require an IV Which isn t a nonce but needs to be provided by the user It s just an extra inteface type That s kind of the point It essentially says that nonce management is a problem not just passing in a zeroed or even random byte array It might also help prevent inadvertent reuse if people interpret to mean return something different than you did last time It s also helpful to not need it for algorithms that don t have nonce management problems like AES SIV or perhaps AES CBC HMAC The exact IV nonce requirements vary based on mode For example AES ECB does not require a nonce or IV AES GCM requires a bit nonce that must never be reused or the security of the key breaks Low entropy is fine as long as the nonce isn t reused AES CBC requires a bit IV that must be random If the IV repeats it only reveals whether the same message has been sent before AES SIV doesn t need an explicit IV since it derives it from other inputs AES CBC needs IV right So are you going to have an InitializationVectorProvider Its not a nonce but nonce like and reusing the last block led to a tls attack because the iv can be predicted You explicitly can t use say a sequential nonce for CBC Yeah but an IV isn t a nonce so you can t have the term nomce provider I didn t mean to imply AES CBC doesn t need an IV it does I just meant to speculate about some schemes that derive the IV from other data Sure I guess my point is I like it generally I can pool the provider but either call it an iv provider or have interfaces to be clear on intent factories passed into cipher constructors are a bad design It completely misses the fact that nonce does not exist by itself the used once constraint has a context In cases of CTR and GCM which uses CTR modes the context of the nonce is the key Ie nonce provider must return a nonce that is used only once within a context of a specific key Since the in your proposed API is not key aware it cannot generate correct nonces other than via randomness which is not what a nonce is even if the bit space was large enough for statistical randomness to work safely I m not entirely sure what this discussion thread aims to achieve Various Authenticated Encryption design ideas are discussed ok What about Authenticated Encryption interfaces already built into NET Core specifically into its ASP NET API There is etc All these capabilities are already implemented extensible and shipping as part of NET Core today I m not saying DataProtection crypto is perfect but is the plan to ignore them Change them Assimilate or refactor DataProtection crypto was built by Levi Broderick He knows the subject matter and his opinion input feedback would be most valuable to this community I enjoy crypto themed entertainment as much as anyone but if someone wants to get serious about crypto API design then actual experts that are already on MS team should be engaged nonce providers needing to be key aware is a good point I wonder if there s a reasonable way to modify these APIs to enforce that DataProtection is a fine API but it s a higher level construct It encapsulates key generation and management IVs and output protocol If somebody needs to use say GCM in an implementation of a different protocol DataProtection doesn t make that possible The NET crypto team includes and myself Of course if wants to chime in he s more than welcome I agree with in that this is supposed to be a low level primitive in fact it says that in the title While data protection etc are designed to be used directly in usercode and reduces the ability to shoot yourself in the foot the way I see this primitive is to allow the framework and libraries to build higher level constructs on a common base With that thought in mind the provider is fine if it has to be supplied anytime a key is supplied It does make it a little messy let me explain using TLS its a well known use of AES block modes for network traffic is all I get a frame maybe over TU s with the MTU of the internet It contains the nonce or part of the nonce with bytes left hidden I then have to set this value on a shell provider and then call decrypt and go through my cycle of decrypting the buffers to get a single plain text If you are happy with that I can live with it I am keen to get this moving along so keen to update the design above to something we can agree on Thanks for forking the discussion getting some free time to jump onto this can you confirm update the top post as gold standard target of this evolving conversation If not can you update it I see the current proposal having a fatal issue and then other issues with being too chatty If you look at a true AEAD primitive the privacy data and the authenticated data are mixed lock step See for Auth Data and CipherText This of course continues for multiple blocks not just Since all the world s a meme can t resist sorry Can t the API seems chatty with new init update etc I d propose this programmer s model Typically AAD plaintext so I ve seen where the entire AAD is passed as a buffer and then the cipher crunches over the rest of the potentially gigabyte stream e g CipherModeInfo Also size of myKey already establishes AES no need for another parameter Init becomes an optional API in case caller wishes to reuse existing class existing AES constants and skipping AES subkey generation if AES key is same cipher s API should shield caller from block size management internals like most other crypto APIs or even existing NET APIs Caller concerned with buffer size optimized for their use case e g network IO via K buffers Demoing with a prime number K to test implementation assumptions inputSpan is readonly And input So need an outSpan Update does Encrypt or Decrypt Just have Encrypt and Decrypt interfaces to match a developer s mental model is also the most important desired data at this instant return that Actually going a step further why not just Also please steer away from and the sorts The crypto primitives don t need this just stick to iv my favorite for small data or the supposed new cool but too much abstraction IMHO Nonce provider operates at a layer above and the result of it could just be the seen here The problem with making primitives so primitive is people will simply use them incorrectly With a provider we can at least force some thought into their use We re talking about AEAD in general of which GCM is specific So first the generalized case should drive the design not the specific case Secondly how does merely shifting from to actually solve the nonce issue You ve only changed the name label on the problem while simultaneously making it more complex than it should be Third since we re getting into policies on protection should we also get into key protection policies What about key distribution policies Those are obviously higher level concerns Finally nonce is extremely situational on usage at higher layers You don t want to have a brittle architecture where cross layer concerns are being coupled together Frankly if we could hide primitives unless someone makes a gesture to say I know what I m doing I d push for that But we can t There are far too many bad crypto implementations out there because people though Oh this is available I ll use it Heck look at AES itself I ll just use that with no HMAC I want to see APIs be secure by default and if that means a little more pain then frankly I m all for it of developers do not know what they re doing when it comes to crypto and making it easy for the who do should be a lower priority Span does not exist I don t care about what may or may not be coming it is not in NetStandard as points out is NET Standard so can be used on any framework Its also safer than as it only lets you access the actual window referenced rather than the whole array Also prevents modification to that window again unlike array segment where anything passed it can modify and or retain a reference to the passed array Span should be the general go to for sync apis The fact an api using Span can additionally cope with stackalloc d native memory as well as arrays is the icing i e With ArraySegment the readonly is suggested via docs and no out of bounds read modifications are prevented However with Span the readonly is enforced by api as well as out of bounds reads of the arrays being prevented It conveys intent with the parameters far better and is less error prone with regards to out of bounds reads writes never said that was in NetStandard any shipped What he did say is agree that is not in any shipped NetStandard that will be shipping around the time frame For this particular Github issue however read only discussion is right now there is no clarity on scope or purpose of the API to be designed Either we go with raw low level primitive AEAD API ex similar to CAESAR Pros nice fit for AES GCM CCM existing test vectors from good sources NIST RFC will be happy will meditate over making primitives so primitive but will eventually see the Yin and Yang because primitives are primitive and there is no way to childproof them Cons Expert users the proverbial will use the low level APIs responsibly while the other non expert users will misuse it to write broken NET software that will be responsible for the vast majority of NET CVEs which will greatly contribute to the perception that NET is an insecure platform Or we go with high level misuse impossible or resistant AEAD API Pros of non expert users will continue to make mistakes but at least not in AEAD code s I want to see APIs be secure by default resonates deeply in the ecosystem and security prosperity and good karma befall all Many good API designs implementations are already available Cons No standards No test vectors No consensus on whether AEAD is even the right goal to target for high level online streaming API spoiler it s not see Rogaway s we do both Or we enter analysis paralysis and might as well close this issue right now I strongly feel that being part of the core language crypto needs to have a solid low level foundational API Once you have that creating high level APIs or training wheels APIs can be bridged quickly by the core or community But I challenge anyone to do the reverse elegantly Plus the topic is General low level primitive for ciphers is there a timeline to converge and resolve this Any plans on involving non Microsoft folks beyond such GitHub alerts Like a min conference call I m trying to stay out of a rabbit hole but we re betting that NET core crypto will be at a certain level of maturity and stability so can triage for such discussions We re still paying attention and working on this We ve met with the Microsoft Cryptography Board the set of researchers and other experts who advice Microsoft s usage of cryptography and will have more information to share soon Based on a little data flow doodling and the advice of the Crypto Board we came up with the following Our model was GCM CCM SIV and CBC HMAC note that we re not talking about doing SIV or CBC HMAC right now just that we wanted to prove out the shape This proposal eliminates data streaming We don t really have a lot of flexibility on that point Real world need low combined with the associated risks extremely high for GCM or impossibility thereof CCM means it s just gone This proposal uses an externalized source of nonce for encryption We will not have any public implementations of this interface Each application protocol should make its own tying the key to the context so it can feed things in appropriately While each call to TryEncrypt will only make one call to GetNextNonce there s no guarantee that that particular TryEncrypt will succeed so it s still up to the application to understand if that means it should re try the nonce For CBC HMAC we would create a new interface IIVProvider to avoid muddying the terminology For SIV the IV is constructed so there s no acceptable parameter and based on the spec the nonce when used seems to just be considered as part of the associatedData So SIV at least suggests that having nonceOrIV as a parameter to TryEncrypt is not generally applicable TryDecrypt most definitely throws on invalid tag It only returns false if the destination is too small per the rules of Try methods Things that are definitely open for feedback Should sizes be in bits like significant parts of the specs or bytes since only values are legal anyways and we re always going to divide and some of the parts of specs talk about things like the nonce size in bytes Parameter names and ordering The LastTag LastNonceOrIV properties Making them be writable Spans on a public TryEncrypt just means there are three buffers that could be too small by making them sit on the side the Try is more clear the base class can make the promise that it ll never offer a too short buffer Offering up an AE algorithm for which this doesn t work Should be moved to the end with a default of Or overloads made which omit it Does anyone want to assert love for or hatred for the returning methods Low allocation can be achieved by using the Span method this is just for convenience The size ranges methods were sort of bolted on at the end Their purpose is that If the destination span is less than min return false immediately The returning methods will allocate a buffer of max and then Array Resize it as needed Yes for GCM and CCM but that s not true for CBC HMAC or SIV Is there an algorithm that would need to take the associatedData length into account Definitely bytes not bits Nonce provider that s not key aware is a big mistake Nonce provider that s not key aware is a big mistake You can write your nonce provider however you like We aren t providing any What about deterministic cleanup What about deterministic cleanup IDisposable Good call Added it to AuthenticatedEncryptor AuthenticatedDecryptor I don t think they should probe for disposability on the nonce provider the caller can just stack the using statements concept purpose makes no sense to me echoing others Let primitives be primitive pass in the nonce the same way you pass in the key ie as bytes however declared No AE AEAD spec forces an algorithm for how nonces are generated derived this is a higher layer responsibility at least in the let primitives be primitive model No streaming Really What is the justification to forcibly remove streaming from a stream cipher like AES GCM at a core foundational level For example what does your crypto board recommend these two recent scenarios we reviewed Client has large healthcare files between GB The core only sees a data stream though between two machines so it s one pass stream Obviously a fresh key is issued for each GB file but you ve just rendered every such workflow useless You now want us to a buffer that data memory no pipe lining b perform encryption all machines in the pipeline are now idle c write the data out first byte written after a and b are done Please tell me you re joking You guys are knowingly putting encryption is a burden back into the game Physical security unit has multiple K streams which are also encrypted for at rest scenarios Fresh key issuance happens at GB boundary You propose buffering the entire clip I don t see any input from the community of people actually building real world software asking to remove streaming support But then the team disappears from the community dialog huddles internally and then comes back with something nobody asked for something that kills real applications and re enforces that encryption is slow and expensi,Yes
,,,,,
e skip it You can provide and which would support both options instead of imposing your decision for the entire ecosystem Elegant design eliminates complexity not control What is the justification to forcibly remove streaming from a stream cipher like AES GCM at a core foundational level I think it was something like This proposal eliminates data streaming We don t really have a lot of flexibility on that point Real world need low combined with the associated risks extremely high for GCM or impossibility thereof CCM means it s just gone GCM has too many oops moments where it allows key recovery If an attacker can do a chosen ciphertext and watch the streaming output from before tag verification they can recover the key Or so one of the cryptanalysts tells me Effectively if any GCM processed data is observable at any point before tag verification then the key is compromised I m pretty sure that the Crypto Board would recommend NOT using GCM for first scenario but rather CBC HMAC If your second scenario is k framing and you re encrypting each k frame then that works with this model Each k nonce tag frame gets decrypted and verified before you get the bytes back so you never leak the keystream key For comparison I m currently developing this let primitives be primitive crypto API is my class for authenticated encryption For me it turned out to be useful to be able to talk about an crypto primitive independently of a key For example I often want to plug a specific primitive into a method that works with any AEAD algorithm and leave the generation of keys etc to that method Therefore there s an class and a separate class Another very useful thing that already prevented several bugs is to use distinct types to represent data of different shapes e g a and a instead of using a plain or for everything AeadAlgorithm API click to expand he she is correct you need to rely on the program not outputting until authentication So for example if you aren t authenticating or just not yet you can control the input for a block and therefore know the output and work backwards from there E g a man in the middle attack can inject known blocks into a cbc stream and perform a classic bit flipping attack Not sure how to solve the large chunks of data issue really other thank to chunk them with serial nonces or similar ala TLS Well let me rephrase that I do but only in the network small sizes case which isn t enough for a general purpose lib In the spirit of openness is it possible to reveal who is on the Microsoft Cryptography Review Board and ideally the comments opinions of specific members that reviewed this topic Brian and who else using reverse psychology I m happy that streaming AEAD is out This means that continues to be the only practical based streaming AEAD for the average Joe Thank you MS Crypto Review Board Building on comment his her approach is driven by RFC which I ve referenced earlier There are many notable quotes in RFC Requirements on Nonce Generation It is essential for security that the nonces be constructed in a manner that respects the requirement that each nonce value be distinct for each invocation of the authenticated encryption operation for any fixed value of the key Requirements on AEAD Algorithm Specifications Each AEAD algorithm MUST accept any nonce with a length between N MIN and N MAX octets inclusive where the values of N MIN and N MAX are specific to that algorithm The values of N MAX and N MIN MAY be equal Each algorithm SHOULD accept a nonce with a length of twelve octets Randomized or stateful algorithms which are described below MAY have an N MAX value of zero An Authenticated Encryption algorithm MAY incorporate or make use of a random source e g for the generation of an internal initialization vector that is incorporated into the ciphertext output An AEAD algorithm of this sort is called randomized though note that only encryption is random and decryption is always deterministic A randomized algorithm MAY have a value of N MAX that is equal to zero An Authenticated Encryption algorithm MAY incorporate internal state information that is maintained between invocations of the encrypt operation e g to allow for the construction of distinct values that are used as internal nonces by the algorithm An AEAD algorithm of this sort is called stateful This method could be used by an algorithm to provide good security even when the application inputs zero length nonces A stateful algorithm MAY have a value of N MAX that is equal to zero One idea potentially worth exploring is the passing of zero length null Nonce which might even be the default The passing of such special Nonce value will randomize the actual Nonce value which will be available as Encrypt s output If stays because reasons another idea is to add a call which will be triggered every time the is rekey ed If on the other hand the plan is to never rekey instances this will trash GC if we want to build a streaming chunk encrypting API ex chunk network packet and every chunk must be encrypted with a different key ex Netflix protocol Inferno others Especially for parallel enc dec operations where we d want to maintain a pool of AEAD engines and borrow instances from that pool to do enc dec Let s give GC some love From my point of view the sole purpose of crypto primitives is to implement well designed higher level security protocols Every such protocol insists on generating nonces in their own way For example TLS follows the recommendations of RFC and concatenates a byte IV with an byte counter TLS xor s an byte counter padded to bytes with a byte IV Noise uses an byte counter padded to bytes in big endian byte order for AES GCM and an byte counter padded to bytes in little endian byte order for ChaCha Poly GCM is way too brittle for randomized nonces at typical nonce sizes bit And I m not aware of any security protocol that actually supports randomized nonces There is not much demand for more APIs providing crypto primitives of developers need high level recipes for security related scenarios storing a password in a database encrypting a file at rest securely transferring a software update etc However APIs for such high level recipes are rare The only APIs available are often only HTTPS and the crypto primitives which forces developers to roll their own security protocols IMO the solution is not to put a lot of effort in designing APIs for working with primitives It s APIs for high level recipes Thanks for the feedback everyone A couple of questions While streaming decryption can fail catastrophically streaming encryption could be doable Does streaming encryption along with a non streaming option but only non streaming decryption sound more useful If yes there are a couple of problems to solve a Some algorithms CCM SIV don t actually support streaming Should we put streaming encryption on the base class and buffer streamed inputs or throw from the derived classes b Streaming AAD likely isn t possible due to implementation constraints but different algorithms need it at different times some need it at the beginning some don t need it until the end Should we require it up front or have a method for adding it that works when the individual algorithms allow We re open to improvements to INonceProvider as long as the point is that users need to write code generating a new nonce Does anyone have another proposed shape for it a I think it could be an issue not to warn the user early Imagine the scenario from someone above a gb file They think they are getting streaming then sometime later another dev changes the cipher and next thing the code is buffering gb or trying before returning a value b Again with the streaming or networking idea for instance AES GCM etc you don t get the AAD information until the end for decryption As for Encryption I am yet to see a case where you don t have the data upfront So I would say at least for encryption you should require it at the start decryption is more complex I think it s really a non issue supplying the bytes for the nonce through an interface or just directly is neither here nor there You can achieve the same thing both ways I just find it uglier for a primitive but am not vehemently opposed if it makes people sleep better at night I would just strike this off as a done deal and move on with the other issues Regarding the deliberation process We could argue all day if closed door decisions devoid of community involvement is an effective justification but we ll go off topic so I ll let that be Plus without richer face to face or realtime comms I don t want to upset anyone there Regarding streaming the streaming implies no AES GCM security argument Specifically steaming return decrypted data to caller before tag verification no security This isn t sound claims chosen ciphertext watch output recover key while claims control input for a block therefore know output work from there Well in AES GCM the only thing the tag does is integrity verification tamper protection It has impact on privacy In fact if you remove the GCM GHASH tag processing from AES GCM you simply get AES CTR mode It s this construct that handles the privacy aspect And CTR is malleable to bit flips but isn t broken in any of the ways you two are asserting recovering key or plaintext because that would mean the fundamental AES primitive is compromised If your cryptanalyst who is it knows something the rest of us don t know he she should be publishing it The only thing possible is an attacked can flip bit N and know that bit N of the plaintext was flipped but they never know what the actual plaintext is So plaintext privacy is always enforced integrity verification is simply deferred till end of stream and no key is ever compromised For products and systems where streaming is foundational you can now at least engineered a tradeoff where one momentarily steps down from AEAD to regular AES encryption then step up back to AEAD upon tag verification That unlocks several innovative concepts to embrace security instead of going You want to buffer all that are you crazy We can t do encryption All because you want to implement just rather than both and or equivalents Not specific to GCM Now AES GCM isn t some magical beast to have oops moments galore It s simply AES CTR GHASH a sort of hash if I may Nonce considerations related to privacy are inherited from CTR mode and tag considerations related to integrity come from the variable tag sizes allowed in the spec Still AES CTR GHASH is very similar to something like AES CBC HMAC SHA in that the first algorithm handles privacy and the second handles integrity In AES CBC HMAC SHA bit flips in ciphertext will corrupt corresponding block in decrypted text unlike CTR AND also deterministically flip bits in the following decrypted plaintext block like CTR Again an attacker won t know what the resulting plaintext will be just that bits were flipped like CTR Finally the integrity check HMAC SHA will catch it But only processing the last byte like GHASH So if your argument of holding back ALL decrypted data until integrity is OK is truly good it should be applied consistently So ALL data coming out of the AES CBC path should also be buffered internally by the library till HMAC SHA passes That basically means on NET no streaming data can even benefit from AEAD advances NET forces streaming data to downgrade To pick between no encryption or regular encryption No AEAD Where buffering is technically impractical architects should at least have the option to warn end users that drone footage may be corrupt rather than no eyes for you It s the best we have Data is getting larger and security needs to be stronger Streaming is also a reality designers have to embrace Until the world crafts a truly integrated AEAD algorithm which can natively detect corruption mid stream tampering we are stuck with encryption authentication as bolted on buddies True AEAD primitive are being researched but we ve just got encryption authentication for now I care less about AES GCM as much as I care about a fast popular AEAD algorithm that can support streaming workloads super prevalent in a data rich hyper connected world Use AES CBC HMAC Use insert workaround the Crypto Board would recommend NOT using GCM for first scenario but rather CBC HMAC Leaving aside everything mentioned above or even the specifics of the scenario suggesting AES CBC HMAC isn t free It s x slower than since AES CBC encrypt is non parallelizable and since GHASH can be accelerated via the PCLMULQDQ instruction So if you re at GB sec with AES GCM you re now going to hit MB sec with AES CBC HMAC This again perpetrates the Crypto slows you down skip it mindset one that security folks try hard to fight encrypting each k frame video codecs should suddenly do encryption Or the encryption layer must now understand video codecs It s just a bitstream at the data security layer The fact that it s a video genomic data images proprietary formats etc shouldn t be a security layer concern An overall solution shouldn t co mingle core responsibilities Nonce NIST allows for randomized IVs for length exceeding bits See section at NIST Nothing new here nonce requirements come from CTR mode Which is also fairly standard across most stream I don t understand the sudden fear towards nonces it s always been Still so while the debate makes for a clunky interface at least it doesn t eliminate innovation like the no stream for you imposition I ll concede to any day if we can get the AEAD security streaming workload innovations I hate calling something basic like streaming an innovation but that s where I fear we would regress I d love to be proven wrong I m just a guy who after a long day at work gave up movie night with my kids to type this I m tired and could be wrong But at least have an open fact based community dialog rather than anecdotes or committee reasons or some other voodoo I m in the business of promoting secure NET and Azure innovations I think we ve got aligned goals Speaking of community dialog Can we please have a community Skype call Expressing a complex topic like this blows into a giant wall of text Pretty please Please don t do a Skype call that s the very definition of closed door meeting with no records available for the community Github issues are the right vehicle for all parties to have a civil documented discourse ignoring MS comment removal Crypto Review Board probably did a Skype call too It s not the fault of the MS folks participating in this thread they likely have very limited access to persuasion power over the ivory towers of MS Crypto Review Board whatever whoever that is Regarding streaming AEAD Byte size streaming encryption is possible for MAC last modes like GCM CTR HMAC but not possible for MAC first modes like CCM Byte size streaming decryption is fundamentally leaking and therefore is not considered by anyone Block size streaming encryption is also possible for CBC HMAC but that does not change anything Ie Byte size or Block size approaches to streaming AEAD are flawed Chunk size streaming encryption and decryption work great but they have constraints they require buffering beyond block size This can be done by the library API if buffering is controlled capped ex Inferno or left to the upper layer calling layer to deal with Either way works Chunked streaming AEAD is not standardized Ex Inferno MS own DataProtection make your own This is just a summary of what everyone in this discussion so far already knows to make sure I understand properly are you ok with this API providing streaming encryption but no streaming decryption well humans brainstorming in real time is certainly beneficial record keeping concerns can be resolved with meeting minutes Back to the technical side while chunking works for streaming decryption that s not a low level security primitive It s a custom protocol And a non standard one like you noted are you ok with this API providing streaming encryption but no streaming decryption No I m not If such API were available it would be easy to create a stream encrypted ciphertext of a size that no buffer decryption will be able to decrypt out of memory This there hasn t been much agreement so far but I think we can all agree whatever way it goes an asymmetric API would be a disaster Both from a hey were is the stream decrypt methods I thought I would rely on because there were encrypt methods and because of comments above Agreed Asymmetric enc dec API would be awful Any updates folks Apparently I conflated a few attacks Inherent weaknesses in stream ciphers which AES CTR and AES GCM are allow for chosen ciphertext attacks to allow for arbitrary plaintext recovery The defense against chosen ciphertext attacks is authentication so AES GCM is immune unless you re doing streaming decryption and you can identify from side channel observations what the plaintext would have been For example if the decrypted data is being processed as XML it ll fail very quickly if characters other than whitespace or are at the beginning of the decrypted data So that s streaming decryption re introduces concerns with stream cipher design which you might have noticed NET does not have any of While looking for where the key recovery was coming from there are papers like Authentication weaknesses in GCM but that one is recovering the authentication key based on short tag sizes which is part of why the Windows implementation only allows bit tags I was probably advised about other authentication key recovery vectors as to why streaming GCM is dangerous In an earlier noted Byte size streaming decryption is fundamentally leaking and therefore is not considered by anyone Byte size or Block size approaches to streaming AEAD are flawed That combined with CCM and SIV not being capable of doing streaming encryption and the comment of it would be weird to have one streaming and not the other suggests that we re back to the proposal of just having one shot encrypt and decrypt So it seems we re right back at my last API proposal Unless there are other outstanding issues that I managed to forget while taking some time off Welcome back I m going to sleep shortly but briefly We ve conflated protocol design with primitive design before on this thread I ll just say that chosen ciphertext attacks is a protocol design concern not a primitive concern Streaming AEAD decryption at least allows you to have privacy and then immediately upgrades to privacy authenticity at last byte Without streaming support on AEAD i e traditional privacy only you re permanently restricting folks to a lower privacy only assurance If technical merits are insufficient or you re rightfully skeptical of the authoritativeness of my arguments I ll try the outside authority route You should know that your actual underlying implementation supports AEAD including AES GCM in streaming mode The Windows core OS allows for streaming GCM via the or functions See there Or an user code Or a Microsoft authored CLR Or that the implementation has been NIST FIP as recently as earlier this year Or that both Microsoft and NIST both spent significant resources around the AES implementation and certified it and And despite all of this nobody has faulted the primitives It makes no sense at all for NET Core to suddenly come around and impose it s own crypto thesis to water down the powerful underlying implementation Especially when BOTH streaming and one shot can be supported simultaneously very trivially More Well the above it true for OpenSSL even with their newer evp APIs And it s true for BouncyCastle And it s true with Java Cryptography Architecture cheers Sid if the cryptoboard is so concerned why do they let windows CNG do this If you check Microsoft s NIST FIPS AES validation ex you ll notice the following AES GCM Plain Text Lengths AAD Lengths AES CCM Plain Text Length AAD Length There is no validation for streaming I m not even sure whether NIST checks that ex AES GCM implementation should not be allowed to encrypt more than Gb plaintext another ridiculous limitation of GCM I am not massively wedded to streaming as my use shouldn t ride over k however fragmented buffers would be nice and should pose no risk at all I actually suspect that cng made it s interface the way it is for exactly that purpose e g I want to be able to pass in a number of spans or similar linked list for instance and have it decrypt in one go If it decrypts to a contiguous buffer that s all fine So I guess moving the shadowy crypto board on the streaming style API is a no go for now so let s move forward make a one shot API There is always scope to expand an API IF enough people show a need later the point is that it s the streaming API that s gone through extensive review by NIST Labs and MSFT Each build being validated is between and MSFT and OpenSSL and Oracle and other crypto heavyweights have invested HEAVILY in getting these API and implementations validated for over years Lets not get distracted by the test plan s specific plain text sizes because I m confident NET will support sizes other than regardless of streaming or one shot The point is all those battle tested APIs literally on weapon support systems on all these platforms support streaming AEAD at the crypto primitive API level Unfortunately every argument so far against it has been an application or protocol level concern cited as a pseudo concern at the crypto primitive level I m all for let the best idea win but unless the net core crypto team MSFT or community has some ground breaking discovery I just don t see how everyone doing crypto so far from all different organizations are wrong and they are right PS I know we re in disagreement here but we all want what s best for the platform and it s customers unless the AEAD interface not necessarily implementation being defined today supports a streaming API surface I don t see how folks can extend it without having two interfaces or custom interfaces That would be a disaster I m hoping this discussion leads to an interface that s future proof or very least mirrors other AEAD interfaces that have been around for many years I tend to agree But this issue is going nowhere fast and when that happens we are likely to hit a crunch point either it won t make it for or it will have to be rammed through with no time left to iron out issues I ll be honest I have gone back to my old wrappers and am just revamping them for We ve got a few reference APIs for or C Bouncy or CLR Frankly any of them will do and long term I wish C to have something like Java s Java Cryptography where all crypto implementations are against a well established interface allowing one to swap out crypto libraries without impacting user code Back here I think it s best we extend the NET Core s interface as If we re ifying all s that should permeate the entire API in the namespace for overall consistency Edit Fixed JCA links If we re Spanifying all byte s that should permeate the entire API in the System Security Cryptography namespace for overall consistency We did that already Everything except ICryptoTransform because we can t change interfaces I think it s best we extend the NET Core s ICryptoTransform The problem with this is the calling pattern is very awkward with getting the tag out at the end particularly if CryptoStream is involved I wrote this originally and it was ugly There s also the problem of how to get one of these since the GCM parameters are different than the CBC ECB parameters So here are my thoughts Streaming decryption is dangerous for AE In general I m a fan of give me the primitive and let me manage my risk I m also a fan of NET shouldn t easily allow completely unsafe things because that s some of its value proposition If as I misunderstood originally the risks of doing GCM decryption badly were input key recovery then I d still be at this is too unsafe The difference between NET and everything else would be having taken longer to do this the world has learned more But since it isn t if you really want the training wheels to come off then I guess I ll entertain that notion My fairly raw thoughts to that end adding to the existing suggestions so the one shot remains though I guess as a virtual default impl instead of an abstract AssociatedData comes at Initialize because algorithms that need it last can hold on to it and algorithms that need it first can t have it any other way Once a shape is decided for what streaming would look like and whether people think CCM should internally buffer or should throw when in streaming encryption mode then I ll go back to the board I know what you mean about plucking and programming the tag from the end of the stream for symmetry across encrypt decrypt It s tricky but worse if left to each user to solve I have an implementation I can share under MIT will need to look internally with my team not at my desk mobile A middle ground could be like OpenSSL or NT s bcrypt where you need to plug the tag right before the final decrypt call since that s when the tag comparisons happen i e a before final decrypt and after final encrypt would work but offloads tag management to the user Most will simply append the tag to the cipherstream since it s the natural temporal order I do think expecting the tag in itself in decrypt breaks symmetry in space byte flow and time tag check at end not start which limits its usefulness But the above Tag APIs resolve that Also for encrypt needs the IV before any crypto transforms Lastly for encrypt and decrypt needs the AES encryption keys before any transforms I m missing something obvious or you forgot to type that bit I do think expecting the tag in Initialize itself in decrypt breaks symmetry In CBC HMAC the usual recommendation is to verify the HMAC before starting any decryption so it s a tag first decryption algorithm Similarly there could be a pure AE algorithm which does destructive operations on the tag during computations and merely checks that the final answer was So like the associated data value since there could be algorithms which need it first it has to come first in a fully generalized API Floating them out into and have the problem that while the base class was algorithm independent the usage becomes algorithm dependent Changing AesGcm to AesCbcHmacSha or SomeTagDesctructiveAlgorithm would now result in TryDecrypt throwing because the tag was not yet provided To me that is worse than not being polymorphic at all so allowing the flexibility suggests breaking the model apart to be fully isolated per algorithm Yes it could be controlled by more algorithm identification characteristic properties like but that really just leads to it being harder to use Also for encrypt Initialize needs the IV before any crypto transforms Lastly for encrypt and decrypt Initialize needs the AES encryption keys before any transforms The key was a class ctor parameter The IV nonce comes from the IV nonce provider in the ctor parameter The provider model solves SIV where no IV is given during encrypt one is generated on behalf of the data Otherwise SIV has the parameter and requires that an empty value be provided or you forgot to type that bit The streaming methods were being added to my existing proposal which already had the key and IV nonce provider as ctor parameters Good point that some algos could want tag first while others at the end and thanks for the reminder that it s an addition to the original spec I found that considering a use case makes it easier so here is a cloud first example We re going to perform analytics on one or more GB AES GCM encrypted files i e tags after ciphertext kept in storage An analytics worker concurrently decrypts multiple inbound streams into separate machine clusters and after last byte tag checks starts off each analysis workload All storage worker analytics VMs are in Azure US West Here there is no way to fetch the tag at the end of every stream and provide it to AuthenticatedDecryptor s method So even if a user volunteers to modify code for GCM usage they can t even begin to use the API Come to think of it the only way we could have an API that accommodates various AEADs AND have no user code changes is if the crypto providers for different AEAD algorithms auto magically handle the tags Java does this by putting the tags at the end of ciphertext for GCM and plucks it out during decrypting without user intervention Other than that anytime someone changes the algorithm significantly e g CBC HMAC GCM they will have to modify their code because of the mutually exclusive nature of tag first and tag last processing IMHO we should first decide if Option The algorithm providers internally handle tag management like Java or Option Expose enough on the API for users to do it themselves like WinNT bcrypt or openssl Option would really simplify the overall experience for library consumers because buffer management can get complex Solve it well in the library and each user won t have to solve it everytime now Plus all AEADs get the same interface tag first tag last tag less and swapping out algorithms is simpler too My vote would be for option Finally we were able to dig up our implementation allowing streaming operations over GCM to automatically pluck out the tag in stream This was a significant update to CLR Security s own wrapper and despite the additional buffer copies it s still really fast GB sec on our test macbook pro in Windows bootcamp We basically wrapped around CLR Security to create option for ourselves so we don t need to do it everywhere else This really helps explain what s going on within the and of the interface I m not sure why your cloud first example is blocked If you re reading from storage you can download the last few tag bytes first and provide that to the decryptor ctor If using the Azure Storage APIs this would be accomplished via Not to get too sidetracked on that example but that s a specific capability of Azure Blob Storage In general VM based storage IaaS or non Azure Storage workloads typically get a network stream that s not seekable I personally am very excited to see yay We re going to perform analytics on one or more GB AES GCM encrypted files i e tags after ciphertext kept in storage An analytics worker concurrently decrypts multiple inbound streams into separate machine clusters and after last byte tag checks starts off each analysis workload All storage worker analytics VMs are in Azure US West you were so adamant about keeping dumb n dangerous primitives and smart n huggable protocols separate I had a dream and I believed it And then you throw this at us This is a protocol a system design Whoever designed that protocol you described messed up There is no point crying over inability to fit a square peg into a round hole now Whoever GCM encrypted Gb files is not only living dangerously close to the primitive edge GCM is no good after Gb but there was also an implicit assertion that the whole ciphertext will need to be buffered Whoever GCM encrypts Gb files is making a protocol mistake with overwhelming probability The solution chunked encryption TLS has variable length k limited chunking and there are other simpler PKI free flavors The cloud first sex appeal of this hypothetical example does not diminish the design mistakes I have a lot of catching up to do on this thread raised a point about reusing the interface from the Data Protection layer To be honest I don t think that s the right abstraction for a primitive as the Data Protection layer is quite opinionated in how it performs cryptography For instance it forbids self selection of an IV or nonce it mandates that a conforming implementation understand the concept of AAD and it produces a result that s somewhat proprietary In the case of AES GCM the return value from is the concatenation of a weird almost nonce thing used for subkey derivation the ciphertext resulting from running AES GCM over the provided plaintext but not the AAD and the AES GCM tag So while each step involved in generating the protected payload is secure the payload itself doesn t follow any type of accepted convention and you re not going to find anybody aside from the Data Protection library that can successfully decrypt the resulting ciphertext That makes it a good candidate for an app developer facing library but a horrible candidate for an interface to be implemented by primitives I should also say that I don t see considerable value in having a One True Interface tm that all authenticated encryption algorithms are supposed to implement These primitives are complex unlike simple block cipher primitives or hashing primitives ,,,,,
,,,,,
here are simply too many variables in these complex primitives Is the primitive AE only or is it AEAD Does the algorithm accept an IV nonce at all I ve seen some that don t Are there any concerns with how the input IV nonce or data must be structured IMO the complex primitives should simply be standalone APIs and higher level libraries would bake in support for the specific complex primitives they care about Then the higher level library exposes whatever uniform API it believes is appropriate for its scenarios We re going off topic again I ll just say that a system is built using primitives The crypto primitives here are bare and powerful While the system protocol layer handled buffering that too at a cluster level certainly not in main system memory that the one shot primitives would force chunking boundary is X X GB here because GB because buffering capacity of the cluster was nearly limitless and nothing would could start until last byte is loaded in the cluster This is exactly the separation of concerns optimizing each layer for it s strengths that I ve been talking about And this can only happen if the underlying primitives don t handicap higher layer designs limitations note that more real world apps come with their own legacy handicaps NIST d sec states In order to inhibit an unauthorized party from controlling or influencing the generation of IVs GCM shall be implemented only within a cryptographic module that meets the requirements of FIPS Pub In particular the cryptographic boundary of the module shall contain a generation unit that produces IVs according to one of the constructions in Sec above The documentation of the module for its validation against the requirements of FIPS shall describe how the module complies with the uniqueness requirement on IVs That implies to me that GCM IVs must be auto generated internally and not passed in externally Good point but if you read even closer you ll see that for IV lengths of bits and above section allows for generating an IV with a random bit generator RBG where at least bits are random you could just other bits I did mention this last month on this thread itself under nonce LT DR is a trap leading to non compliance with NIST and FIPS guidelines Section simply says for FIPS the IV generation unit fully random i e sec or deterministic implementation i e sec must lie within the module boundary undergoing FIPS validated Since RBGs are already FIPS validated IV lens is recommended designing an IV generation unit that persist reboots indefinite loss of power into a crypto primitive layer is hard getting above implemented within the crypto library AND getting it certified is hard and expensive K for anything resulting in a non bit exact build image No user code will ever implement and get it certified because of above lets leave aside some exotic military govt installations most crypto libraries see Oracle s Java WinNT s bcryptprimitives OpenSSL etc undergoing FIPS certification use the RBG route for IV and simply take a byte array for input Note that having the interface is actually a trap from NIST and FIPS perspective because it implicitly suggests that a user should pass an implementation of that interface to the crypto function But any user implementation of is almost guaranteed to have NOT undergone the month and K NIST certification process Yet if they had just sent a byte array using the RGB construct already in the crypto library they would be fully compliant with the guidelines I ve said before these existing crypto libraries have evolved their API surface and have been battle tested across multiple scenarios More that what we ve touched upon in this long thread My vote again is to leverage that knowledge and experience across all those libraries all those validations and all those installations rather than attempting to reinvent the wheel Don t reinvent the wheel Use it to invent the rocket Hi folks Any updates on this Haven t seen any updates at s crypto roadmap or on the AES GCM Thanks Sid So the last concrete proposal is from a few potential issues have been raised since The tag is required upfront which hinders certain scenarios Either the API must become significantly more complex to allow further flexibility or this issue must be considered a protocol i e high level problem might be needlessly complex and or lead to non compliance with NIST and FIPS guidelines The intended abstraction of authenticated encryption primitives might be a pipe dream as differences might be too great There has not been any further discussion of this suggestion I d like to suggest the following The additional complexity of not requiring the tag upfront seems severe the corresponding problem scenario seems uncommon and the problem does indeed sound very much like a matter of protocol Good design can accommodate much but not everything Personally I feel comfortable leaving this to the protocol Strong counterexamples welcome The discussion has consistently moved towards a flexible low level implementation that does not protect against misuse with the exception of IV generation Let s be consistent The general consensus seems to be that a high level API is an important next step vital for proper use by the majority of developers this is how we get away with not protecting against misuse in the low level API But it seems that an extra dose of fear has sustained the idea of misuse prevention in the area of IV generation In the context of a low level API and to be consistent I d lean towards a equivalent But implementation swapping is more seamless with the injected Is comment irrefutable or could a simple implentation that merely calls the RNG still be considered compliant The abstractions seem useful and so much effort has been put into designing them that by now I am convinced they will do more good than harm Besides high level APIs can still choose to implement low level APIs that do not conform to the low level abstractions IV is the general term and a nonce is a specific kind of IV correct This begs for renames from to and from to After all we are always dealing with an IV but not necessarily with a nonce The tag upfront is a non starter for my scenario so I will probably just keep my own inplementation Which is fine I am not sure it s everyone s cup of tea to write high perf code in this area The problem is it will cause unneeded latency You have to pre buffer an entire message to get the tag at the end to start decoding the frame This means you basically can t overlap IO and decrypting I am not sure why it s so hard to allow it at the end But I am not going to out a road block for this API it just won t be of any interest in my scenario IV is the general term and a nonce is a specific kind of IV correct No A is a number used once An algorithm which specifies a nonce indicates that reuse violates the guarantees of the algorithm In the case of GCM using the same nonce with the same key and a different message can result in the compromise of the GHASH key reducing GCM to CTR From Nonce A value used in security protocols that is never repeated with the same key For example nonces used as challenges in challenge response authentication protocols generally must not be repeated until authentication keys are changed Otherwise there is a possibility of a replay attack Using a nonce as a challenge is a different requirement than a random challenge because a nonce is not necessarily unpredictable An IV doesn t have the same stringent requirements For example repeating an IV with CBC only leaks whether the encrypted message is the same as or different than than a previous one with the same IV It does not weaken the algorithm A nonce is a number used once An IV doesn t have the same stringent requirements Yes I would reason that since a nonce is used to initialize the crypto primitive it is its initialization vector It adheres perfectly to any definition of IV that I can find It has more stringent requirements yes just as being a cow has more stringent requirements than being an animal The current wording seems to ask for a cowOrAnimal parameter The fact that different modes have varying requirements of the IV does not change the fact that they are all asking for some form of IV If there s something I m missing by all means keep the current wording but as far as I can tell just iv or IIVProvider are both simple and correct To indulge in the bikeshedding The bit GCM IV is sometimes defined as a byte and byte ex RFC RFC defines GCM as a byte and byte RFC GCM in CMS says that CCM takes a GCM takes an but to have a common set of terms for AES CCM and AES GCM the AES GCM IV is referred to as a nonce in the remainder of this document RFC GCM for SSH says note in RFC the IV is called the nonce RFC GCM in IPSec says we refer to the AES GMAC IV input as a nonce in order to distinguish it from the IV fields in the packets RFC GCM for SRTP talks about a byte and almost maintains its consistency but then says minimum maximum nonce IV length MUST be octets Given the complete lack of consistency in most GCM specs kinda makes sense Tag upfront is a non starter Like other customers voicing themselves here requiring the tag upfront is a non starter for us too There is no way NET can then process concurrent streams with this artificially introduced limitation Totally kills scalability Can you back the assertion that it adds complexity Because it should actually be trivial Plus none of the platform specific crypto implementations that you ll be wrapping have this limitation Specifically the reason is that the input tag needs to be merely constant time compared against the computed tag And the computed tag is available only after the final block has been decrypted during So essentially when you start your implementation you ll find that you re merely storing the inside your instance until the You could very well have it as an optional input I also think we re trying too hard to normalize to a single interface that will cover all crypto scenarios I too prefer generalized interfaces but never at the expense of functionality or scalability especially at such a foundational layer like the standard cryto library of the language itself IMHO if one finds oneself doing so it usually means the abstraction is faulty If a simple consistent interface is needed I prefer the Java approach also raised previously here as option It also sidesteps the above issue of tag first tag last by keeping them within the algorithm implementations IMHO as I think it should My team isn t implementing this so it s not our decision BUT if we had to make a decision and start implementing we d go this route for sure Please avoid the interface a simple or should suffice for a compliant low level interface IV vs Nonce Generalized case is indeed IV For GCM the IV is required to be a Nonce e g Car vs RedOrCar And as I m copy pasting this I just noticed used a very similar example Can you make a precise proposal that both supports algorithms that need the tag upfront and only needs the tag as late as in all other situations I suppose you are thinking something in the following direction The tag in is allowed to be null Only those algorithsm that need it upfront will throw on null The tag in is required or alternatively is allowed to be null for those algorithms that have already required it upfront I suppose the above only adds complexity in the form of documentation and know how For a low level API this could be considered a small sacrifice since adequate documentation and know how are required anyway I am starting to become convinced that this should be possible for compatibility with other implementations and streaming Sure I hope to budget some time tomorrow for this I ended up having time just today and this turned out to be quite the rabbit hole Thisis long but I think it captures most use cases captures NET crypto s strengths while embracing the NET Core Standard direction I ve re read but hope there are no typos below I also think some realtime communications chat conf call etc is vital to speedy brainstorming I hope you can consider that Programming model I ll first talk about the resulting programming model for users of the API Streaming Encrypt Streaming Decrypt Non streaming Since non streaming is a special case of streaming we can wrap the above user code into helper methods on defined below to expose a simpler API i e This can double as presenting a simpler API like Non streaming encrypt Non streaming decrypt Under the hood Looking at the corefx source Span is everywhere This includes System Security Cryptography except for symmetric ciphers so lets fix that first and layer authenticated encryption on top Create for Span I O This is like a Span aware version of I d just change the interface itself as part of the framework upgrade but since people can get touchy about that I m calling it Also mark as To be polite to people with previous knowledge of NET crypto Extend existing class for Span I O Extend existing for Span I O This is just like in System Runtime Plus we ll add a c tor for our AEAD case to follow CRITICAL will need a mandatory upgrade in to add the tag to the end of the stream during encryption and automatically extract the tag TagSize bytes during decryption This is similar to other battle tested API s like Java s Cryptographic Architecture or C BouncyCastle This is unavoidable yet the best place to do this since in streaming the tag is produced at the end yet is not needed until the final block is transformed during decryption Upside is it vastly simplifies the programming model Note With CBC HMAC you can choose to verify the tag first It s the safer option but if so it actually makes it a two pass algorithm The st pass compute the HMAC tag then the nd pass actually does the decryption So the memory stream or network stream will always have to be buffered in memory reducing it to the one shot model not streaming True AEAD algorithms like GCM or CCM can stream efficiently TransformFinalBlockGetTagTagSizeSetExpectedTagTransformFinalBlock ICipherTransformCryptoStreamIAuthenticatedCipherTransformCryptoStreamSymmetricAlgorithm System Security Cryptography Aes SupportsStreaming out string whyNot SymmetricAlgorithmAuthenticatedEncryptionAlgorithmCreateEncryptorCreateDecryptorSymmetricAlgorithmAuthenticatedSymmetricAlgorithmAuthenticatedEncryptionAlgorithmTryEncryptTryDecryptTagkeyivauthenticatedAdditionalDataAesGcmivauthenticatedAdditionalDatakeyCreateAuthenticatorEncryptorAesGcmCreateAuthenticatedEncryptorTryEncryptICipherTransformCipherTransformauthenticatedDataauthenticatedAdditionalDataplaintextciphertextTryEncryptciphertextTryDecryptplaintextE c t E c tE t cReadOnlySequenceIGcmDecryptorCryptoStreamStreamReaderXmlReaderXmlReader So actually many of the dangers discussed apply to stream objects but not to block operation To work with block operation when a one shot API is also available suggests that we know what we are doing and that we specifically require low level tweaking We could protect the layman and have flexibility As for avoiding RUP I m still pondering how much of an advantage block operation truly is for GCM Encryption reaps the full benefits whereas decryption benefits only somewhat We can avoid storing the full ciphertext but we must still buffer the full plaintext A decryptor could choose to store the intermediate plaintext on disk But in return we have introduced more room for error Do we have a convincing argument to not solve this problem at a higher level e g chunk there or use a truly streaming algorithm TLS and pipelines Currently and for the foreseeable future pipelines uses k blocks but a tls message can be k of cipher text with a one shot you will need to copy the k to a single contingous buffer before you can decrypt With blocks you might have say or and you might need to buffer upto bytes to ensure compete blocks k is still constant and not huge Does it make much of a difference in this context Yes it means another copy in the pipeline This has a major and measurable effect on perf What is needed to make this happen What are the next steps As for AES GCM I think that its delivery is impaired due to the corresponding issue being locked could you unlock It is really hard to have progress when people can t discuss Or if that s not an option maybe propose an alternative solution that allows bringing this feature to the public Nope I m not unlocking that A decision has been made the topic is done Thanks for the reply I understand that maybe this was not clear enough Or if that s not an option maybe propose an alternative solution that allows bringing this feature to the public I appreciate that there is a decision for supporting AES GCM This is great I definitely want that algorithm Thus now it would be cool to actually have it supported Would you like the discussion on AES GCM design and implementation be held here or in a new issue Also if that topic is done why not close it And make it more explicit by changing the title of that issue as right now it suggests that the discussion on the implementation would be held here Maybe something like Decide which AEAD algorithm to support first In other words I provide feedback that in the current situation it is unclear what is needed to push AES GCM forward There s already a PR out It ll probably be available in master Wednesday next week,,,,,
452,issue,Proposal: Drop minsafe option and templates,Proposal Drop minsafe option and templates Since the project is built using ngmin in grunt does it make sense to still have min safe and minsafe templates They add complexity to the code and if removed would make maintaining and testing easier,thoughts From what I can remember they re there because ngmin was quite unstable Not sure if that still applies I would love to rip that out if no one has an objection Granted if people rely on minsafe because they created a project not using ngmin then the generator no longer will work for them But for those people updating to use ngmin could be a documentation update issue Really who wants to write all their code like name function name Ugh so ugly Let it be done in the background Even though ngmin has some edge cases it doesn t cover at the moment you can still manually work around them The branch complicates the code a lot and is a big maintenance burden that very few people actually benefit from as addicted user of generator angular I ask you to not make me type additional option each time I thought programming is also about automation of repeating actions so it would be un automation I m personally for removing it This would be getting rid of something that requires you to type additional stuff and automates it for you Deprecate in the next point release and remove in the one after that then Any opposed sgtm On Dec PM Eddie Monge notificationswrote This would be getting rid of something that requires you to type additional stuff and automates it for you Deprecate in the next point release and remove in the one after that then Any opposed Reply to this email directly or view it on clap,Unsure
68,pr,Add a fuzz test,Add a fuzz test This test tries to produce a million messages to a Kafka cluster that is simultaneously being screwed with by a separate thread that randomly kills of of the nodes waits seconds restarts the node waits another seconds and repeats Hopefully this will flush out hard to find bugs,,Unsure
28822,issue,saltenv url-parameter not working in file.managed for salt:// sources since 2015.8,saltenv url parameter not working in file managed for salt sources since Until this feature was working fine Since the source file is not found anymore When I use env instead of saltenv a DeprecationWarning is returned that I should use saltenv instead but the file is not found either,thanks for the report I can reproduce this I am experiencing the same issue and can trace it back to d e ba ec e baa cd cd where the function changed so that it would start calling which does not implement any type call to look at the saltenv query parameter I can see that you have added this functionality to the function so I ve added it to also but this means it would be called twice for a call It would be good to confirm if it needs to be added to all the other cp functions or if it should be moved out to the file module thanks for your research and work on this I changed all of the salt url handling in develop before Beryllium was forked and so only modified code that was already there If the env needs to be split out of the URL in then it should also be split in compare I am not very familiar with the workings of the module and the fileclient so I can t say anything about where else this may also need to be but the efficiency effects should be minor As your pull request was submitted against develop I added the backport label I have fixed the RemoteClient function in This issue has been automatically marked as stale because it has not had recent activity It will be closed if no further activity occurs Thank you for your contributions If this issue is closed prematurely please leave a comment and we will gladly reopen the issue,Unsure
5502,issue,Enable user namespaces in the Debian package,Enable user namespaces in the Debian package Lots of users are having problems e g installing Brave on Debian because of the extra step of enabling user namespaces Maybe we should do it for them by shipping a file containing kernel unprivileged userns clone and then doing a in the postinst script,Perhaps we should do this in to avoid having to patch the Chromium source Fixed in the package i e not tied to a particular release could that new package update have caused this just curious I cannot figure out how to fix this and am wondering if it s normal thanks Yes we had a problem with version of the package This should be fixed in though Try,Unsure
2367,pr,[ZEPPELIN-2584]. Livy doesn't work under kerberos and ssl,ZEPPELIN Livy doesn t work under kerberos and ssl What is this PR for We found that Livy doesn t work under kerberos and ssl this is due to a bug when constructing KerberosRestTemplate This PR fix this issue What type of PR is it Bug Fix Todos Task What is the Jira issue How should this be tested Unfornatelly it is difficult to add system test so I manually tested it in a secure cluster Screenshots if appropriate Questions Does the licenses files need update No Is there breaking changes for older versions No Does this needs documentation No,Mind to review this Thanks Generally looks good will test it out in one of my test clusters and update this thread Took me a while to configure and but looks good works on my local Thanks will merge it if no more discussion The failed test is not related,Unsure
861,pr,Update arc hash,Update arc hash Pulls in the,This is automatically updated every time I commit a PR shouldn t be needed Apologies had no idea wasn t documented,Unsure
3513,issue,IKEv2 Authentication credentials are unaccptable,IKEv Authentication credentials are unaccptable Hi I made for All certificate settings correctly But I have given IKE authentication credentials are unacceptable error message when i connect via always on vpn I have checked all Possible solution Verified that the server certificate includes Server Authentication under Enhanced Key Usage Verified that the server certificate is still valid Verified that the CA used is listed under Trusted Root Certification Authorities on the RRAS server Verified that the VPN client connects by using the FQDN of the VPN server as presented on the VPN server s certificate But i couldn t find solutions,,Yes
603,issue,这些功能很多没有开放，是hack出来的吗？,hack hack,itchat itchat,Unsure
55119,issue,ssh connection closed,ssh connection closed SUMMARY ISSUE TYPE Bug Report COMPONENT NAME ANSIBLE VERSION CONFIGURATION OS ENVIRONMENT STEPS TO REPRODUCE EXPECTED RESULTS ACTUAL RESULTS,It would be nice if you can add some details about the problem you are facing and reproducer Thanks needs info As stated above please create a new issue with details on how to reproduce the issue and complete output from running Ansible If you have further questions please stop by IRC or the mailing list IRC ansible on irc freenode net mailing list,Yes
13917,issue,Memory growth issue about crypto module.,Memory growth issue about crypto module Thank you for reporting an issue This issue tracker is for bugs and issues found within Node js core If you require more general support please file an issue on our help repo fill in as much of the template below as you re able Version output of Platform output of UNIX or version and or bit Windows Subsystem if known please specify affected core module name If possible please provide code that demonstrates the problem keeping it as simple and free of external dependencies as you are able Version v v Platform Linux el x SMP Tue Jun UTC x x x GNU Linux If I run cipher related function many times I can see memory growth even though execute gc manually To be more specific if I use cipher final it causes memory growth Below is test code,Define memory growth How and what do you measure I mean memory leak I just run that code and the result was like attached picture Okay but what is Memory used RSS JS heap something else It s not unexpected that the memory footprint grows over time because the garbage collector periodically resizes the heap As long as you don t get actual out of memory errors there probably is no memory leak I took memwatch result of heap diff and rss I executed times in a loop If this is not a memory leak why memory usage is growing My test approach was wrong Now we re getting somewhere So it s RSS that steadily grows while the JS heap only grows in fits At what interval did you record those samples Since you are on Linux can you check if your issue is In a nutshell disable transparent huge pages if they are enabled I recorded every executions I will check the link you mentioned Already turned off gentlejo cat sys kernel mm transparent hugepage enabled always madvise never RSS is only increasing when I called method If I don t call method RSS is not increasing Can I free or prevent RSS increasing Thanks I was able to reproduce I ll look into it Do we know if this is a regression and if so when it was introduced Not a regression AFAICT It s been present ever since authenticated mode support was added in commit e d ea from November,Yes
2024,issue,sandbox paths are too long,sandbox paths are too long from our jenkins build Caused by org h jdbc JdbcBatchUpdateException Value too long for column SITE PATH VARCHAR home jenkins cache bazel bazel jenkins d ecb efd ed f e c a f fde bazel sandbox d a a f d f a b ddab ad c SQL statement UPDATE system config SET would it be possible to compress the path components You could easily get shorter names without losing randomness by using base Also do you really bits of randomness Can t you just use a bit incremented counter,is this still under investigation It s probably easy to fix just replace the UUID with something like mdktemp We don t need the randomness we just need a unique directory That could indeed be made much shorter Will put it on my list of things to fix This was fixed some months ago by replacing the UUID with a counter,Yes
463,issue,Firstpass projects and unsafe code,Firstpass projects and unsafe code Hi all Why unsafe from rsp files does not applied to firstpass projects In CsprojAssetPostprocessor cs exists two functions IsPlayerProjectFile and IsEditorProjectFile but they do not know nothing about firstpass projects,Can i help you with something No thanks I have already consulted with Unity team You are right it should affect all projects Will be fixed shortly Do I understand correctly smcs rsp and gmcs rsp Don t work for firstpass projects I made a fix it will be merged during this week I expect it will be public in a nightly build also this week Nightly builds are available via JetBrains toolbox I saw your fix But in that fix smcs rsp and gmcs rsp affect only on Editor and Player projects mcs rsp affect on all projects Is it correct behaviour Why smcs rsp and gmcs rsp don t apply settings to firstpass projects I thought you are using mcs rsp It appeared to me that smcs and gmcs are for Unity prior to What version do you use I use Unity and msc rsp But i think it s inconsistent behaviour If this is not a problem then I m satisfied with the fix I used gmsc and smsc early We got that gmcs smcs logic from I don t want to change it unless someone really requests it Fix must be in the nightly build,Yes
9545,issue,Add test for multibyte characters encode on URL bar,Add test for multibyte characters encode on URL bar Describe the issue you encountered Add a webdriver test for multibyte characters encode on URL bar Paste to URL bar and go The URL should be encoded,,Yes
6789,pr,remove overwritten keys from hashes,remove overwritten keys from hashes This fixes I chose to delete the overwritten hash values rather than merge since it was clear that the overwritten values were never tested since they had no effect Verification x Visual code inspection the fixes are fairly obvious On an up to date Kali rolling VM verify that msfconsole does not throw warnings with the system ruby when running a fresh metasploit framework checkout with this PR OR x You can also simulate Kali s environment with RVM by updating to ruby by modifying ruby version reentering the directory following rvm s instructions then bundling the gems again,,Yes
2036,issue,Detox Running on IOs wants to login once on the application  per each execution,Detox Running on IOs wants to login once on the application per each execution HI I m working in an application which has a login at the beginning for that I need a particular code retrieved from the backend I need to ask for it only once for each execution so I need to go to login only time and then send to background the application and get it from there to run the rest of the scenarios I was trying to fix the spec for login to run it first I know is NOT a good practice there is any way in which I can do that As a plan B I was going to check on the before all on each spec to login or not not nice either but is an option My main question is the next one having that in mind I sent it to the background each time a spec finish and getting from background each time spec starts but I noticed that between each spec execution the app start fresh I m guessing somehow the login information is clear from cache or something like that Can you help me with the setup for it On the init I have the following and on the specs I m doing this As far as I know is better to used reloadReatNative instead of launchApp Here the purpose is to refresh before run each test on this spec,We use the issue tracker exclusively for bug reports and feature requests This issue appears to be a general usage or support question Instead please ask a question on Stack Overflow with the tag Feel free to post your Stack Overflow question here for more visibility We ll take a look at it For issues with Expo apps it is most likely not an issue with Detox itself but with the Expo runtime or with incorrect Detox setup For support on how to use Detox with Expo you should contact the Expo team or the Expo community For more information on bots in this repository read this,Yes
615,issue,Question: Is Protobuf thread safe when serializing and deserializing Lists?,Question Is Protobuf thread safe when serializing and deserializing Lists Is Protobuf Thread safe when Serializing and Deserializing IDictionary and IList,That s an impossible question to answer since it really isn t up to the serializer it is up to the list dictionary whatever and I can t tell anything about the concrete implementation if it is an interface Gowever As a general rule no This however is not specific to serialization If you ask in the general case whether something is thread safe then the only safe answer is no If you can discuss the specific collections and competing operations then there may be cases when the answer is yes For example to take the trivial case it you are serializing an ImmutableList T the answer is going to be yes Can you be more specific What is the actual scenario here Dictionary and List to be specific Those types are not thread safe So if you have other threads mutating them expect pain But that isn t the serializer that s the types themselves Usually when deseriazing nothing else is touching the same objects So it isn t an issue Is there a specific threading scenario you re cautious of here Having Serialization on a seperate thread from where the objects are potentially being changed Specific use case is here I m not going to try and read all of that to infer the threading model Fundamentally you re on very rocky ground doing anything concurrently on most types without strong inbuilt concurrency guarantees List and Dictionary do not provide strong concurrency guarantees So again my default here is this could bite you But it isn t really anything to do with the serialization library there s nothing it can do to impact things here since it doesn t control the types you give it,Yes
15199,pr,bpo-37807: Make hash() return a non-negative number.,bpo Make hash return a non negative number ,Please could you also update the documentation for the numeric hash The old docs are no longer true with this change I do not know what words to use for documenting the changes in the algorithm I have added a comment so now can be edited via browser could you please help with documentation But I am not sure that this change should be done I do not know what code will need returning a non negative number I withdrew this suggestion due to the suggestion that the implementation details became guaranteed,Unsure
6271,issue,The use of the transport key,The use of the transport key I just want to ask when and how the transport key is being used It is also missing the key exchange of the transport key and the device key Document Details Do not edit this section It is required for docs microsoft com GitHub issue linking ID db a cc f dc e Version Independent ID a af c fff f Content How Windows Hello for Business works Device Registration Microsoft Content Source Product w Technology windows GitHub Login Microsoft Alias mapalko,Device Registration is a prerequisite for Windows Hello for Business but it is a separate topic from WHFB itself For more information on device registration you should refer to the device registration docs Hello The issue is being closed since your question seems to be answered Feel free to re open this issue if you feel that it hasn t been answered or that there are further suggestions to improve the documentation itself Thanks,Yes
2450,pr,Fixes #10785 - force encoding for encrypted fields,Fixes force encoding for encrypted fields Some info in the ticket error only appears on sqlite,Any test to reproduce it our unit tests actually cover this already you can grep about warnings in our logs during the test run Pushed the issue is in the PasswordEnrypt perhaps it returns this US ASCII that causes these warnings The unit tests could check the encoding of the resulting root pass though Oh yeah sure Done Tests are failing Okay good points amended the change Please check the test failures on Ruby Merged as e f thanks,Yes
3930,issue,How do I set the login expiration time?,How do I set the login expiration time How do I set the login expiration time,Once a user logs in a Session object is created containing a createdAt and expiresAt parameter The expiration time defaults to year from creation and I m not sure if you can change that somewhere What you could try Fetching the Session object and overwriting the expiresAt time Creating a Cron job that would delete old Sessions every day Can I change the default expiration time B QQ Original From Martin Herman Date Wed Jun PM To parse community parse server Cc lxq Author Subject Re parse community parse server How do I set the login expirationtime Once a user logs in a Session object is created containing a createdAt and expiresAt parameter The expiration time defaults to year from creation and I m not sure if you can change that somewhere What you could try Fetching the Session object and overwriting the expiresAt time Creating a Cron job that would delete old Sessions every day You are receiving this because you authored the thread Reply to this email directly view it on GitHub or mute the thread This is controlled with the config property if mounting parse as express middleware or with the environment variable This issue has been automatically marked as stale because it has not had recent activity It will be closed if no further activity occurs Thank you for your contributions,Yes
33043,pr,begin moving salt over to using openstack-infra/shade for openstack libraries,begin moving salt over to using openstack infra shade for openstack libraries What does this PR do Moves keystone module nova cloud driver and swift over to using shade for their library Tests written No,ugh lint Some lint errors here I found something really broken in this,Yes
477,issue,Error: ../deps/openssl/openssl/ssl/s3_pkt.c:1293:SSL alert number 48,Error deps openssl openssl ssl s pkt c SSL alert number To get the title error message Reproduction Steps create a secure websocket from server with pem generated certificates and no crt connect with chrome when you see The site s security certificate is not trusted click Proceed anyway connect with firefox note that as soon as firefox displays the This Connection is Untrusted chrome instance s websockets is are instantly disconnected myWebSocket on error shows nothing but myWebSocket socket on error displays the following error message Error error SSL routines SSL READ BYTES tlsv alert unknown ca deps openssl openssl ssl s pkt c SSL alert number Note this does not happen the other way around ie with chrome booting firefox instances from the server Most likely something about firefox client certificates when the server has no crt on are causing openssl to choke This does not happen with and insecure websockets Final notes I suspect this is likely a bug in node not ws but I figure only your team is qualified to pass this bug on to the node team after verifying this isn t a problem in ws js It was also an annoyance that initially no error message was generated from wsjs when the websockets were inexplicably disconnected In was only listening to the base socket in the websocket that displayed this error While most low level errors are perhaps more than your library should pass through to the user perhaps lower level errors that cause disconnects should be passed through Node Version console log All System Versions JSON stringify process versions null t node v uv zlib modules openssl l Related package json versions ws pem OS version cat etc release DISTRIB ID Ubuntu DISTRIB RELEASE DISTRIB CODENAME precise DISTRIB DESCRIPTION Ubuntu LTS NAME Ubuntu VERSION LTS Precise Pangolin ID ubuntu ID LIKE debian PRETTY NAME Ubuntu precise LTS VERSION ID OpenSSL version dpkg s openSSL Package openssl Status install ok installed Priority optional Section utils Installed Size Maintainer Ubuntu Developers ubuntu devel discussArchitecture amd Version ubuntu Depends libc libssl Suggests ca certificates Conffiles etc ssl openssl cnf ce ab bf c a e e Description Secure Socket Layer SSL binary and related cryptographic tools This package contains the openssl binary and related tools It is part of the OpenSSL implementation of SSL You need it to perform certain cryptographic actions like Creation of RSA DH and DSA key parameters Creation of X certificates CSRs and CRLs Calculation of message digests Encryption and decryption with ciphers SSL TLS client and server tests Handling of S MIME signed or encrypted mail Original Maintainer Debian OpenSSL Team pkg openssl devel,One addition I forgot to mention the disconnect code from the websocket when this happens is ie CLOSE NORMAL However as the report indicates this is certainly not a normal close Call stack for reference ERROR T Z Error error SSL routines SSL READ BYTES tlsv alert unknown ca deps openssl openssl ssl s pkt c SSL alert number at TLSSocket onError home jeremy Projects EmpathicCivGameEngine engine private scripts NetworkServer js at TLSSocket emit events js at TLSSocket tlsError tls wrap js at TLSWrap ssl onerror tls wrap js I can confirm that I was able to reproduce the issue on Arch Linux with node v Well indirectly I had a user of my socket io powered software complain about this error message investigated and was able to use a similar setup to what you described to reproduce it The real kicker here is that it seems to reset the entire HTTPS server kicking any clients that were connected before Actually it appears to just kill a random other socket I m also inclined to believe this is an issue with node I was able to reproduce it even when forcing socket io to use long polling rather than websockets and I was NOT able to reproduce it with node v I was trying to come up with a minimal test case but had trouble coming up with an example using This looks more like a bug in node core than a bug in ws as none of the stack traces point or originate from ws Also it s is known that there issues when using self signed certificates in combination with websockets safari also has it s fair share of issues with it And it makes sense for the browsers to kill the connection from a security point of view I agree it makes sense for Firefox to abort the connection What does not make sense is killing the connection of a random other client on the server It s worth noting this does not only happen with self signed certificates when the problem was reported to me it was caused by someone who for some reason didn t have a particular CA in their Firefox trust store These things said I think it is likely an issue with node core and we should bring the discussion over to that project Calvin On Apr at Arnout Kazemier notificationswrote This looks more like a bug in node core than a bug in ws as none of the stack traces point or originate from ws Also it s is known that there issues when using self signed certificates in combination with websockets safari also has it s fair share of issues with it And it makes sense for the browsers to kill the connection from a security point of view Reply to this email directly or view it on GitHub There seems to be more movement on this in iojs io js issues iojs is as most of you will probably know a fork of nodejs and some changes fixes are ported from one to another,Yes
3128,issue,[Packager] Resolve assets based on platform.,Packager Resolve assets based on platform So i have image named on ios and android While loading the image on ios it is picked up the same image from android which is having a different height width than what i expect on ios I just added a console log from Bundler and the path seems to be of android packager asset true isStatic true path Users chirag Desktop lrn lrn android app src main res drawable hdpi js l icon png uri js l icon width height deprecated true cc going by commits in bundler index js,I think this should to be fixed when we ship the new asset system FYI I m using the master branch Any ETA for the new asset system to land on master No ETA yet but it s being worked on Haha can t believe i really asked for an ETA here I guess i just wanted to ask casually Thanks for the reply I will wait for it closing this one in favor of the new asset system,Unsure
1105,pr,Changed protected->public for getJSMainModuleName,Changed protected public for getJSMainModuleName Fixes errors when implementing on android because getJSMainModuleName is now public,Nevermind this is true with but not original react native,Unsure
13154,pr,Check whitelisted paths #13107,Check whitelisted paths Description A follow up on which forced the path to EXIST as well Path resolve strict False does not require the path to exist it will resolve as far as possible The oiginal code has Path parent resolve strict True so have to enure the parent exists and not just as far as possibe Related issue if applicable fixes Checklist x The code change is tested and works locally x Local tests pass with Your PR cannot be merged unless tests pass If the code does not interact with devices x Tests have been added to verify that the new code works ex requir,That work not with Python A real fix if to check if the path exists and if not it use the parent for validate like before,Yes
263,issue,"is it can batch open ssh like iterm2's ""open all profiles""  ",is it can batch open ssh like iterm s open all profiles or can add this feature,,Yes
71,issue,Add RenameFields setting to control how fields are obfuscated,Add RenameFields setting to control how fields are obfuscated As titled,Closed via,Unsure
3993,issue,mitmweb event log doesn’t show messages at level higher than info,mitmweb event log doesn t show messages at level higher than info Problem Description I ve seen the but I still have this problem I think you haven t solve it Steps to reproduce the behavior The steps to reproduce the behavior is the same as System Information Mitmproxy Python OpenSSL OpenSSL j Nov Platform Linux generic x with Ubuntu bionic,,Yes
50,issue,:message ignored by validates_date,message ignored by validates date Specifying a message for example The error message will still display the message in the locales translation file or complain about a missing translation This is using the mongoid ODM I do not know if ActiveRecord has the same problem,Having found the specs that cover this areas I see that we need special keys In this case after message Not sure how I managed to miss that in the readme,Unsure
2833,issue,Support Extractor injection for HLS chunks,Support Extractor injection for HLS chunks Issue description When using Demo player in ExoPlayer version to playback the HLS stream the player is stuck in loading mode after getting track information and not switching any further The same stream opens fine with Demo player in ExoPlayer version with all default settings Seems like the issue arises when there is a subtitle track inside HLS s TS chunk in this case CEA whereas the similar stream without subtitle track opens fine Are there any possible modifications in the code that could lead to this problem in the latest version Reproduction steps Try to open the stream in Demo player in ExoPlayer version Link to test content Link sent to dev e mail Version of ExoPlayer being used ExoPlayer Device s and version s of Android being used Nexus Player Nexus X A full bug report captured from the device,When the stream is saved as TS it is plays normally I also tried to disable the subtitle track but it didn t help Below is the extracted m u content found that it can be fixed by setting inside HlsMediaChunk java in createExtractor Is it possible to set this flag for HlsMediaSource or any media source or global non idr keyframe value for H reader the same way as for ExtractorMediaSource so the modification of library can be avoided in the future Not right now I ll use this issue to track Extractor factory injection Already tracked by,Unsure
152,pr,Resolve 2.4.0 warnings in safe backwards compatible way,Resolve warnings in safe backwards compatible way Like tom lord I wanted to resolve Ruby warnings This method is more backwards compatible and uses detection to figure out which class or should be extended,I m really happy you submitted this On Thursday I m running a class where merging this will help me illustrate the concept of continuous delivery I ll be merging this Thursday merging a few more of these Saturday and hopefully issuing the new version immediately after,Yes
11,pr,remove disruptive characters from email addresses and usernames,remove disruptive characters from email addresses and usernames Prevented emails and userNames from including generally unacceptable characters such as apostrophes which occur semi regularly when Faker generates last names such as o hara,Bump Fixed with a f c c b b f df Thank you for your contribution,Yes
31328,pr,Adding documentation for salt-ssh agent forwarding support,Adding documentation for salt ssh agent forwarding support I am the original author of the feature and it was pointed out that the feature lacked documentation So I have created this pull request to resolve issue,,Yes
7060,issue,SIMD Scalar move instruction should encoded VEX.L = 0 instead of VEX.L = 1,SIMD Scalar move instruction should encoded VEX L instead of VEX L Currently in RyuJIT genSIMDScalarMove when it s on an AVX system and useAVX is enabled SIMD scalar move instructions such as such as vmovlpd vmovlps vmovhps vmovhps and vmovss are been encoded as VEX L to be however JIT should ensure VEX L is for those SIMD Scalar move instructions For example following instruction vmovss xmm xmm xmm Currently it is encoded as C E E E This instruction is encoded as byte VEX form VEX L is bit on Byte For E as binary format VEX L bit The correct encoding should be C E A E because For A as binary format VEX L bit JIT should ensure VEX L here because encoding VMOVSS with VEX L may encounter unpredictable behavior across different processor generations,,Unsure
3876,issue,exception of page_transport_timeout,exception of page transport timeout how to pass the exception of page transport timeout PAGE TRANSPORT TIMEOUT Encountered too many errors talking to a worker node The node may have crashed or be under load The scene is two hard SQL one is two tables MM left join MM results MM have left join one is count number MM,is there any parameter can avoid this problem by the way node one is set to coodinator three is set to work nodes hi i m going to climb around this ticket too running version i m getting the same error ultimately returned back to the client I can t duplicate using TPCH data unfortunately but it is a pretty big query with a join i dug around in the server logs and found this code java lang NullPointerException maxSize is null at java util Objects requireNonNull Objects java at com facebook presto execution SqlTaskManager getTaskResults SqlTaskManager java at com facebook presto server TaskResource getResults TaskResource java at sun reflect GeneratedMethodAccessor invoke Unknown Source at sun reflect DelegatingMethodAccessorImpl invoke DelegatingMethodAccessorImpl java at java lang reflect Method invoke Method java at org glassfish jersey server model internal ResourceMethodInvocationHandlerFactory invoke ResourceMethodInvocationHandlerFactory java at org glassfish jersey server model internal AbstractJavaResourceMethodDispatcher run AbstractJavaResourceMethodDispatcher java at org glassfish jersey server model internal AbstractJavaResourceMethodDispatcher invoke AbstractJavaResourceMethodDispatcher java at org glassfish jersey server model internal JavaResourceMethodDispatcherProvider VoidOutInvoker doDispatch JavaResourceMethodDispatcherProvider java at org glassfish jersey server model internal AbstractJavaResourceMethodDispatcher dispatch AbstractJavaResourceMethodDispatcher java at org glassfish jersey server model ResourceMethodInvoker invoke ResourceMethodInvoker java at org glassfish jersey server model ResourceMethodInvoker apply ResourceMethodInvoker java at org glassfish jersey server model ResourceMethodInvoker apply ResourceMethodInvoker java at org glassfish jersey server ServerRuntime run ServerRuntime java at org glassfish jersey internal Errors call Errors java at org glassfish jersey internal Errors call Errors java at org glassfish jersey internal Errors process Errors java at org glassfish jersey internal Errors process Errors java at org glassfish jersey internal Errors process Errors java at org glassfish jersey process internal RequestScope runInScope RequestScope java at org glassfish jersey server ServerRuntime process ServerRuntime java at org glassfish jersey server ApplicationHandler handle ApplicationHandler java at org glassfish jersey servlet WebComponent service WebComponent java at org glassfish jersey servlet ServletContainer service ServletContainer java at org glassfish jersey servlet ServletContainer service ServletContainer java at org glassfish jersey servlet ServletContainer service ServletContainer java at org eclipse jetty servlet ServletHolder handle ServletHolder java at org eclipse jetty servlet ServletHandler CachedChain doFilter ServletHandler java at org eclipse jetty servlets UserAgentFilter doFilter UserAgentFilter java at org eclipse jetty servlets GzipFilter doFilter GzipFilter java at org eclipse jetty servlet ServletHandler CachedChain doFilter ServletHandler java at at org eclipse jetty servlet ServletHandler CachedChain doFilter ServletHandler java at at org eclipse jetty servlet ServletHandler CachedChain doFilter ServletHandler java at org eclipse jetty servlet ServletHandler doHandle ServletHandler java at org eclipse jetty server handler ContextHandler doHandle ContextHandler java at org eclipse jetty servlet ServletHandler doScope ServletHandler java at org eclipse jetty server handler ContextHandler doScope ContextHandler java at org eclipse jetty server handler ScopedHandler handle ScopedHandler java at org eclipse jetty server handler HandlerCollection handle HandlerCollection java at org eclipse jetty server handler HandlerWrapper handle HandlerWrapper java at org eclipse jetty server handler StatisticsHandler handle StatisticsHandler java at org eclipse jetty server handler HandlerList handle HandlerList java at org eclipse jetty server handler HandlerWrapper handle HandlerWrapper java at org eclipse jetty server Server handle Server java at org eclipse jetty server HttpChannel handle HttpChannel java at org eclipse jetty server HttpConnection onFillable HttpConnection java at org eclipse jetty io AbstractConnection run AbstractConnection java at org eclipse jetty util thread QueuedThreadPool runJob QueuedThreadPool java at org eclipse jetty util thread QueuedThreadPool run QueuedThreadPool java at java lang Thread run Thread java code lemme know if there s anything else i can supply thanks Stephen Assuming your machines didn t actually crash there are two main causes of this long GC pauses and network saturation Both of these can sometimes be fixed by tweaking the query Use to see the join order and exchanges and make sure you are building hash tables out of the smaller table The first is you are getting very long full GCs you can see this by enabling GC logging on the workers If you are getting log GCs sometimes you can tweak the JVM settings to help things but if you need more memory then you have you will need to add more memory or machines When it comes to network saturation there isn t much that can be done I suggest you run on gig networks I ve never seen that error before It implies that the client did not send a well formed request it was missing a required header If true you should be seeing this everywhere thanks i think i m going to try to enable GC logging as well as the error returned to my client is the same page transport timeout however digging deeper into the server logs i was able to find a uri and follow it and its that that reported the NPE on maxsize is null maybe that s just a symptom though but figured it be worth bringing to your attention Sun Nov error executing query Encountered too many errors talking to a worker node The node may have crashed or be under too much load This is probably a transient issue so please retry your query in a few minutes requests failed for s clicking on that uri yields java lang NullPointerException maxSize is null at java util Objects requireNonNull Objects java at com facebook presto execution SqlTaskManager getTaskResults SqlTaskManager java at com facebook presto server TaskResource getResults TaskResource java at sun reflect GeneratedMethodAccessor invoke Unknown Source at sun reflect DelegatingMethodAccessorImpl invoke DelegatingMethodAccessorImpl java at java lang reflect Method invoke Method java the other interesting thing is v does not exhibit this error while v and do which leads me to believe something in the presto server code is at play here and not GC or environment Also given clark has something very very similar i m guessing there s something going on inside the presto code maybe between the two of us we can help narrow it down By follow do you mean load that URI in your browser That probably won t work and would explain the NPE because your browser won t include the necessary HTTP header ahhhh that is correct okay that explains that so back to the original page transport timeout investigation i ll work at logging GC and see what that shows out of curiosity would there be any timeout heartbeat config setting on the presto side to control the server s behavior under these circumstances or is it entirely up to the JVM Judging from Dain s response above seems like the latter eh EDIT this test was done with broadcast join Same error here with PAGE TRANSPORT TIMEOUT error on worker node by the time problematic SQL running here s the gc log g gc app presto var log grep pause presto gc log GC pause Metadata GC Threshold young initial mark secs GC pause Metadata GC Threshold young initial mark secs GC pause Metadata GC Threshold young initial mark secs GC pause G Evacuation Pause young secs GC pause G Evacuation Pause young secs GC pause G Evacuation Pause young secs GC pause G Evacuation Pause young secs GC pause G Evacuation Pause young secs GC pause G Evacuation Pause young secs GC pause G Evacuation Pause young secs GC pause G Evacuation Pause young secs GC pause G Evacuation Pause young secs GC pause G Evacuation Pause young secs GC pause G Evacuation Pause young secs GC pause G Evacuation Pause young secs GC pause G Evacuation Pause young secs it seems that long GC is not the issue here I m running on coordinator worker each node with MB ram core w hyperthreading I tried with CMS GC before trying G GC global pause was long enough to think that GC is causing this But switching to G GC shows that this issue might not be closely related to GC problem here s my configuration config properties query max memory GB query max memory per node GB jvm config Xmx G Xms G XX UseNUMA XX UseG GC XX AggressiveOpts XX ReservedCodeCacheSize M XX PermSize M XX MaxPermSize M XX HeapDumpOnOutOfMemoryError XX OnOutOfMemoryError kill p XX PrintGCDetails XX PrintGCTimeStamps verbose gc Xloggc app presto var log presto gc log problematic query was a union all of many following subqueries union or so select TA c TB b count distinct TA a from select a b count distinct c from bigtable where part date between blahblah group b TA left outer join select a b from smalltable where blahblah TB on TA a TB a group by TA c TB b thanks for this good to get another data point on this seemingly mysterious error Anything in your traceback that looks like a smoking gun did this query work in a previous version of presto both and sometimes produce this error in my case as the error message says this error is transient today i was able to reproduce this error again g gc hash join servers were under modest load before issuing a problematic presto query coordinator log is flooded with following two exceptions with many different task ids ContinuousTaskInfoFetcher h z com facebook presto server HttpRemoteTask Error getting info for task h z java util concurrent TimeoutException com facebook presto server HttpRemoteTask Error updating task h z java util concurrent TimeoutException s log file is flooded with following exception just showing that the TCP connection was org glassfish jersey server ServerRuntime Responder An I O error has occurred while writing a response message entity to the container output stream org glassfish jersey server internal process MappableException org eclipse jetty io EofException at org glassfish jersey server internal MappableExceptionWrapperInterceptor aroundWriteTo MappableExceptionWrapperInterceptor java by that time cpu usage was just percent network usage was about MB s G NIC so here s my interpretation of this situation the task info api on worker node is not responding within seconds time out exception coordinator cancels request worker node s pending request handler is canceled and this goes on for seconds for one or more task id boom a query failed to run with com facebook presto operator PageTransportTimeoutException and here s the question why task info api is not responding within second maybe a synchronization mechanism is blocking the api to read and send the relevant info and why this can go on for full minute maybe the task is running over minute I m just a new guy trying to evaluate presto haven t read any source code yet so please forgive my wild guess smile again g gc was not the issue this time GC pause Metadata GC Threshold young initial mark secs GC pause Metadata GC Threshold young initial mark secs GC pause Metadata GC Threshold young initial mark secs GC pause G Evacuation Pause young secs GC pause G Evacuation Pause young secs GC pause G Evacuation Pause young secs GC pause G Evacuation Pause young secs GC pause G Evacuation Pause young secs GC pause G Evacuation Pause young secs GC pause G Evacuation Pause young secs GC pause G Evacuation Pause young secs GC pause G Evacuation Pause young secs GC pause G Evacuation Pause young secs GC pause G Evacuation Pause young secs GC pause G Evacuation Pause young secs GC pause G Evacuation Pause young secs GC pause G Evacuation Pause young secs GC pause G Evacuation Pause young secs GC pause G Evacuation Pause young secs GC pause G Evacuation Pause young secs GC pause G Evacuation Pause young secs GC pause G Evacuation Pause young secs GC pause G Evacuation Pause young secs GC pause G Evacuation Pause young secs GC pause G Evacuation Pause young secs GC pause G Evacuation Pause young secs GC pause G Evacuation Pause young secs GC pause G Evacuation Pause young secs GC pause G Evacuation Pause young secs GC pause G Evacuation Pause young secs GC pause G Evacuation Pause young secs GC pause G Evacuation Pause young secs GC pause G Evacuation Pause young secs GC pause G Evacuation Pause young secs GC pause G Evacuation Pause young secs that sec was pretty big at but it doesn t stop the world for seconds i couldn t reproduce this error with yet but i m pretty sure that the same has happened with If there s anything I can provide to narrow down this problem pls tell me Thanks nazgul Great analysis I m in the same boat as you a user evaluating presto not a developer If you re in the experimenting mood I ve found that v does not exhibit this particular behavior for our company I d be curious if you see the same thing My hunch is the changes between and have contributed to what we re seeing though just what that is i have no idea This issue has been automatically marked as stale because it has not had recent activity It will be closed if no further activity occurs,Yes
1655,issue,Codesandbox is down,Codesandbox is down ,It works All sample links are still broken with same error This was fixed in the new README for the v branch v examples were removed from the master branch and placed on the v branch for safe keeping thus the codesandbox links changed,Unsure
71,issue,Feature Request - manage TS-gateway credentials,Feature Request manage TS gateway credentials ts gateway credentials cannot be managed by credential manager cannot propagate credential changes on group folder needs to edit one by,When will this feature be added,Unsure
3315,issue,"Ombi not updating availability, error thrown in log",Ombi not updating availability error thrown in log Describe the bug Development release not updating status of movies TV Shows Status stuck showing processing Movies TV Shows are already on disk and have been for some time Running Media full sync gives error To Reproduce Steps to reproduce the behavior Request a movie Movie downloads doesn t matter if NZB or torrent Validate movie download is completed and shows up in Plex not totally necessary Wait time for availability to normally update and mark movie as available Movie TV Show does not get automatically marked available From Ombi run Full Manual Sync error shown below is thrown in log Expected behavior Movies TV Shows should update accordingly Screenshots Screen Shot at Logs directory where Ombi is located ThrowIdentityConflict InternalEntityEntry entry at Microsoft EntityFrameworkCore ChangeTracking Internal IdentityMap handleNode at Microsoft EntityFrameworkCore DbContext SetEntityState TEntity TEntity entity EntityState entityState at Ombi Store Repository Requests MovieRequestRepository MarkAsAvailable Int id in C projects requestplex src Ombi Store Repository Requests MovieRequestRepository cs line at Ombi Schedule Jobs Plex PlexAvailabilityChecker ProcessMovies in C projects requestplex src Ombi Schedule Jobs Plex PlexAvailabilityChecker cs line at Ombi Schedule Jobs Plex PlexAvailabilityChecker Execute IJobExecutionContext job in C projects requestplex src Ombi Schedule Jobs Plex PlexAvailabilityChecker cs line Debug Trigger instruction DeleteTrigger Debug Deleting trigger Desktop please complete the following information OS Windows Ombi Version please complete the following information Version Branch develop Media Server e g Plex Version,Hi Thanks for the issue report Before a real human comes by please make sure you used our bug report format Have you looked at the wiki yet Before posting make sure you also read our Make the title describe your issue Having not working or I get this bug for issues isn t really helpful If we need more information or there is some progress we tag the issue or update the tag and keep you updated Thanks Ombi Bot This is a brand new bug I must have introduced yesterday I ll sort it out Thanks for the report please let me know when you have a fix and I will test for you Thanks This has been fixed in the develop branch,Unsure
4039,issue,View with no `authentication_classes` failing permission should raise 403,View with no authentication classes failing permission should raise Checklist x I have verified that that issue exists against the branch of Django REST framework x I have searched for similar issues in both open and closed tickets and cannot find a duplicate x This is not a usage question Those should be directed to the discussion instead x This cannot be dealt with as a third party library We prefer new functionality to be in the form of third party where possible x I have reduced the issue to the simplest possible case x I have included a failing test as a pull request Steps to reproduce Create a view with no set and a set Query the view in order to fail the permission check Expected behavior A with the permission s message should be returned Actual behavior A with a Not authenticated message is returned This is slightly related to the main difference being that this issue is only concerned about view with no and is about prioritizing permissions over authentication in views with,,Yes
200,issue,Feature request: let users have blank passwords (another config option?),Feature request let users have blank passwords another config option Feature request Would it be possible for users to have blank passwords This would ideally be another authlogic option like I m guessing this might affect the existing ignore blank passwords option as well Why this feature I am aware of the security implications of allowing website users to have blank passwords However I m coding a website that isn t holding massively personal data needing bank level security User accounts will start off with blank passwords so users can quickly login by entering their username and an unchanged blank password in the signin form Users can decide later if they d like the extra security but greater inconvenience of a full password This feature request is driven by our particular use case but I do think it s useful to other developers We re following the principle of gradual engagement in designing our website and I believe other developers will too Discussion I initially thought the allow blank passwords option set to false would allow blank passwords and used this in my User model This does allow the model to be saved to the DB with a blank password but authentication fails with an error message in errors password I believe this line in authlogic session password rb is causing the error Thanks for authlogic it s a great library,Look at the source code Whether or not to validate the password field Default true Accepts Boolean def validate password field value nil rw config validate password field value true end alias method validate password field validate password field The validate password field option does not enable blank passwords to be used I ve tested it with the following authlogic configuration in my User model The root problem is the line I specified above errors add password field in the validate by password method of authlogic session password rb This method is triggered during session validation by validate validate by password if authenticating with password Yeah That line should be changed to validate validate by password if authenticating with password validate password field Maybe you could monkeypatch it Hello I m going through old authlogic issues and seeing what to do with them This one looks a bit like a usage question and a bit like a feature suggestion If this is a feature suggestion it s still relevant and you are committed to implementing it please open a new issue and we can discuss your implementation plan If this is a usage question please ask it on stackoverflow Unfortunately we just don t have enough volunteers to handle usage questions on github Also please check the reference documentation You might find something there that s not in the readme Thanks,Yes
1919,pr,Adds missing OAuth login request parameters,Adds missing OAuth login request parameters Adds support for login parameter Adds support for allow signup parameter Closes,release notes Add additional optional fields and to request sorry for not getting back to this earlier,Yes
1129,issue,ruby plugin has security hole,ruby plugin has security hole the connection from nginx to the backend is not authenticated when it s fixed we can put it back on the menu,,Yes
9823,issue,Option tag with v-for causing DOM nodes memory leak,Option tag with v for causing DOM nodes memory leak Version Reproduction Steps to reproduce Press the toggle button What is expected That the garbage collector clears all the nodes What is actually happening Not all nodes are cleared How to see the garbage collection Open the fiddle in single view of the jsFiddle so you can open devtools Open dev tools performance tab record Press toggle a bunch of times or hold enter to keep activating it Stop recording Keyed same issue is still happening,Seems to happen with vanilla JS too in latest chrome I will check a bit more As I understand browsers will schedule GC at appropriate time and we don t have control over that But shouldn t we be able to still force the garbage collection in devtools I opened for the moment Forgot to close this It s a bug in Chrome,Yes
4094,pr,Fix error when using daily availability mgmt datepicker,Fix error when using daily availability mgmt datepicker Strings were passed in instead of dates Now method supports both to be consistent with the other methods in the Concern,,Unsure
1688,pr, add hiveserver 2 support to delegation tokens,add hiveserver support to delegation tokens hiveserver support is added to delegation tokens,Hey can you explain a little more about this change What s the purpose How have you tested it Hi Charlie In the existing hive plugin hive cli is used to connect to hive We want to connect to hiveserver instead When running in secured environments obtaining tokens from hivemetastore is enough for hive clie But for hiveserver we need to obtain hiveserver tokens We added this function this is basically the purpose of this change This version has been running on a production environment for more than one month I tried to write unit tests for this one but I couldn t find a way to run unit tests in a secured environment Is it possible that you give me some information on how to do this or may be send me some examples We are planning to contribute more we have developments such as an impala plugin going on So we will need to run unit tests for secured environments in other cases too Thanks ayca On Wed Mar at AM Charlie Summers wrote Hey can you explain a little more about this change What s the purpose How have you tested it You are receiving this because you were mentioned Reply to this email directly view it on GitHub or mute the thread image Global Maksimum Data Information Tech Ay a Acar Expert Software Engineer ayca acarMaksimum Data Information Tech Office Fax FSM Mahallesi Poligon Caddesi Buyaka Kule Sitesi No C Blok Kat Istanbul T rkiye For the hiveserver stuff I asked to take a look because she knows Hive much better than me Other than that make sure to check out our contribution guide see some minor formatting issues but configuring your IDE to the specifications above should help clean it up Let me know if anything in the guide is unclear your feedback would be helpful Thanks Thanks for the review do you have the throughput to review this Thanks did we miss this file when we did mass formatting change in the past no I ve just been instructing in how to set up their code styling I think they have it right now We don t use HiveServer yet So we won t exercise this functionality regularly Do you have ideas how to automate testing of this feature I just saw your earlier comment about unit testing I am glad you already thought about this The challenge for us is that we don t have a test environment set up to test this feature It s a gap that we have to have test coverage for testing these scenarios I am not aware of an existing test that you can use as a reference yet It s something we should work on and I would appreciate any contribution there have any other thoughts on this PR If not I think we can merge We will have an internal discussion about what accepting changes that we can t test ourselves first We will get back to you,Unsure
3114,pr,KEYCLOAK-3321 OIDC requests without 'nonce' claim should be rejected …,KEYCLOAK OIDC requests without nonce claim should be rejected unless using the code flow Started responseType tests,,Yes
275,pr,Fix queue validation for UnsafeDataTransaction,Fix queue validation for UnsafeDataTransaction When trying to access from an i get a crash related to invalid queue I assume this was a typo during refactoring,Sorry for the silence This looks good thanks,Yes
6947,pr,[DONTMERGE] testing audit stuff,DONTMERGE testing audit stuff Thank you for contributing to The Foreman please read the following in short Create an Reference the issue via in the commit message Prefer present tense imperative style commit messages Mark all strings for translation see Suggest prerequisites for testing and testing scenarios following example above Prepend for work in progress to prevent bots from triggering actions Be patient we will do our best to take a look as soon as we can Explain the purpose of the PR attach screenshots if applicable List all prerequisites for testing e g VMware cluster two smart proxies Reviewers often use extensive list of items to check have a look prior submitting Be nice and respectful,Issues There were the following issues with the commit message eb c a d c ff bced e fcbd c must be in the format If you don t have a ticket number please create an issue in guidelines are available in Coding or on the Foreman message was auto generated by Foreman s There were the following issues with the commit message fc dfbf de e ee f c d c b bf must be in the format d ecc ff a aa f ccc e a must be in the format If you don t have a ticket number please create an issue in guidelines are available in Coding or on the Foreman message was auto generated by Foreman s test foreman There were the following issues with the commit message fc dfbf de e ee f c d c b bf must be in the format d ecc ff a aa f ccc e a must be in the format b b d c ec b f ccda c fa d must be in the format If you don t have a ticket number please create an issue in guidelines are available in Coding or on the Foreman message was auto generated by Foreman s There were the following issues with the commit message fc dfbf de e ee f c d c b bf must be in the format d ecc ff a aa f ccc e a must be in the format b b d c ec b f ccda c fa d must be in the format a df c cefd dfe bbb be must be in the format If you don t have a ticket number please create an issue in guidelines are available in Coding or on the Foreman message was auto generated by Foreman s,Unsure
8697,pr,DEV: Refactor 2FA authentication flows for sanity,DEV Refactor FA authentication flows for sanity Move confusing FA logic involving whether to authenticate with security key or totp to second factor manager and clean up and move authenticate webauthn functionality to second factor manager Replace confusing code in session controller with new calls to second factor manager Add specs for new manager code and ensure current session controller specs work fine,You ve signed the CLA martin brennan Thank you This pull request is ready for review,Yes
51884,issue,[fluorine] mac test_salt_contains_function test failing,fluorine mac test salt contains function test failing commented on Wed Nov test is failing on mac sierra and highsierra commented on Wed Dec have not seen this fail in a while I think it has been fixed commented on Tue Jan like this is still commented on Tue Jan commented on Tue Jan believe its still failing even with the PR above commented on Wed Jan dug into this a little bit and I m pretty sure it s happening due to the minion failing to start If you run then pop up a new terminal and run It works and the result is True as expected On the other hand when I just run the test I get this output So it looks like something is getting borked somewhere the test works when manually running it just not on autopilot commented on Wed Jan also it s definitely something going on with the Mac libs because I can run the same test within a Docker ubuntu container and it works A OK,This test last failed on Feb th so need to make sure if its still failing on before this gets deemed a blocker or not Assigning it to Gareth since he s working on getting the Mac test machines to run again Marking this as fixed since tests are running again since the move to kitchen salt,Unsure
2200,issue,Make shine report generation thread safe,Make shine report generation thread safe Issue Type Bug Report Summary After a stage job completion a sub component called shine extracts RDF using This is done by applying an xslt transformer that is cached but not thread safe leading to loss of data when stages jobs complete at the same time Basic environment details Go Version and below Expected Results Generation of the shine stage job RDF data Actual Results Depending on the transformer used For Xalan it s Possible Fix Modify the following use a queue for,,Yes
4643,pr,Fix authn delegation behavior,Fix authn delegation behavior If we force the authn delegation process on an existing SSO session the current behavior is unappropriate the credentials should not be put in the webflow for an existing session as they trigger a login process erasing the previous authenticated user I also changed the visibility of two methods from to for customisation purposes,CLA assistant Thank you for your submission we really appreciate it Like many open source projects we ask that you sign our Contributor License before we can accept your contribution You have signed the CLA already but the status is still pending Let us it Report Merging into will increase coverage by The diff coverage is Impacted file tree Impacted Coverage Complexity arrow up and Continue to review full report at Legend Click here to learn Powered by Last update Read the comment,Yes
369,issue,can login method accept the 'username' or 'email' at the same time?,can login method accept the username or email at the same time I want login by username or email how can I do Thanks,In you have following line You just need to uncomment it and add to that line maybe it wasn t available in the version you used when added this issue it s possible now Awesome Thanks,Yes
9273,issue,"Actuator health endpoint is ""full content"" for anonymous user when security.enabled is false and health.sensitive is true",Actuator health endpoint is full content for anonymous user when security enabled is false and health sensitive is true Bug Report Summary The Spring Boot Actuator specifies that when management security enabled is false and endpoints health sensitive is true the health endpoint should return status only Actual Behavior When I set in application properties and I access the health endpoint I get full content for anonymous authentication Expected Behavior For the above setting when accessing the endpoint as an anonymous user I should get only Configuration Spring Boot RELEASE spring security web RELEASE REST endpoint access with Firefox and RestClient addon but when testing I didn t present any certificate so it was one way SSL Note this was initially reported on Spring Security issue mistake which was closed in favor of this report,This looks like a bug in the documentation If is set to unauthenticated requests to the endpoint are not allowed If is set to full health details are exposed,Unsure
1522,issue,Secret Mode (or safe mode),Secret Mode or safe mode Add a Secret Mode like when downloading some NSFW content it will be awkward if there is a preview displayed on the screen,This issue has been automatically marked as stale because it has not had recent activity It will be closed if no further activity occurs I don t really care about this but I don t like the stale bot This issue has been automatically marked as stale because it has not had recent activity It will be closed if no further activity occurs,No
1546,issue,`localtunnel` dependency has security vulnerabilities,localtunnel dependency has security vulnerabilities Issue details contains security vulnerabilities in its dependencies Upgrading to removes the dependency which contains the vulnerability which is located in hoek node module before suffers from a Modification of Assumed Immutable Data MAID vulnerability via merge See current browser sync dependency tree Steps to reproduce test case Use in a project on GitHub with vulnerability alerts turned on screen shot at Please specify which version of Browsersync node and npm you re running Browsersync Node Npm Affected platforms x linux x windows x OS X freebsd solaris other please specify which Browsersync use case API x Gulp Grunt CLI,,Yes
23789,pr,🏗🐛Manually update `build-system/tasks/visual-diff/yarn.lock` to address security vulnerabilities,Manually update build system tasks visual diff yarn lock to address security vulnerabilities The visual tests use v of which has dependencies with known security vulnerabilities of fixes these vulnerabilities but we can t upgrade because of breaking API changes See Until then this PR manually upgrades the offending dependencies to safe versions Future task Upgrade to v of,That worked,Yes
4869,issue,Potential deadlock when using phased scheduler with broadcast joins,Potential deadlock when using phased scheduler with broadcast joins The scheduling dependency graph is missing an edge which can cause the join stage to be scheduled independently and before the build stage,,Yes
676,issue,Use public suffix list for 3rd party cookie blocking to detect 3rd party hosts,Use public suffix list for rd party cookie blocking to detect rd party hosts This is a better fix for Ideally this would be exposed in a shareable lib for iOS Android and the laptop browser Possibly as another C lib with another dat file,,Yes
4861,issue,Help overcoming two errors building macOS app - Electron doesn't recognize my Apple developer certificate ERROR ITMS-90237 and App sandbox not enabled ERROR ITMS-90296,Help overcoming two errors building macOS app Electron doesn t recognize my Apple developer certificate ERROR ITMS and App sandbox not enabled ERROR ITMS electron electron builder dist entitlements mac plist dist entitlements mac inherit plist I have placed the correct Developer ID certificates Have any of you successfully overcome these two problems I am facing to create a build of my electron app for the macOS store I have included the correct apple certificate and entitlement properties but still electron is not detecting these things in the build process Errors,you all have chimed in on similar electron build issues is the expert here and we are back to figuring this out so we can get our angular app compiled and working in the Mac and Windows stores Do you have any ideas on a fix to the above issue Can you check if in Can you check if in i am creating pkg not dmg or mas Here s what I ve done to get a working MAS pkg on your post I see that you ve set target to It should be instead which will pick up the right certificates Also I suggest you remove setting of custom It should only contain the sandbox and security inherit keys unless you know what you re doing Lastly I d suggest making a build as well Thanks for replying I had tried mas but build failed because if identity issue skipped macOS application code signing reason Identity name is specified but no valid identity with this name in the keychain identity XYZ VXKRTP allIdentities Even that i have placed all corect identities at KeyChain I saw your issue comment link above you have created build via mas and manually signed using electron osx sign But if we used mas in electron builder internally it used electron osx sign lib to sign the app In my case I resolved the issue by upgrading electron and electron builder to electron electron builder These two upgradation resolved my all problems Here is my build settings build appId my app id productName Plv copyright company Inc asar true files build public embedded provisionprofile entitlements mac plist entitlements mas plist all certificates p directories buildResources build output package desktop app mac gatekeeperAssess false darkModeSupport false entitlements build entitlements mac plist entitlementsInherit build entitlements mas plist target dmg mas pkg mas entitlements build entitlements mac plist entitlementsInherit build entitlements mas plist provisioningProfile build embedded live provisionprofile dmg sign false win certificateFile winCerts certi pfx certificatePassword mypassword verifyUpdateCodeSignature false By this I have successfully publish the app on mac store and windows store thanks for sharing details let me try this and back to you Where you have provided all certificates p in above config where should i place this file in directory how can i create this p files which certificate should include in this p I used this link to create the all certificate I place this file in root directory of the project i am following these and able to submit build to apple store but i am facing these last two issues Do you have idea about these issues can you please share your entitlements build entitlements mac plist build entitlements mas plist Here is my entitlements mac plist Screenshot at Screenshot at thanks for sharing Once i signed app via codeSign The app crash on startup I have debug app this error shown FATAL gpu data manager impl private cc The display compositor is frequently crashing Goodbye Once i removed com apple security app sandbox from plist then app works but Apple store not accepting build without adding sandbox You have any idea about this Is this still relevant If so what is blocking it Is there anything you can do to help move it forward This issue has been automatically marked as stale because it has not had recent activity It will be closed if no further activity occurs,Unsure
3250,pr,Bug 1402483: Remove BVC logging spam,Bug Remove BVC logging spam ,There are also debug statements in TabManager HistoryPanel BookmarksPanel could we also remove those tbh and a lot of the debug statements in AppDelegate we could probably get rid of those At least the ones that always happen like We could keep the start finish but everything inbetween seems useless imo Agreed on above points I ll take the others you mentioned out also,Unsure
23996,issue,"Unlike lambdas, local functions do not capture scripting globals",Unlike lambdas local functions do not capture scripting globals There are workarounds but they are irritating during what should be simple refactors I use Roslyn Scripting the most via Cake This issue seems to be with Roslyn itself Expected Local functions capture the global all examples run successfully Actual Microsoft CodeAnalysis Scripting CompilationErrorException error CS An object reference is required for the non static field method or property Program Globals SomeGlobal If this is according to the spec please make it a feature request I don t see any reason why local functions should fail to capture globals,Tagging Can someone confirm whether this is per spec or a bug cc Scripting basically has its own design so I have no idea what the expected behavior of any C language feature is in scripting Globals and script variables should definitely be available in local functions If I submitted a PR don t laugh would you take it Absolutely I see what you mean about script variables Methods too I ve traced the problem this far Because the local function has the receiver is determined to be causes this code to report So the question is why is LocalFunctionSymbol considered to be Removing fixes the added tests but breaks existing tests Either local functions need to be conditionally static seems the more complex guess or should not always require a non static Got it PR is up,Unsure
26230,pr,Avoid stealing focus from the active output window pane,Avoid stealing focus from the active output window pane Avoid stealing focus when creating our output window pane Fixes part of NOTE I ve spent three hours trying to test this but failed miserably due to a number of issues I m not going to spend anymore time on it but others are welcome to take my changes test and merge I ve since tested this and it works,Is focus only set to the IntelliSense Errors window the first time a message is written to it i e it never occurs again unless the IDE is restarted If so the current behavior sounds like what we would want Is focus only set to the IntelliSense Errors window the first time a message is written to it i e it never occurs again unless the IDE is restarted If so the current behavior sounds like what we would want It does but because of the workflow TemporaryGeneratedFiles MSBuild generated TFM files etc that the odds of you getting an error is quite high And those errors are useless Frankly we added this pane because it s what the old IDE did Do we have any evidence this has helped anyone diagnose anything smile I m not aware of any such evidence Well I vote for just deleting the thing Somebody to second the motion Ran into this again Give no one has taken up to delete the Output window can we please look over this and get code review sign off This can be a stop gap until someone deletes the category This is no longer a work in progress I ve successfully tested this and confirmed it works I will merge into tomorrow if there is no more feedback Can I get approval for this I am neutral as to whether or not we accept this change Functionally I believe it achieves the intended purpose and the code behavior is clear as can be aside from the one question I added The following items prevent me from landing on the side of full support The messages described and are not the only messages capable of using this window A review of code paths leading to this window suggest other more serious situations could be revealed by this window and hiding the window would cause a user to miss these messages During an initial attempt to remove the specific messages mentioned in the previous issues I became concerned that the underlying cause of these messages is a bug in Roslyn s handling of file change notifications and or incremental updates The IntelliSense engine should be accounting for the possibility of asynchronous modifications to the file and not strictly assuming they will exist Even more concerning to me is sensitivity to asynchronous file modifications likely means Roslyn is capable of producing instances that represent torn state i e the immutable snapshot compilation describes a state which never actually existed In short this PR adds a bunch of code to hide what is likely a more serious bug in the project The following items prevent me from landing on the side of blocking I agree that the messages described in the bugs this PR works around are annoying and generally not helpful We have not established a timeline for fixing the bugs mentioned above so without a workaround things are likely to stay as they are Summary I defer to the rest of the IDE team to decide whether or not to take this change in light of the information above If they decide to take the change I believe my code review is relevant Sam none of the above concerns should block this check in we are not hiding the pane We just don t make it steal focus the very first time it is created It never steals focus after that regardless of the error that is output If you feel strongly that the error messages should be removed or are hiding race conditions this change doesn t prevent you from fixing them Given we haven t fixed them in two years and they are not assigned to a milestone I will not block this check in on resolving those issues Yeah totally OK with this change Regarding these messages The nature of the file system means these issues can be legitimate problems or entirely transient issues that we will handle correctly the messages give no way to determine which of those two it is I don t think I can recall of a single instance where these were ever used to diagnose any problem I can think of plenty of times people saw the errors and panicked and got confused by the problem I d still vote just delete but admittedly haven t found the time myself to make a change now And no reason to hold this up for the undetermined future The nature of the file system means these issues can be legitimate problems or entirely transient issues that we will handle correctly the messages give no way to determine which of those two it is One option to consider During build collect the information but do not display it until the end At the end if we thought we couldn t read a file but now we can suppress do not report that problem I d still vote just delete but admittedly haven t found the time myself to make a change now And no reason to hold this up for the undetermined future I agree with this It just doesn t actually have any positive benefits to the user And it def have negative ones During build collect the information but do not display it until the end At the end if we thought we couldn t read a file but now we can suppress do not report that problem The information isn t collected during build the simple example of these is you open a solution that pulls in an autogenerated file but that file isn t generated until the first real build We ll give this this error but we have no way to know whether this is a project file being broken or just something that will be fixed by a build perhaps minutes or hours later The information isn t collected during build the simple example of these is you open a solution that pulls in an autogenerated file but that file isn t generated until the first real build We ll give this this error but we have no way to know whether this is a project file being broken or just something that will be fixed by a build perhaps minutes or hours later That s fair however for the bug i reported the issue is files presumably getting deleted regenerated during build So at least some of the issues could potentially be addressed if not all of them I ve tagged you in that issue for your thoughts This is ready for M approval then once that s approved we can merge you want the honors or should I This error occurs simply by deleting a file in CPS projects No auto generation needed Approved to merge for Preview,Unsure
269,issue,New install: OLW Crashes when signing into blogger account,New install OLW Crashes when signing into blogger account Just DL OLW for first time but have got nowhere as every time it starts DL of my selected blog it crashes and closes,Can you post your log file please at localappdata openlivewriter Open Live Writer one That s the one thanks Ok looks like this is a dupe of Please follow that issue for progress on this Oh but that s still unresolved Is this going to take a while Hopefully not When you try adding your blog does it ask you if you want it to download supporting files for your theme If it does click no That should I think at least let you use the application Nope all just runs auto Thanks for addressing this issue my bloggger theme can now be updated with no issues,Unsure
5278,issue,ROW type hash implementation throws misleading message,ROW type hash implementation throws misleading message Message should say is not supported for,It seems that this was intentional reason why not compare row with null elements I think the problem might be that However for now only return which is not a object and could not express imo should be not null The row itself is not null being seems a weird behavior Complex one too since is why precedes anyway I agree in returning null like does btw this same problem also happens to array throws an exception Should we treat this in this issue or or a new one Row comparison semantics are equivalent to doing a pairwise comparison of the elements and joining them with AND So Row a b Row c d Is equivalent to a c AND b d Then standard semantics apply for how nulls are treated null AND true null null AND false false The way to think about it is null means the actual value is unknown Given that notion if any pair of fields don t match we know for sure that the equality is false If all pairs of fields but one match as the latter is a comparison with an unknown value we can t tell whether the equality is true or false so it returns unknown Got it that s a really good explanation thanks a lot Fixed by,Unsure
823,pr,Remove pycrypto (vinta/awesome-python#819),Remove pycrypto vinta awesome python It appears pycrypto is no longer maintained and has known vulnerabilities see dlitz pycrypto dlitz pycrypto Appears that larger projects paramiko ansible twisted have moved over to PyCA s cryptography which is already on the list What is this Python project Describe features What s the difference between this Python project and similar ones Enumerate comparisons Anyone who agrees with this pull request could vote for it by adding a to it and usually the maintainer will merge it when votes reach,,Yes
10634,pr,Add truststore to testerapp 4443 port ,Add truststore to testerapp port I confirm that this contribution is made under the terms of the license found in the root directory of this repository s source tree and that I have the authority necessary to make this contribution on behalf of its copyright owner,Merge conflitct with master,Yes
3281,issue,Cookies are not set if authentication service is on a different port than web app,Cookies are not set if authentication service is on a different port than web app Current behavior Our application has separate services responsible for authentication and delivering our web app On local environment that would be and is set to Running this code in tests fails It would seem that on purpose isolates cookies between different ports of the same domain Desired behavior As this works in Chrome or any tested Firefox Safari Edge to be explicit other browser I think cookies should be set as described e g in this a global change would be an issue maybe could be an exemption Steps to reproduce have separate services with authentication and web app available on different ports set the web app as make a request to the auth api as in the code above response contains returns empty array Versions Cypress v macOS Chrome,,Yes
8489,pr,[FIX] Wrong message when resetting password and 2FA is enabled,FIX Wrong message when resetting password and FA is enabled Closes When password is reset the user is logged in automatically but one error is received when the user has FA enabled requiring to pass the token that is why we have the password reset but one error is displayed This PR just check the error message and redirect the user to the login page when FA is required and show a success alert about the message reset The possible results are FA Disabled After a successful password reset the user will be logged in automatically FA Enabled After a successful password reset the user will receive a successful message and will be redirect to the login page,,Yes
6745,issue,QueryStringDecoder does not decode correctly path part with '+' (plus) sign in it,QueryStringDecoder does not decode correctly path part with plus sign in it Expected behavior is a valid char for path part of URI it should not be replaced by space Actual behavior is replaced with space Steps to reproduce Minimal yet complete reproducer code or URL to code Netty version JVM version e g OS version e g Any,See application x www form urlencoded This is the default content type Space characters are replaced by And Javadoc for says that This decoder can also decode the content of an HTTP POST request whose content type is application x www form urlencoded I am talking about the path part of an URL See grammar in yes you are right It s a bug A also doesn t cut a from query string as prescribed by RFC output WDYT I can provide a PR to fixing both issues for a PR thanks yes please Found one more problem a charset does not work as intended Code return I ll try to fix this too Cool thx Am um schrieb Nikolay Fedorovskikh Found one more problem a charset does not work as intended Code System out println new URI getPath System out println QueryStringDecoder decodeComponent System out println QueryStringDecoder decodeComponent return A CG K I ll try to fix this too You are receiving this because you were mentioned Reply to this email directly view it on GitHub or mute the thread Check please There is one more question Why QueryStringDecoder treat double percent as escaping of the percent character I could not find it in the RFC URLDecoder from JDK throw an exception on a string containing Commit f b d f bc bb f dedd can you clarify this please I don t remember why I added this Seems like it was intentional since there is a test case that specifically verifies this behavior but it does look weird to me too now thanks I think we need to fix this too for a more accurate match of This is essentially equivalent to calling URLDecoder decode s charset name I m updated a PR related close this fixed by,Yes
4561,pr,Update bundled script-security plugin,Update bundled script security plugin See usual update bundled versions to not have the vulnerability Proposed changelog entries Update bundled Script Security Plugin from to Proposed upgrade guidelines N A Submitter checklist n a JIRA issue is well described x Changelog entries and upgrade guidelines are appropriate for the audience affected by the change users or developer depending on the change Fill in the section only if there are breaking changes or other changes which may require extra steps from users during the upgrade n a Appropriate autotests or explanation to why this change has no tests x For dependency updates links to external changelogs and if possible full diffs Desired reviewers Comment If you need an accelerated review process by the community e g for critical bugs mention Maintainer checklist Before the changes are marked as There are at least approvals for the pull request and no outstanding requests for change Conversations in the pull request are over OR it is explicit that a reviewer does not block the change Changelog entries in the PR title and or are correct Proper changelog labels are set so that the changelog can be generated automatically If the change needs additional upgrade steps from users label is set and there is a section in the PR title If it would make sense to backport the change to LTS a JIRA issue should exist and be labeled as,Merging in h if no negative feedback,Yes
5740,pr,added 'assets_callback' to 'register_block_type' function,added assets callback to register block type function Description Like suggested in this PR adds to the function With this developers can access block attributes on and action hooks and use them to do things like conditionally enqueue scripts styles add inline styles or scripts etc An example of how to use this callback Tested with WordPress Gutenberg PHP nginx MySQL,do whatever you need with the block attributes For example you can generate tags with wp add inline style enqueue scripts styles or call wp localize script What of these would not be possible with existing and properties Hi thanks for reviewing my PR Currently and properties are handlers used only for enqueuing block assets as described on the documentation you mentioned That s fine and it is a good architecture But you can t do much more than just enqueue these assets You can only assign a style script handler name to these properties You can t for example assign a callback function to use functions like or Obviously you can just ignore these properties and use the existing hooks and but why would I do that Currently when you re building a shortcode for example you can register a script on an hook and then inside the render function for the shortcode you call to ensure that your script will only be enqueued if your shortcode is present on the content But you can also for example inside this same render function and after enqueueing the shortcode s script call and generate some variables based on the shortcode s attributes That s the main keyword attributes On and hooks you can do whatever you want but you don t have access to block attributes So if for example I want to generate some custom styles for a block based on its attributes you can t The is similar to a render function for a shortcode and you do have access to blocks attributes there but there are some downsides based on my own research while building some custom blocks of using it for this purpose Some functions may not work properly inside On my own tests using with an existing style handler didn t worked and the tag that should show up was missing By using for the single purpose of manipulate blocks attributes to generate assets or styles scripts you are enforced to use this PHP callback to render your block instead of using javascript My PR with the solves both problems You have access to attributes inside the proper hooks methods like works properly and you have a separation of concerns with a callback for rendering the block html and another one to render generate blocks styles scripts The main goal of this PR is to provide a viable solution if you don t want to inline specific block styles js variables For example by using along with blocks attributes you can properly generate tags for your block instead of inlining the css inside html tags or are sufficient for static additions to script styles and handles The compelling bit for me is attribute dependent additions I could imagine this being useful though I d agree some real world use cases may be valuable to have Ok guys to better explain how the is useful I ll give a real example Currently I m working on a set of custom blocks One of them is a slideshow block On this block you select a set of images from your media library and then you can customize the pieces that compose the slideshow One of these pieces is the navigational the navigational arrows I added options for Arrow size Arrow color Arrow background color Arrow background opacity Arrow background roundness Each one of these options is an attribute All of them are the kind of attributes that you can t set using css classes You have to either generate the css to apply these attributes or inline everything So here is the implementation of these attributes with the current state of Gutenberg and with the Current State The only way to add styles like color background color and opacity is through inline styles So you have to generate the html markup with the styles applied For the arrow background if you want to add a semi transparent background you need to create an html element only for that if is accepted and merged then this extra element would not be necessary anymore On your block s JavaScript file the callback should return an output similar to this So all css styles are inline and the element is created to generate the background with the opacity properly set With By adding the to the function we can simplify our html output and remove unnecessary tags So our output may look like this And then with the function we can do this By using the we can do two things Keep our markup only for content structure and move all attribute based styles into it s own tag Since we re free to manipulate the attributes we can replace unnecessary elements by targeting pseudo elements like and You can also conditionally load other assets based on attributes Let s suppose that my slideshow module has it s main JavaScript library that adds all the base functionality An then I have some addons modules for extra functionality like slideshow thumbnails or zooming into the current slide You can create an attribute to enable disable these features and based on that attribute you can enqueue the secondary assets I hope this example helps to clarify why this PR can be useful Thoughts Hi thanks for your contribution A couple of points This is my own assessment and not necessarily Daniel s or Andrew s but I don t think this use case is compelling enough to justify the added interface complexity and render time burden For one this is a very specific kind of optimization that is it s not a block level optimization like async asset loading but rather an optimization on the amount of styles imported or inlined Notably it s not a blocker for the intended plugin even if it may be less convenient and the optimization yield isn t expected to be significant from what I can see at least Secondly nascent Web standards prove quite handy In this instance I m looking at CSS variables and scoping With them one can define default values by way of CSS variables in the block type s actual stylesheet and override them with block specific values through inline styles during the call Here is a concrete jsfiddle proof of Depending on your user base and intended browser support your could either use this today or very soon More generally if you re curious Block level front end asset loading is being explored in There are priors for block level not attribute dependent async asset loading in the Custom HTML though there are many kinks to work out there and thus that block type shouldn t serve as example yet thanks for your comment Here are some considerations For one this is a very specific kind of optimization that is it s not a block level optimization like async asset loading but rather an optimization on the amount of styles imported or inlined Notably it s not a blocker for the intended plugin even if it may be less convenient and the optimization yield isn t expected to be significant from what I can see at least The example provided is just one example of what you can do when you have access to blocks attributes inside the right action hook My point of not using inline styles is not about being convenient It s more about best practices and flexibility The decrease of the amount of styles inlined is just a plus My point is that Inline styles are not a best practice and should be used wisely I think that this on Codecademy is a good one to clarify when inline styles are considered good or bad practice It is ok and probably the only way to go to have inline styles inside Gutenberg But by saying Gutenberg I mean the editor interface Since we re live previewing our changes it is ok and natural to use inline styles inside a React component But on the frontend there s no real compelling reason to favor inline styles over an external stylesheet or even a tag with CSS rules There are some things that you can t do using inline styles For example how can you target a pseudo element with inline styles With CSS classes you can easily use or CSS is only one side of the coin You can also use these attributes with JavaScript Even if my personal opinion is that inline styles are not a good practice I m not against using them on the frontend What I m against is to not provide a more flexible approach to attribute based styles scripts if we can Secondly nascent Web standards prove quite handy In this instance I m looking at CSS variables and scoping With them one can define default values by way of CSS variables in the block type s actual stylesheet and override them with block specific values through inline styles during the render callback call Here is a concrete jsfiddle proof of concept Depending on your user base and intended browser support your could either use this today or very soon The scoped attribute is currently and seems like will eventually be deprecated But dude I really like CSS variables They re really cool and your jsfiddle is a good example on how they can be handy But one of the downsides is that they re not supported on IE Of course the current support is pretty good But still like you said depending on your user base it might be a good fit or not If I have a the option to style my block and at the same time support all browsers even some old versions I think that this can be a better fit and override them with block specific values through inline styles during the call Yes you can use the call to do some stuff but like I said on one of my comments if you use it then you re forced to use this callback to render your whole block This means that the output will be always dynamically generated If I just use the callback on the function The html output of my block will be stored on the post content and will be just static HTML which is faster than a generated output done with PHP With you have a clear separation of concerns You can use whatever you like to generate the output of your block The block styles or scripts can be independent of how you render your block With all of that said I took a look on and I really like the idea of dynamic bundles One way of doing it is not only bundling CSS assets for all blocks on a page but we could also add to the bundle some attribute based styles generated for a block This is a approach similar to what Beaver Builder does On BB for a custom module there s a php file where you can use a module s attributes to generate CSS This CSS is then bundled with all of the generated CSS styles from the modules used on the page and then this bundle is served on a single CSS file enqueued for that specific page If we could do something like that it would be awesome Hi for all of your work on this pull request For now I d suggest we close it but keep the issue open and revisit the conversation in a couple of months once we ve seen Gutenberg in the wild a little bit longer I think time will help guide a better decision on this Closing this in favor of and related PRs to make sure we don duplicate the same discussions thanks for opening this PR it was very helpful in the context of the work in other PRs any reason why assets callback not working in register block type This pull request was closed without merging meaning its changes were not effected See for a broader issue on the topic,Unsure
394,issue,Split fingerprintjs into multiple files,Split fingerprintjs into multiple files I imagine a structure as follow Structure fingerprintjs js imports every component and murmur so that the result is the same This could be a non breaking change The components don t need to import fingeprint js everything needed is provided in options argument Bundler As bundler I think rollup is appropriate can produce standard iife umd and commonjs output Publishing ES Modules To make sure your ES modules are immediately usable by tools that work with CommonJS such as Node js and webpack you can use Rollup to compile to UMD or CommonJS format and then point to that compiled version with the main property in your package json file If your package json file also has a module field ES aware tools like Rollup and webpack will import the ES module version directly New file outputs New pacakage json,Sounds good I wonder if there s a way to allow for custom minimal builds that don t include the code for components you re not using I did splitting into multiple files for the pro version I used webpack though I like it more than rollup Once I get some time I ll be able to back port this into the OSS version was the case ever resolved I m having now same issue,Yes
348,issue,Could there possibly be a importer and assets build function in the near future?,Could there possibly be a importer and assets build function in the near future I don t currently have a viable way to import FBX correctly back into assets files Unity screws up the model file when building the assets Could there possibly be a importer and assets build function in the near future,Will not consider adding the edit future of the asset,Unsure
1150,pr,Don't update window hash on scroll (fixes #1149),Don t update window hash on scroll fixes While having a constantly accurate bookmark without clicking is useful the browser s history becomes unusable when the page gets even light usage,Sorry I m new to GitHub s management of pull requests I guess this and need merging It s all good It s typical to refer to the original issue either as a comment as you did or in the commit message Thanks,Unsure
8217,issue,MigrationQueue deadlock,MigrationQueue deadlock The internal queue and counter do not synced queue size but counter in some situation happens couple times when try to orderly restart a cluster by invoke shutdown method on hazelcastinstance which cause deadlock Usually it happens there is a migration task failure I haven t been able to create a reliable producible configuration the log keeps loop until timeout,Ok I think I find out why the MigrationQueue also accept RepoartiioningTask which is not a instaceof MigrationTask When shutdown is claiming about Waiting for cluster migraiton tasks it is actually waiting for ReportioningTask But ReportioningTask keep failing because local instance is in shutdown mode If ReportioningTask is actually not allowed after shutdown process kick off shouldn t shutdown process only check the counter not queue size the following code should use MigrationQueue hasMigrationTasks not size Hi As I see in the logs RepartitioningTask produces the same migration repeatedly and it fails for some reason From the logs you share reason of the migration failure is not clear Do you have any other logs you can share with us Maybe migrations are failing because of an exception thrown from a service etc I don t have the logging anymore The failure is caused by migration target was shutdown after repartingint task which why it was picked as migration target before migration complete then infinite loop The situation happens during my rolling deployment process which will shutdown hazelcast node one by one gracefully by invoking HazelcastInstance shutdown then deploy new code restart hazelcast node move on to next one Fixed by,Yes
889,pr,Track rollback safeness in shipit,Track rollback safeness in shipit undeployed commits this case is the deploy which contains a unrollbackable commit This means that we can rollback to this revision but any rollback attempt on an older revision will result in the following we should always give developers the option to rollback a commit even if it s marked as unsafe because it s possible that it was marked as unsafe wrongly At the same time we should raise sufficient alarms so that these actions are performed with the right information Any thoughts on the above ui experience Should we make it louder cc,It ll render in the github UI exactly as the screenshot above the screenshotted page was rendered with github s stylesheet that we inject also yeah I ran into a snag with since it s already something that s used on I m probably gonna rename the flag to instead Thoughts Also added the experience on rollbacks Logic and the associated screenshots are documented in the pr summary would appreciate another round of I m really tired and my head is full of conference things so I apologise in advance for the half baked thoughts I m worried about unintended consequences perverse incentives with this change and want to make sure we re aligned on what we want to achieve The way I see it there are big areas we want a better story on When things are on fire people dealing with the issue may not have all the context on all the changes A quick signal on rollback safety allows them to move more quickly and more confidently at at time when they may really need to Have developers think about rollback safety make a conscious decision either way and then optionally later have Shipit help them rollout unrollbackable changes in isolation so that they re not bundled with other changes which might break and need rolling back If we re agreed there I haven t missed anything I wonder if we shouldn t actually have a default set either way and have people deliberately pick and refuse to merge without a choice On the plus side it cant be ignored and we sidestep the risk that we don t trust the boolean because people never set it On the downside shipping an unrollbackable change should be extremely exceptional and so for the vast majority of PR s we re introducing unnecessary friction I m keen to get everyone s thoughts on this Thanks for the comments everybody I think we can make the Add to Merge Queue a two step process like this Add to merge queue click Is this change safe to rollback Yes No click yes or no change added to merge queue with flag set This change will also fix the polling state problem We can make it so that clicking the initial Add to merge queue button pauses the polling Once Yes No are selected we can resume the polling We could also put the second step here on a timer so that if Yes No is not selected within a certain time the polling kicks in again which will reset the ui back to add to merge queue Maybe a timer bar at the bottom can communicate this This will make it so that there s a maximum time drift between Shipit s state and the user s UI thoughts I like that idea and that it is process driven Maybe add this to the shipitnext document for experimentation This has been put on hold since the interaction here is pretty janky and shipit next might be a much better place to establish something like this,Unsure
738,issue,Observing leak in hikari connection pool 2.2.5 ver,Observing leak in hikari connection pool ver Hi We have allocated connection pool size of Sometime suddenly find the all the connection in use No connection available Checked in database server it indicates no connection are open from hikari connection pool This happens interminently We also observed nothing is running in application and suddenly it shows all the connection are inuse system freezes completely We have following logs but cannot make out anything Below logs for reference Please suggest Hikari Housekeeping Timer pool HikariPool DEBUG com zaxxer hikari pool HikariPool After cleanup pool stats HikariPool total inUse avail waiting RMI TCP Connection DEBUG com zaxxer hikari pool HikariPool Performing alive check for connection oracle jdbc driver T CConnection RMI TCP Connection DEBUG com zaxxer hikari pool HikariPool Performing alive check for connection oracle jdbc driver T CConnection RMI TCP Connection DEBUG com zaxxer hikari pool HikariPool Performing alive check for connection oracle jdbc driver T CConnection RMI TCP Connection DEBUG com zaxxer hikari pool HikariPool Performing alive check for connection oracle jdbc driver T CConnection RMI TCP Connection DEBUG com zaxxer hikari pool HikariPool Performing alive check for connection oracle jdbc driver T CConnection RMI TCP Connection DEBUG com zaxxer hikari pool HikariPool Performing alive check for connection oracle jdbc driver T CConnection RMI TCP Connection DEBUG com zaxxer hikari pool HikariPool Performing alive check for connection oracle jdbc driver T CConnection RMI TCP Connection DEBUG com zaxxer hikari pool HikariPool Performing alive check for connection oracle jdbc driver T CConnection RMI TCP Connection DEBUG com zaxxer hikari pool HikariPool Performing alive check for connection oracle jdbc driver T CConnection RMI TCP Connection DEBUG com zaxxer hikari pool HikariPool Performing alive check for connection oracle jdbc driver T CConnection RMI TCP Connection DEBUG com zaxxer hikari pool HikariPool Performing alive check for connection oracle jdbc driver T CConnection RMI TCP Connection DEBUG com zaxxer hikari pool HikariPool Performing alive check for connection oracle jdbc driver T CConnection RMI TCP Connection DEBUG com zaxxer hikari pool HikariPool Performing alive check for connection oracle jdbc driver T CConnection RMI TCP Connection DEBUG com zaxxer hikari pool HikariPool Performing alive check for connection oracle jdbc driver T CConnection RMI TCP Connection DEBUG com zaxxer hikari pool HikariPool Performing alive check for connection oracle jdbc driver T CConnection RMI TCP Connection DEBUG com zaxxer hikari pool HikariPool Performing alive check for connection oracle jdbc driver T CConnection RMI TCP Connection DEBUG com zaxxer hikari pool HikariPool Performing alive check for connection oracle jdbc driver T CConnection RMI TCP Connection DEBUG com zaxxer hikari pool HikariPool Performing alive check for connection oracle jdbc driver T CConnection RMI TCP Connection DEBUG com zaxxer hikari pool HikariPool Performing alive check for connection oracle jdbc driver T CConnection RMI TCP Connection DEBUG com zaxxer hikari pool HikariPool Performing alive check for connection oracle jdbc driver T CConnection RMI TCP Connection DEBUG com zaxxer hikari pool HikariPool Performing alive check for connection oracle jdbc driver T CConnection RMI TCP Connection DEBUG com zaxxer hikari pool HikariPool Performing alive check for connection oracle jdbc driver T CConnection RMI TCP Connection DEBUG com zaxxer hikari pool HikariPool Performing alive check for connection oracle jdbc driver T CConnection RMI TCP Connection DEBUG com zaxxer hikari pool HikariPool Performing alive check for connection oracle jdbc driver T CConnection RMI TCP Connection DEBUG com zaxxer hikari pool HikariPool Performing alive check for connection oracle jdbc driver T CConnection RMI TCP Connection DEBUG com zaxxer hikari pool HikariPool Performing alive check for connection oracle jdbc driver T CConnection RMI TCP Connection DEBUG com zaxxer hikari pool HikariPool Performing alive check for connection oracle jdbc driver T CConnection RMI TCP Connection DEBUG com zaxxer hikari pool HikariPool Performing alive check for connection oracle jdbc driver T CConnection RMI TCP Connection DEBUG com zaxxer hikari pool HikariPool Performing alive check for connection oracle jdbc driver T CConnection Hikari Housekeeping Timer pool HikariPool DEBUG com zaxxer hikari pool HikariPool Before cleanup pool stats HikariPool total inUse avail waiting Hikari Housekeeping Timer pool HikariPool DEBUG com zaxxer hikari pool HikariPool After cleanup pool stats HikariPool total inUse avail waiting,Please upgrade your HikariCP version Thanks for responding Few queries upgrading is fine But is this known issue in the release Any thing we need to configure to detect leaks or increase the connection pool in case connection pool get exhausted automatically To be honest was so long ago I would suggest just checking the change Of course you can enable the to check your app for leaks I d recommend using a fairly high value like minutes to avoid false positives Leaks will be reported in the log,Yes
17468,pr,v3.2.x: Fix leaks in C++ code,v x Fix leaks in C code PR Summary This is a cherry pick of the leak fix in and another leak fix in the png code which doesn t exist on PR Checklist x Has Pytest style unit tests x Code is Flake compliant N A New features are documented with examples if plot related N A Documentation is sphinx and numpydoc compliant N A Added an entry to doc users next whats new if major new feature follow instructions in README rst there N A Documented in doc api api changes rst if API changed in a backward incompatible way,,Yes
6497,issue,Misleading IsAdminUser signature,Misleading IsAdminUser signature Class IsAdminUser has a misleading name as it only checks for is staff which does not make the user an admin class IsAdminUser BasePermission Allows access only to admin users def has permission self request view return bool request user and request user is staff,I think it s close enough to be clear We ve not had the ticket raised before and that class has been in place for a long time now Django s docs By default logging in to the admin requires that the user has the is superuser or is staff attribute set to True,Yes
974,issue,0.5.0 asset list is empty,asset list is empty asset list is empty asset row item,,No
15371,issue,Thread-safe delegate invocation fix.,Thread safe delegate invocation fix I think the following example needs a fix var handler this PropertyChanged if handler null handler Invoke was handler Document Details Do not edit this section It is required for docs microsoft com GitHub issue linking ID a abe b e e e af ed e c Version Independent ID b c e a d d c f bdc Content Member access operators C Content Source Product dotnet csharp GitHub Login Microsoft Alias wiwagn,is correct but is also correct and a shorter alternative I believe if one doesn t use the null conditional operator one usually uses the shorter syntax as if calling a method or function is correct I m leaving this open as a preferred fix would be to use the more recent thread safe invocation I ve added the up for grabs label if you want to submit a PR We ll help you with the process Otherwise I ve added this to our backlog to update when we next update this article the article uses the thread safe way That snippet shows how the things were done before the null conditional operator After that the modern way is presented I don t think the article needs updates The article even mentions that the snippet is for C and earlier We are talking about this Thanks I read the issue but didn t check back at the content I ll close this The current article is correct Could the team please add some more detailed explanation about the topic I mean thats a very interesting and essential topic imo And there is only one line written Could the team explain why the operator makes the invocation thread safe Sincerely and thanks in advance,Yes
9146,pr,Add cookie option to win_get_url,Add cookie option to win get url Add cookie option for win get url This is useful to download files that require license agreements such as java Example,I wonder if it might be a better idea to follow the standards that the module currently uses by allowing you to set arbitrary module doesn t support it but we should maybe look to standardize I don t know how to replicate this part in powershell I think it would look like Note I haven t had an opportunity to test that Hi Thanks very much for your interest in Ansible It sincerely means a lot to us On September due to enormous levels of contribution to the project Ansible decided to reorganize module repos making it easier for developers to work on the project and for us to more easily manage new contributions and tickets We split modules from the main project off into two repos and you still would like this pull request merged we will need your help making this target the new repo If you do not take any action this pull request unfortunately cannot be applied We apologize that we are not able to make this transition happen seamlessly though this is a one time change and your help is greatly appreciated this will greatly improve velocity going forward Both sets of modules will ship with Ansible though they ll receive slightly different ticket handling To locate where a module lives between core and extras Find the module at Open the documentation page for that module If the bottom of the docs say This is an extras module submit your ticket to Otherwise submit your pull request to update the existing module to Note that python modules in ansible now also end in py and this extension is required for new contributions action plugins modules with server side components still live in the main repo If your pull request touches both which should be exceedingly rare submit two new pull requests and make sure to mention the links to each other in the comments Otherwise if this is a new module Submit your pull request to add a module to may be possible to re patriate your pull requests automatically one user submitted approach for advanced git users has been suggested at should you need more help with this you can ask questions on the development mailing list you very much,Yes
2119,pr,Add support for setting several cipher suites for HTTP/2,Add support for setting several cipher suites for HTTP There are many SSL ciphers which are supported by HTTP clients see and the user should have the ability to use them in Dropwizard applications Currently it s not possible because Dropwizard forces the default cipher defined in the HTTP spec This change allows users to provide a custom list of supported ciphers so clients who support more strong ciphers can use them The provided list of ciphers MUST contain the cipher as defined in the HTTP spec Redux of,Coverage decreased to when pulling a e b d d e c on several suites into a e b fe d ce fedef b on master Ah I forgot to update the test after changing the error message for absence of the default cipher Will do tommorow,Yes
14689,issue,"Add test assets package for X509Certificates tests, and enable the tests",Add test assets package for X Certificates tests and enable the tests The file load based tests for X Certificates are disabled pending having assets to load,This was resolved by,Yes
775,issue,Overwrite attributes containing hashes,Overwrite attributes containing hashes Hi Seth when overwriting setting attributes it seems to me that this does not work with entire attribute hashes When monkey debugging my recipe with puts Attribute settings node nagios master macros an rspec run with let chef run do runner ChefSpec SoloRunner new runner node normal nagios master macros runner converge described recipe end shows that the attribute is not empty but instead returns the settings from the attributes file Attribute settings USER opt nagios plugins How would you advise to test a chef run with an empty or unset attribute I m using chefspec Thanks Patricia,this is just doing a deep merge between default and normal attributes and is just how attributes work might work or plus setting a value although it seems a really weird use case,Unsure
4802,issue,Android UXSS + XFO bypass no longer operational,Android UXSS XFO bypass no longer operational I know you ve noticed this already I m not sure how to go about fixing and you type fluent Javascript about times faster than me I ve tested android stock browser uxss and that still works like a champ on my Samsung Galaxy SIII mini and the XFO bypass is still functional as seen here So how about it We see daily press mentions of this exploit so it d be super nice to be able to demo again,said this obviously Called out I did look into this a bit a few days ago Play store s any request that matches stock Browser s User Agent I suspect they mucked this up at first and that s why they accidentally blocked Firefox which is funny For a demo you might try the exploit in a WebView wrapping browser that overrides User Agent to something else Another neat thing to demo although this would not involve a UXSS would be a module that runs android browser new tab cookie theft then proxies some HTTP requests to play google com through msf which replaces the Cookie header with the ones you ve stolen and replaces User Agent with Chrome s okay thanks Usually Maxthon and CM browser are good for that kind of thing I ll give it a shot today Mainly I m concerned that Google Play store s protection is inadequate and that bad guys will figure out a way around it That would leave people in a situation where they can t safely test with Metasploit giving them the impression that all is clear even though the UXSS and XFO bypass are still present and potentially exploitable will allow theft of secure HttpOnly cookies which is enough to steal the victim s session and install through the Play Store remotely That would be a good demo I don t think I will find a way around the User Agent check so I m going to close this out Fixed kinda Just a quick update I ve tested through the User Agent protections that Play store is using and it appears effective on the usual suspects AOSP reskinned AOSP Maxthon and CM However while looking for a list of most popular mobile browsers I came across this only got k k downloads but it s mentioned a weird browser but it s WebKit and it seems to be lying about its User Agent It s claiming So this module is still effective though in a very limited way It can be triggered when a custom browser built with older WebKit rewrites its User Agent for whatever reason malicious compatability reasons or otherwise IOW I envision an attack scenario where a malware author reskins the stock browser puts it on the play store and uses it to later inject UXSS and slide in Play store apps Thus the Metasploit module is still effective at demonstrating this risk though it s vastly decreased And now I have a device with OEM skinned AOSP Chrome Firefox Maxthon CM Dolphin Opera Opera Mini and Hover Browser cc Haha wow hooray for options You know I bet the attack would still work if the user has the Request Desktop site option checked,Unsure
7457,issue,Cannot access control center on real IOS device,Cannot access control center on real IOS device The problem I am not able to access the control center or change the wireless connectivity during a test on a real device Environment Appium version Last Appium version that did not exhibit the issue if applicable Desktop OS version used to run Appium Mac El Capitan Node js version unless using Appium app exe NA Mobile platform version under test iOS Real device or emulator simulator Real Device Appium CLI or Appium app exe Appium app Details I used to be able to swipe up from the bottom of the screen to access the control center on a real IOS device which I used in many tests to set airplane mode and Wifi connectivity Since updating to Appium this functionality has not worked The swipe is not pulling up control center and trying to start the swipe below the screen creates a point is not within the bounds of the screen exception If this functionality is going to be broken going forward I would like some alternative to pull up the control center Code To Reproduce Issue,Please attach a full set of Appium logs as a This thread has been automatically locked since there has not been any recent activity after it was closed Please open a new issue for related bugs,Unsure
30640,issue,child_process normalization logic can be bypassed,child process normalization logic can be bypassed The module allows to bypass the JavaScript validation logic and to pass a custom array into C which then crashes the process This should be virtually impossible to exploit so I am not marking this as a security issue,Related to and probably several other issues Oh right I ignored closed issues when checking for duplicates assuming we had fixed those,Yes
406,issue,sizeof being called on struct in unsafe context,sizeof being called on struct in unsafe context The generated IL code for SharpDX Interop SizeOf calls sizeof directly on managed structs outside an unsafe block which is not allowed Instead it should use System Runtime Interop SizeOf Adding an unsafe block around sizeof instead will just cause another error Cannot get the address of get the size of or declare a pointer to a managed type I discovered this as I was trying to get SharpDX s DirectInput wrapper to work with the Unity D game engine I was always getting an exception from result CheckError in SharpDX DirectInput CustomDevice SetDataFormat I found the cause of this was in SharpDX DirectInput CustomDevice GetDataFormat line dataFormat new DataFormat DataFormatAttribute dataFormatAttributes Flags DataSize Utilities SizeOf Utilities SizeOf was returning an incorrect value of instead of for the struct When testing with a form application it actually worked but when tested within Unity it failed with an exception By changing Utilities SizeOf to call System Runtime InteropServices Marshal SizeOf typeof T the problem was solved I also changed the SizeOf T array overload to use all other types including structs the sizeof operator can be used only in unsafe code blocks Although you can use the Marshal SizeOf method the value returned by this method is not always the same as the value returned by sizeof Marshal SizeOf returns the size after the type has been marshaled whereas sizeof returns the size as it has been allocated by the common language runtime including any padding,Actually this is not related to unsafe or safe context Using the IL sizeof is perfectly working except that I had to do a around three years ago in Mono to support correctly sizeof on generic see this I believe that Unity has not this patch because they forked Mono a long time ago You can double check using on a for example Unfortunately we cannot replace sizeof with because is taking into account marshalling attributes which we don t want The sizeof instruction is fast it is actually converted to a constant while the Marshal SizeOf can be costly So you should report this bug to Unity the patch is really small so they could integrate it easily Thanks for your reply and explaining it Unfortunately there s absolutely zero chance Unity will patch their Mono distribution The whole reason I m trying to get SharpDX working with it is because Unity has ignored over years of pleas begging for hot plugging support for joysticks connect disconnect events and a reliable way to identify a joystick by id none of these things are functional in Unity I and many others are desperate to have functional joystick support so I started trying to use other means to get it working SharpDX s DirectInput wrapper was perfect and so far I m seeing a VASTLY better joystick experience with perfect hot plugging capabilities Actually I just checked all the references to Utilities SizeOf in my stripped down build of SharpDX just SharpDX SharpDX DirectInput and SharpDX XInput and it doesn t appear any of the structs contain data that should throw off the size I m not too concerned about the speed of Marshal SizeOf since this is only going to be used for DirectInput Thanks for creating this amazing library Sorry if I m not supposed to be commenting on a closed topic This is my first day at github THANK YOU I too have been banging my head against the wall trying to figure out why Kerbal Space Program which unfortunately relies Unity couldn t get Joystick input using SharpDX DirectInput and concluding after recompiling SharpDX to enable the call in that the issue had to do with wrong sizes being reported for the structs Applying your patch worked perfectly to solve this specific issue Copy pasting the exception one typically gets so that other people can find this issue more easily and don t waste as much time as I did SharpDX DirectInput JoystickState SharpDX DirectInput RawJoystickState SharpDX DirectInput JoystickUpdate ctor SharpDX DirectInput DirectInput directInput Guid deviceGuid x in at SharpDX DirectInput Joystick ctor SharpDX DirectInput DirectInput directInput Guid deviceGuid x in at AltInput ProcessInput Start x in Hello and sorry for the bump we are working our way to integrate a non standard joystick controller in Unity using SharpDX without success so far when it comes to put the dll into Unity everything works well in Visual Studio We tried to recompile SharpDX without success Could any of you or upload your SharpDX library base and DirectInput for anyone wanting to use it with Unity Thank you very much With best regards EDIT I found the libraries recompiled especially for Unity They were initially compiled for a Kerbal Space Program add on but you can use them for DirectInput no XInput though You can find the libraries at this address anyway,Yes
116,issue,Code security issues,Code security issues Our security scans and reports from security sites gives Wexflow a very low score I m having difficulty getting it approved even for trial purposes Here s one report showed these low high issues SC Protection of information at Rest P issues SC Information in Share Resources P issues SC Denial of Service Protection P issues SC Transmission Confidentiality and Integrity P issues SC Information Input Validation P issues SC Error Handling P issues SC Information Output Filtering P issues Overall High Medium Low and Information issues found Do you have plans to add static security scanning to your build pipeline and address such issues in any way,I am using Inno Setup to create the installer of the NET version of Wexflow Maybe those issues are related to how I generate the installer of the NET version Also I always check Wexflow packages with Windows Defender before to upload them to GitHub and Windows Defender has never reported a problem or malware threats,Yes
6856,issue,[intro] check for duplicate or inconsistent availability attributes,intro check for duplicate or inconsistent availability attributes Duplicates This can easily happen when existing type s or framework are added to a platform E g Here we have duplicate attributes and while not confusing it does mean extra and non required metadata into the platform assemblies Inconsistent Here we declare a member as available when the type is not I m not sure how the IDE will react but this should be audited since one of them is wrong whatever the IDE behaviour is,this should be audited It should be possible to make it automated I meant the test is automated but the solution fix needs to be audited since it s often copy paste errors or special cases,Unsure
116,pr,omnisharp: Fix hashes,omnisharp Fix hashes Closes,,Unsure
2503,issue,"""Missing credentials in config"" using shared credentials file",Missing credentials in config using shared credentials file Hello I have read lots of topics about this error but still can t seem to figure out a solution to my issue I am using AWS SDK JS as part of a Nuxt project and whenever I try to instantiate AWS I get the following error I have setup my credentials and config files as follows in C Users Bruno aws credentials config I have tried installing the dotenv package to override environment variable and displays So I really don t understand why AWS seems unable to retrieve credentials from anywhere I also installed aws cli and when running it picks up correctly the default credentials I ve input,Which version SDK are you using Which version of Node Can you show a code sample of how you are using the SDK I use node and aws sdk The code that uses the SDK is as follows The AWS object is then used to define a callback function as data of a Vue component that is passed as a property to a child component which is my contact form code you ve provided runs in the browser is that correct You ll need to refer to this documentation Setting Credentials in a Web This issue has been automatically closed because there has been no response to our request for more information from the original author With only the information that is currently in the issue we don t have enough information to take action Please reach out if you have or find the answers we need so that we can investigate further This thread has been automatically locked since there has not been any recent activity after it was closed Please open a new for related bugs and link to relevant comments in this thread,Yes
139,pr,Add openssl again to fix tmux,Add openssl again to fix tmux Adding the old openssl package this should resolve,Looks like I missed issue don t merge this until tested Issue should probably be investigated before merge too openssl TEST PASSED open ssl installed successfully Output openssl e chromeos x tar M MB s in s MB s openssl e chromeos x tar gz saved Archive downloaded Unpacking archive this may take a while Installing Openssl installed I do a openssl version and get the following reply OpenSSL e Dec TMUX TEST PASSED I m on a x chromebook and did a crew install tmux Output bin mkdir p usr local tmp crew dest usr local share man man usr bin install c m tmux mdoc usr local tmp crew dest usr local share man man tmux make Leaving directory install data am make Leaving directory usr local tmp crew tmux a Installing Tmux installed merged thanks thanks for the testing it s really valuable for I guess everyone,Yes
31907,issue,pillars not updated on minions until salt-minion is restarted,pillars not updated on minions until salt minion is restarted Description of Issue Question When using git pilalr if I make a change to the pillar data on the repo and run The pillar data is not updated only if the minion is restarted that new pillars show up when I run the git pillar config file in etc salt master d pillar config conf Steps to reproduce I am not sure how this will be reproduced I am using the same repo for gitfs and git pillar and all hosts are RHEL on a virtual environment vMWare Versions Report,thanks for reporting What happens when you do return the old pillar value thanks for confirming This is possibly related to and I updated to the new version but the problem still exists I have another setup with another master running on ERHEL and I don t see the problem on that one Here is the versions report of the WORKING master where minions DO NOT need to be restarted for pillars updates to show up And here is the versions report of the NON WORKING master where the minions NEED TO BE RESTARTED after the pillars are updated for changes to take effect The minions for both masters looks similar and are all RHEL or OEL here is a versions report of one minion is there a workaround that I can implement to fix this not that I know of Hmm my first reaction here is that this might be be related to the difference in git provider libs If you take pygit down to the version on the working master does this problem go away Does the fact that I have two masters setup in redundant master setup have anything to do with this setup was made base on this walk through two masters have the same key minions are configured to check in with both masters and both masters look at the same repository for gitfs and git pillar Do I need to keep the local cache files on each master in sync in order to solve this Same here here is our minion We re struggling with this issue and we re running a multimaster topology with The masters and minions are running We re using a custom pillar backend and and Changes in pillars are not updated in pillar get and item calls when you target minions from one of the masters after you ve executed This is also the case when the pillar get item command is run from within a custom module on the targeted minion A without args does hand you fresh pillar data Running salt call pillar get or pillar item on the minion also works ok There seems to be little activity on this and the related issues linked here Is it something that s being worked on or are there workarounds we can use perhaps a different multimaster topology I can confirm this issue is still occurring in The only workaround even in a simple master minion setup is to restart the salt minion Neither of the associated issues have been addressed This issue is still occuring on Still reproducible on Is it going to be addressed soon I m hitting the same issue in Same here with I ran into something similar but a restart of the minion didn t help My problem was with how we use packer and the salt masterless provisioner The provisioner copies pillar and salt files under srv due to and Once the salt master EC instance launched based off of this new AMI it would merge data in both srv left over from the build process and gitfs ext pillar I was able to see this after running the salt master in debug mode The fix was to do a clean up during the packer build shell provisioner before it actually created the One interesting thing and don t give the files read for the pillar information Seeing similarly strange things in where having updated a plain YAML SLS style pillar file on the master and tried restarting master minions etc the minions are not getting the same values A bit more debugging running commands on a minion The pillar that you see when I pass reflects the source of truth pillar file on master There is only one pillar defined on this deployment it s a very small scale single master deployment not really using many clever SaltStack tricks I was expecting to have stumbled onto a weird edge case of my own making but I m instead surprised by how long this has been a problem for other users How can we help you get more information to fix this because it s fundamental to why people use Salt repeatability Right now Salt can literally deploy the wrong things on the wrong hosts I found that I could workaround my problems by doing this on the master I found that I could workaround my problems by doing this on the master I needed to do the above but also renamed a cache directory under and restarted the service I m having the same problem I just noticed that one of my Windows minions is not refreshing its in memory pillar data after a saltutil refresh pillar I m on salt on my minions and salt on the master I don t see what setting pillar cache False on the master would do since that supposed to be the default but I m trying it anyway I have done that and I have deleted all of the directories in var cache salt master minions just to see what happens I also notice that pillar based scheduling stops doing anything on these minions once the refresh stops working It my particular case there could be some kind of timeout issue lurking in the background I schedule a saltutil refresh pillar but in the scheduling specification I don t see how to include a timeout value If the salt master is not available to the minion at the time of the function is called it s possible that the the job never returns which may be the cause of what I m seeing somehow Sorry for this stream of conciousness babble I m trying to understand what s going on WHat I said about refresh pilar makes no sense since that just causes a signal to be sent I am seeing this happening on machines that I believe are suspending usually laptops and then waking up I notice that for the pillar events since the pillar is apparently frozen schedule next fire time for all of the events specified in the pillar also becomes frozen and all the times become times in the past Alright I apologise for the previous post I wasn t really ready to say anything but I am now sort of AFAICS it only happens on minions that experience network disruptions or in the very least it happens ways more on those machines In particular it happens a lot with laptops and I assume that this is because people are closing the lids and putting them to sleep or they re going to sleep on their own I don t know if this bug happens on Linux minions because I haven t got Linux installed on any minions that aren t always connected I don t think that whatever sleep mode a machine goes into would make any difference assuming the sleep mode is properly implemented so I think it has to be the network disruption Some things I have observed pillar items always gives correct up to date pillar data as we would hope Pillar schedule events stop firing or appear to In some cases the fire times reported by shchedule show next fire time are in the past and stop updating In some cases the fire times are updating but the events stop firing anyway That s all I ve got I have no idea how I could possibly triangulate this I hope that this can be looked at because I consider it to be a quite serious problem with core functionality If it is due to network disruptions and cannot be fixed for instance due to however zeromq is implemented then the FAQ should have workarounds for that situation On Windows machines I believe I can have the scheduler restart minions after waking up which I will try next I think This may be an adequate workadound if not ideal fingers crossed This seems to be resolved for Windows minions by having the salt minion service restart after waking up from sleep I don t know what the situation is for linux minions I now have much more reliability with minions specifically the laptops reporting in regularly and actually carrying out their scheduled events I have the same problem with my slat minion version I couldn t refresh pillars I have created I couldn t see my pillars data on my minion even after restarting minion I could see only the static state tmp tmp deletemeplease txt in my init sls is applied but not the user creation state that obtain multiple user data from pillars Attaching my sample init sls for user creation state that needs to read data from pillars through jinja template Also Attaching my sample qa environment for users state and its pillars directory structure I am learning salt to deploy our infrastructure with code via jenkins Your help is much appreciated here to expedite my learning init sls code to create multiple users with one state via jinja and pillar data,No
393,pr,Updating build to inject license text at start of output files,Updating build to inject license text at start of output files This pull request adds attribution comments at the start of the distributed artifacts Background Context Updated build process to inject the license comment into output files and prevent uglify from removing it,Missing item s on my end will reopen resubmit after fixing,Unsure
392,pr,Fix database id mapping to remove guesswork hacks,Fix database id mapping to remove guesswork hacks The SqliteDatabaseDriver had to resort to counter intuitive hacks to manually locate a database by its file name and didn t properly handle deduplicating multiple databases with the same name As we expanded flexibility we failed to address the possibility nay likelihood that this will occur and it would create very confusing results for users This diff doesn t address the confusion in the UI two database entries of the same name can still occur but it internally makes it possible to treat them as separate databases and track their filenames separately It also makes it relatively straightforward to fix the uniqueness of the user visible naming by introducing a context parameter to DatabaseDescriptor which would be used in the case of name ambiguity This diff addresses concerns raised in and,Thank you for your pull request We require contributors to sign our Contributor License Agreement and yours has expired Before we can review or merge your code we need you to email clawith your details so we can update your status Thank you for signing our Contributor License Agreement We can now accept your code for this and any Facebook open source project Thanks Wow this is a big old diff apparently by me but it does look important I think my patch is overall viable but I think it got stalled due to a binary compat issue I m looking into now ping ping YOLO,Yes
3612,pr,Ignore android.injected.build.abi,Ignore android injected build abi It is set by AS randomly for some reasons seems AS will inject ABIs according to execution target But it is not having the right ABI values all the time So just disable it only check buildTargetABIs property,,Unsure
2797,issue,Microsoft Graph App Role permissions assigned to Security Group -- Members not inheriting permissions,Microsoft Graph App Role permissions assigned to Security Group Members not inheriting permissions I apologize ahead of time as I don t believe this is the correct place for this question but I honestly can t find where I should post this question Please point me in the right direction if I need to post this somewhere else I have several Managed Service Identity MSI accounts I want to give them all the same set of Microsoft Graph permissions Directory Read All and User Read All I did this on one of the MSI and I am able to query the information I need from Microsoft Graph without any issues To simplify the permissions I created a security group in Azure AD and assigned the aforementioned approles to the security group I then added all the MSIs that need those permissions to that security group as members I ve waited a day because I ve noticed sometimes it takes time for permissions to propagate and I get an error whenever the MSIs try to access a user s photo It looks like the MSIs are not inheriting the access from the security group they are assigned to Is this scenario supported If so what might I be doing wrong,could you help here I couldn t find any documentation that covers this scenario Is there any update on this Sorry for the delayed response In future please file these kinds of questions on StackOverflow and tag with microsoftgraph Issues for this repo are more targeted to doc bugs in general However since you and Jeremy have me here The system doesn t really work that way or the way you are expecting it to App roles can be assigned in one of ways Assign an app role to a user or group When you do this this enables the user or members of the group to sign in to the app that defines the app role and then the app role is presented as a claim in the user token and the app can authorize the user s access based on that app role Assign Grant an app role permission to an app servicePrincipal MSI When you do this the access token that the app servicePrincipal MSI acquires to call an API that defines those permissions that were granted will have a claim that contains the permission app role The API then authorizes based on the app roles claim So when you did your first step granting your MSI some perms you were going through flow When you tried your step with that doesn t work because that s geared towards user sign in and using groups as a container for users In theory assigning those app role permissions to a group should have failed because those app roles should have been configured as ONLY applicable to applications i e above and not applicable to users and groups i e OK that s how it works I think what you are suggesting based on your expectation is that you should also be able to assign app roles to a set of MSIs servicePrincipals and now those servicePrincipals MSIs should all have the assigned level of access to the targeted API in this case Microsoft Graph based on the app roles assigned Do I have this correct I did ask on first though I was a bit impatient as I also asked it here on the same day It sounds like the root of the problem is that app roles for users work the way I would expect them to I can assign them to either a user or a security group If it s assigned to a security group then members of that security group will inherit the permission App roles for applications work differently they can only be assigned directly to a service principal which both App Registrations and MSIs are types of service principals and cannot be inherited via group membership So you would have expected the assignment of the app role to the security group to have failed If it should then it sounds like there s a bug I was able to assign the role to a security group and have run scripts to verify that the security group does in fact have the app role assigned to it OK great on the SO question Yes I would have expected the assignment of the app role to the security group to have failed If it didn t fail then it s either a bug or the app role definitions are incorrectly defined will need to check I d also like to evaluate how common a scenario it is in devops to create multiple MSIs and assign them the same access levels to Microsoft Graph or other APIs If so enabling through group membership might seem a reasonable approach Mine isn t a DevOps scenario I have an application that needs to query our Azure AD I don t want to use delegated permissions though it was a valid option and my IT team didn t want to assign the permissions to the app since it has a non expiring password i e client secret I learned about MSIs and how they have a rolling password this satisfied the IT teams requirements so we moved forward with that My app is hosted in Azure as an App Service and App Services do not currently support user managed service principals so I had to use an MSI so each of my environments has its own MSI but they all need the same permissions to the Microsoft Graph API Any update on this,Yes
3845,pr,Update advanced-security-audit-policy-settings.md,Update advanced security audit policy settings md link,Can you please assist to check approve and merge the content of this PR based on issue Thank you,Yes
60727,pr,acme_certificate: make compatible to Buypass' ACME v2 testing endpoint,acme certificate make compatible to Buypass ACME v testing endpoint SUMMARY While trying the Buypass ACME v testing see I found a problem where Boulder and Pebble behave differently than Buypass When finalizing an order Boulder and Pebble return a header with the order URI while Buypass does not If I understand RFC correctly this header does not need to be returned in any case there should be no need for it since we already know the order URI Note that the Buypass ACME v doesn t seem to work with If anyone wants to debug this feel free ISSUE TYPE Bugfix Pull Request COMPONENT NAME acme certificate,cc here for bot and also thanks a lot for reviewing this one,Yes
1376,pr,"In Live Development, strip off query/hash strings from stylesheet URLs when comparing them",In Live Development strip off query hash strings from stylesheet URLs when comparing them Fixes,Ready for review I decided not to actually make the same change in the JS agent because it s not part of a working feature yet and it doesn t make sense to spend the time to figure out how to test it right now So I just added TODO comments to note that we should make the same fix there once we start working on JS related live development features Looks good Merging,Yes
75,issue,Use OAuth authentication,Use OAuth authentication The app should really use OAuth authentication instead of asking users to provide username password in the app Your API already supports OAuth so I can t see a good reason not to use it for the app,Why Do you not trust GitHub with your GitHub credentials I don t trust anyone I shouldn t really need to explain why asking for username password instead of using OAuth is a bad idea but here goes There is no reason why the app should store my crendentials It should just store the oauth token In the case of a lost phone I just need to de authorize the app not change my password So instead of logging in through the app github s controlled app you want an oauth step that goes to a less secure app the browser for you to put in login credentials I m failing to see how this makes it more secure How is the browser less secure than the github app That statement needs some backing up Anyway with OAuth your credentials are sent once and they are never stored on the device Only the token is stored The current mechanism stores the credentials on the device I see your point about storing only the OAuth token on the device versus the username password combo That s why I opted to go that route in Hubroid Ask for username and password create OAuth token with GitHub s API and store the token for use in the app But I still think it s just an odd request to ask a service to use its own OAuth implementation as if it can t be trusted In the case of a lost or stolen device though you should just use a remote wipe solution that ll take care of all your data then you don t have to worry about changing anything Fair point about storage of credentials I agree with the above however instead of using oauth I would like OAuth if for no other reason than laziness I use a password manager and unique very large character passwords Typing something like that in on my phone is not fun I use the PasswordMaker Pro app It generates the password and leaves it in my clipboard so I can handily paste it places That s a cool app but neither here nor there for this problem as I don t generally generate passwords on my phone and can t copy paste from my computer to phone Use Chrome to Phone to copy your clipboard over to your device they are all workarounds a solution already exists to protect credentials the solution is OAuth What s wrong with a little dog food I d like to this This is not about trusting GitHub but rather about securing my password While I assume that GitHub internally has my password secured enough my phone and my data connection won t be as secure After all the application needs to store the password in a decryptable way so if someone gets hold of my phone they have my password The main idea behind OAuth is to protect my login credentials by creating a new set that is very specific to the application I use That way when someone gets access to my phone they might get into my account using the combination but they won t get my password And I can easily shut them out by removing the authorization So instead of logging in through the app github s controlled app you want an oauth step that goes to a less secure app the browser for you to put in login credentials That s not how the initial OAuth login works You usually enter your password once to have the application generate its access token set After that it no longer needs the password and also never needs to store it for anything This has been fixed in master,Yes
14733,issue,"link to scripts: java.security.AccessControlException: access denied (""java.io.FilePermission""...",link to scripts java security AccessControlException access denied java io FilePermission In ES x I was able to symbolically link from a subdirectory of the scripts directory to a directory containing my groovy scripts Now with ES on load I get the following error Exception in thread main java security AccessControlException access denied java io FilePermission usr local Cellar elasticsearch libexec config scripts my directory my subdirectory read at java security AccessControlContext checkPermission AccessControlContext java at java security AccessController checkPermission AccessController java at java lang SecurityManager checkPermission SecurityManager java at java lang SecurityManager checkRead SecurityManager java at sun nio fs UnixPath checkRead UnixPath java at sun nio fs UnixFileSystemProvider checkAccess UnixFileSystemProvider java at java nio file Files exists Files java at org elasticsearch watcher FileWatcher FileObserver init FileWatcher java at org elasticsearch watcher FileWatcher FileObserver createChild FileWatcher java at org elasticsearch watcher FileWatcher FileObserver listChildren FileWatcher java at org elasticsearch watcher FileWatcher FileObserver onDirectoryCreated FileWatcher java at org elasticsearch watcher FileWatcher FileObserver init FileWatcher java at org elasticsearch watcher FileWatcher FileObserver createChild FileWatcher java at org elasticsearch watcher FileWatcher FileObserver listChildren FileWatcher java at org elasticsearch watcher FileWatcher FileObserver onDirectoryCreated FileWatcher java at org elasticsearch watcher FileWatcher FileObserver init FileWatcher java at org elasticsearch watcher FileWatcher FileObserver access FileWatcher java at org elasticsearch watcher FileWatcher doInit FileWatcher java at org elasticsearch watcher AbstractResourceWatcher init AbstractResourceWatcher java at org elasticsearch watcher ResourceWatcherService add ResourceWatcherService java at org elasticsearch watcher ResourceWatcherService add ResourceWatcherService java at org elasticsearch script ScriptService ScriptService java at sun reflect NativeConstructorAccessorImpl newInstance Native Method at sun reflect NativeConstructorAccessorImpl newInstance NativeConstructorAccessorImpl java at sun reflect DelegatingConstructorAccessorImpl newInstance DelegatingConstructorAccessorImpl java at java lang reflect Constructor newInstance Constructor java at at org elasticsearch node Node Node java at org elasticsearch node NodeBuilder build NodeBuilder java at org elasticsearch bootstrap Bootstrap setup Bootstrap java,Have a look at Sounds like we advertised we can follow symlinks for scripts symbolic links are never supported if they happen to work its random chance do I misunderstand the doc I linked they are neither tested nor supported we can t we can t prevent some code from traversing the link in which case unix permissions checks are different too same problem I totally agree with you Robert I m just asking if we must fix the doc or if I simply misunderstood that part What the documentation says works that is not what is happening here So I definitely don t understand this but no symlinks under that path will be followed with the exception of path scripts which does follow symlinks My bad English I guess Closing the issue then I saw that part of the docs before I posted the issue I also am confused by it With ES what I was doing worked without issue on each installation I tried both on Centos and OSX The doc quoted above says path scripts does follow symlinks and symlinks under that path will be followed How is my symlink NOT under the path scripts path path scripts is not explicitly set in my elasticsearch yml so ES appears to be using the default This is my symlink usr local Cellar elasticsearch libexec config scripts my directory my subdirectory Users tbr projects www my site es scripts I believe the document means that itself can be a symlink but that symlinks within the directory aren t supported I haven t tried it though Then the doc should say a symlink from path scripts but not within will be followed Or even better ES would follow the symlinks within path scripts No we don t need to do a recursive traversal for symlinks for security purposes when symlinks themselves are broken from that perspective Just don t use symlinks I prefer this wording Symlinks are forbidden Period This is clear IMO OK Then the doc should be updated the combination of under with plural for symlinks is confusing and makes it sound like you can have multiple symlinks within path scripts I agree and the purpose of adding in the first place was so that people could configure a shared location without resorting to stuff like symlinks path scripts data www sample name releases current app search scripts current symlink to the directory with the current checkout of the application releases current releases Elastic can not load scripts What s wrong with the such setup New approach is just horrible I investigated more and issue exists only after switching symlink I am getting WARN threadpool master failed to run org elasticsearch watcher ResourceWatcherService ResourceMonitoraccess denied java io FilePermission data www sample name releases current app search scripts read After restart of elasticsearch everything works as expected Symlinks in java security manager require adding permission for both the link and what the link points to The setting is read and followed at startup and those permissions are added to the policy then Simply changing the link while elasticsearch is running will not work This is why restarting solved your problem it re read the link and added the setup the new appropriate permissions,Yes
